# Module Trip Parser

Documentation technique compl√®te du module `trip_parser`, incluant les d√©tails des mod√®les ML, l'entra√Ænement, et la configuration.

## üì¶ Vue d'ensemble

Le module `trip_parser` est le c≈ìur du syst√®me d'extraction de trajets. Il combine deux mod√®les de Machine Learning pour transformer du texte en fran√ßais en informations structur√©es de voyage.

**Composants principaux :**

| Composant | Type | R√¥le |
|-----------|------|------|
| **NERExtractor** | Mod√®le pr√©-entra√Æn√© | D√©tection des entit√©s g√©ographiques |
| **DepartureArrivalClassifier** | Mod√®le fine-tun√© | Classification d√©part vs arriv√©e |
| **TripParser** | Orchestrateur | Coordination des mod√®les |
| **Config** | Configuration | Chemins et param√®tres |
| **Exceptions** | Gestion d'erreurs | Exceptions typ√©es |

## ü§ñ NERExtractor (D√©tection d'entit√©s)

### Mod√®le utilis√©

**Nom :** `Jean-Baptiste/camembert-ner`

**Source :** [Hugging Face Hub](https://huggingface.co/Jean-Baptiste/camembert-ner)

**Architecture :**
```
CamemBERT Base (110M param√®tres)
    ‚Üì
[Embedding Layer]
    ‚Üì
[12 Transformer Blocks]
    ‚Üì
[Token Classification Head]
    ‚Üì
4 classes : PER, LOC, ORG, MISC
```

**Capacit√©s :**

- ‚úÖ D√©tecte les noms de villes fran√ßaises (Paris, Lyon, Marseille...)
- ‚úÖ D√©tecte les lieux (gares, a√©roports...)
- ‚úÖ G√®re les variations orthographiques
- ‚ö†Ô∏è Moins pr√©cis sur les petites villes peu connues

### Tokenisation d√©taill√©e

/// tab | Exemple basique
```python
text = "Je vais de Paris √† Lyon"

# √âtape 1 : Tokenisation subword
tokens = ["‚ñÅJe", "‚ñÅvais", "‚ñÅde", "‚ñÅParis", "‚ñÅ√†", "‚ñÅLyon"]
# Note : ‚ñÅ indique le d√©but d'un mot

# √âtape 2 : Conversion en IDs
input_ids = [5, 123, 456, 789, 12, 567]

# √âtape 3 : Forward pass CamemBERT
# Chaque token obtient un score pour chaque classe
logits = [
    [0.1, 0.05, 0.05, 0.8],  # "‚ñÅJe"    ‚Üí O (Outside)
    [0.15, 0.1, 0.05, 0.7],  # "‚ñÅvais"  ‚Üí O
    [0.2, 0.05, 0.05, 0.7],  # "‚ñÅde"    ‚Üí O
    [0.05, 0.9, 0.03, 0.02], # "‚ñÅParis" ‚Üí LOC (B-LOC)
    [0.3, 0.05, 0.05, 0.6],  # "‚ñÅ√†"     ‚Üí O
    [0.05, 0.92, 0.02, 0.01] # "‚ñÅLyon"  ‚Üí LOC (B-LOC)
]
# Classes : [PER, LOC, ORG, MISC]

# √âtape 4 : Agr√©gation
entities = [
    {"entity_group": "LOC", "word": "Paris", "score": 0.90},
    {"entity_group": "LOC", "word": "Lyon", "score": 0.92}
]

# √âtape 5 : Extraction finale
locations = ["Paris", "Lyon"]
```
///

/// tab | Cas complexe : tokens multiples
```python
text = "Je vais √† Saint-√âtienne"

# Tokenisation subword (Saint-√âtienne en plusieurs tokens)
tokens = ["‚ñÅJe", "‚ñÅvais", "‚ñÅ√†", "‚ñÅSaint", "-", "√ât", "ienne"]

# NER labels (B=Begin, I=Inside)
labels = ["O", "O", "O", "B-LOC", "I-LOC", "I-LOC", "I-LOC"]

# Agr√©gation (strategy="simple" fusionne B-LOC + I-LOC)
entities = [
    {
        "entity_group": "LOC",
        "word": "Saint-√âtienne",  # Reconstruit automatiquement
        "score": 0.87
    }
]

locations = ["Saint-√âtienne"]
```
///

/// tab | Gestion des locations compos√©es
```python
text = "Paris Marseille demain"

# NER d√©tecte les deux villes coll√©es
entities = [
    {"entity_group": "LOC", "word": "Paris Marseille", "score": 0.75}
]

# Split automatique des locations compos√©es
# (fonction _split_compound_locations)
locations = ["Paris", "Marseille"]  # Split car 2 mots majuscules
```
///

### M√©triques de performance

**Dataset de test :** ~1000 phrases vari√©es

| M√©trique | Score | Description |
|----------|-------|-------------|
| **Precision** | 95% | 95% des entit√©s d√©tect√©es sont correctes |
| **Recall** | 93% | 93% des villes pr√©sentes sont d√©tect√©es |
| **F1-Score** | 94% | Moyenne harmonique pr√©cision/rappel |

**Temps d'inf√©rence :**

- CPU : ~100-150ms par phrase
- GPU (CUDA) : ~20-30ms par phrase

### Limitations connues

**1. Noms communs ambigus**
```python
"Train de Paris-Gare-de-Lyon"
# Risque de d√©tecter "Lyon" comme ville
```

**2. Petites villes rares**
```python
"De Tiny-Village √† Unknown-Town"
# Peut ne pas d√©tecter les villages peu connus
```

**3. Noms de lieux non-villes**
```python
"A√©roport Charles de Gaulle √† Orly"
# Peut confondre a√©roports et villes
```

## üéØ DepartureArrivalClassifier (Classification)

### Mod√®le fine-tun√©

**Mod√®le de base :** `camembert-base` (Hugging Face)

**Fine-tuning :**

- Dataset : `data/training_dataset.json`
- Task : Classification binaire (2 classes)
- Classes : 0 = departure, 1 = arrival
- Epochs : 3
- Learning rate : 2e-5
- Batch size : 8

**Architecture :**
```
CamemBERT Base (110M param√®tres)
    ‚Üì
[Embedding Layer]
    ‚Üì
[12 Transformer Blocks]
    ‚Üì
[Dropout 0.1]
    ‚Üì
[Linear Layer : 768 ‚Üí 2]
    ‚Üì
2 classes : departure, arrival
```

### Format du dataset d'entra√Ænement

**Fichier :** `data/training_dataset.json`

```json
[
  {
    "text": "Je veux aller de [LOC] Paris [/LOC] √† Lyon",
    "label": 0
  },
  {
    "text": "Je veux aller de Paris √† [LOC] Lyon [/LOC]",
    "label": 1
  },
  {
    "text": "Train de [LOC] Marseille [/LOC] vers Nice",
    "label": 0
  },
  {
    "text": "Train de Marseille vers [LOC] Nice [/LOC]",
    "label": 1
  }
]
```

**Structure des exemples :**

Chaque exemple contient :

- `text` : La phrase avec une ville marqu√©e entre `[LOC]` et `[/LOC]`
- `label` : `0` pour departure (d√©part), `1` pour arrival (arriv√©e)

**Format des labels :**

```python
# Exemple 1 : Ville de d√©part marqu√©e
{
    "text": "Je veux aller de [LOC] Paris [/LOC] √† Lyon",
    "label": 0  # 0 = departure (Paris est le d√©part)
}

# Exemple 2 : Ville d'arriv√©e marqu√©e
{
    "text": "Je veux aller de Paris √† [LOC] Lyon [/LOC]",
    "label": 1  # 1 = arrival (Lyon est l'arriv√©e)
}
```

### Entra√Ænement du classifier

**Script :** `scripts/train.py`

**Commande :**
```bash
trip-train
```

**√âtapes d'entra√Ænement :**

/// tab | 1. Chargement des donn√©es
```python
# Charger le dataset
with open("data/training_dataset.json") as f:
    data = json.load(f)

print(f"Loaded {len(data)} examples")

# Exemple de sortie :
# Loaded 140 examples
```
///

/// tab | 2. Extraction des textes et labels
```python
# Extraire les textes et labels du dataset
training_texts = [item["text"] for item in data]
training_labels = [item["label"] for item in data]

print(f"Training texts: {len(training_texts)}")
print(f"Training labels: {len(training_labels)}")

# Exemple de sortie :
# Training texts: 140
# Training labels: 140
```
///

/// tab | 3. Split train/validation
```python
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    training_texts,
    training_labels,
    test_size=0.2,
    random_state=42,
    stratify=training_labels  # √âquilibre les classes
)

print(f"Train: {len(X_train)}, Validation: {len(X_val)}")
# Train: 1920, Validation: 480
```
///

/// tab | 4. Cr√©ation du dataset PyTorch
```python
from torch.utils.data import Dataset

class TripDataset(Dataset):
    def __init__(self, texts, labels, tokenizer):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
    
    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            max_length=128,
            padding="max_length",
            truncation=True,
            return_tensors="pt"
        )
        
        return {
            "input_ids": encoding["input_ids"].squeeze(),
            "attention_mask": encoding["attention_mask"].squeeze(),
            "labels": torch.tensor(label)
        }

train_dataset = TripDataset(X_train, y_train, tokenizer)
val_dataset = TripDataset(X_val, y_val, tokenizer)
```
///

/// tab | 5. Configuration d'entra√Ænement
```python
from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="models/departure_arrival_classifier",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    learning_rate=2e-5,
    weight_decay=0.01,
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)
```
///

/// tab | 6. Lancement de l'entra√Ænement
```bash
# Lancer l'entra√Ænement
trainer.train()

# Sortie attendue :
# Epoch 1/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:23<00:00]
#   Train Loss: 0.142
#   Eval Loss: 0.098
#   Eval Accuracy: 96.2%
#
# Epoch 2/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:21<00:00]
#   Train Loss: 0.067
#   Eval Loss: 0.084
#   Eval Accuracy: 97.5%
#
# Epoch 3/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:22<00:00]
#   Train Loss: 0.034
#   Eval Loss: 0.079
#   Eval Accuracy: 98.1%
```
///

/// tab | 7. Sauvegarde du mod√®le
```python
# Sauvegarder le meilleur mod√®le
trainer.save_model("models/departure_arrival_classifier")
tokenizer.save_pretrained("models/departure_arrival_classifier")

# Fichiers sauvegard√©s :
# models/departure_arrival_classifier/
#   ‚îú‚îÄ‚îÄ config.json
#   ‚îú‚îÄ‚îÄ model.safetensors
#   ‚îú‚îÄ‚îÄ tokenizer_config.json
#   ‚îú‚îÄ‚îÄ sentencepiece.bpe.model
#   ‚îú‚îÄ‚îÄ special_tokens_map.json
#   ‚îî‚îÄ‚îÄ added_tokens.json
```
///

### M√©triques de performance

**Dataset de validation :** 480 exemples

| M√©trique | Score | Description |
|----------|-------|-------------|
| **Accuracy** | 98.1% | Taux de classification correcte |
| **Precision** | 97.8% | Pr√©cision (departure) |
| **Recall** | 98.5% | Rappel (departure) |
| **F1-Score** | 98.2% | F1 global |

**Matrice de confusion :**
```
                Predicted
              Dep    Arr
Actual  Dep   236     4      ‚Üí 98.3% recall
        Arr     3    237     ‚Üí 98.7% recall
        
Precision:    98.7%  98.3%
```

### Inf√©rence d√©taill√©e

```python
text = "Je vais de Paris √† Lyon"
location = "Paris"

# 1. Marquer la location
marked_text = text.replace(location, "[LOC]")
# ‚Üí "Je vais de [LOC] √† Lyon"

# 2. Tokeniser
inputs = tokenizer(marked_text, return_tensors="pt")
# ‚Üí {
#     "input_ids": tensor([[5, 123, 456, 789, 12, 567, 6]]),
#     "attention_mask": tensor([[1, 1, 1, 1, 1, 1, 1]])
#   }

# 3. Forward pass
with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
# ‚Üí tensor([[4.2, -3.8]])  # [score_departure, score_arrival]

# 4. Softmax pour probabilit√©s
probs = torch.softmax(logits, dim=1)
# ‚Üí tensor([[0.9982, 0.0018]])

# 5. Pr√©diction
label = logits.argmax().item()  # ‚Üí 0 (departure)
confidence = probs[0, label].item()  # ‚Üí 0.9982

return ("departure", 0.9982)
```

## ‚öôÔ∏è Configuration

### Fichier de configuration

**Fichier :** `src/trip_parser/config.py`

```python
@dataclass
class Paths:
    """Configuration des chemins (absolus)."""
    
    # Racine du projet (calcul√©e automatiquement)
    PROJECT_ROOT: Path = field(
        default_factory=lambda: Path(__file__).parent.parent.parent
    )
    
    @property
    def models_dir(self) -> Path:
        """Dossier des mod√®les : PROJECT_ROOT/models/"""
        return self.PROJECT_ROOT / "models"
    
    @property
    def data_dir(self) -> Path:
        """Dossier des donn√©es : PROJECT_ROOT/data/"""
        return self.PROJECT_ROOT / "data"
    
    @property
    def logs_dir(self) -> Path:
        """Dossier des logs : PROJECT_ROOT/logs/"""
        return self.PROJECT_ROOT / "logs"
    
    @property
    def departure_arrival_model(self) -> Path:
        """Chemin du classifier fine-tun√©."""
        return self.models_dir / "departure_arrival_classifier"
    
    @property
    def training_dataset(self) -> Path:
        """Chemin du dataset d'entra√Ænement."""
        return self.data_dir / "training_dataset.json"

@dataclass
class ModelConfig:
    """Configuration des mod√®les ML."""
    
    # Nom du mod√®le NER sur Hugging Face
    ner_model_name: str = "Jean-Baptiste/camembert-ner"
    
    # Seuil de confiance pour la classification
    confidence_threshold: float = 0.5
    
    # Device (None = auto-d√©tection)
    device: str | None = None  # "cuda" ou "cpu"

@dataclass
class Config:
    """Configuration globale."""
    
    paths: Paths = field(default_factory=Paths)
    model: ModelConfig = field(default_factory=ModelConfig)
```

### Utilisation de la configuration

```python
from trip_parser import get_config

config = get_config()

# Acc√©der aux chemins
print(config.paths.PROJECT_ROOT)
# ‚Üí /Users/natchi/Epitech/T-AIA-911/bootstrap

print(config.paths.models_dir)
# ‚Üí /Users/natchi/Epitech/T-AIA-911/bootstrap/models

print(config.paths.departure_arrival_model)
# ‚Üí /Users/natchi/Epitech/T-AIA-911/bootstrap/models/departure_arrival_classifier

# Acc√©der √† la config des mod√®les
print(config.model.ner_model_name)
# ‚Üí Jean-Baptiste/camembert-ner

print(config.model.confidence_threshold)
# ‚Üí 0.5

# Modifier la configuration
config.model.confidence_threshold = 0.7
config.model.device = "cuda"
```

## üö® Exceptions

### Hi√©rarchie compl√®te

```python
TripExtractionError (Exception)
‚îÇ
‚îú‚îÄ‚îÄ ModelNotFoundError
‚îÇ   Message: "Model not found at '{path}'. Please train the model first..."
‚îÇ   Attributs: model_path
‚îÇ
‚îú‚îÄ‚îÄ ModelLoadError
‚îÇ   Message: "Failed to load model '{name}': {original_error}"
‚îÇ   Attributs: model_name, original_error
‚îÇ
‚îú‚îÄ‚îÄ InsufficientLocationsError
‚îÇ   Message: "Need at least {required} locations, but only found {found}"
‚îÇ   Attributs: found_count, required_count
‚îÇ
‚îú‚îÄ‚îÄ InvalidInputError
‚îÇ   Message: "Invalid input for '{field}': {reason}"
‚îÇ   Attributs: field, value, reason
‚îÇ
‚îú‚îÄ‚îÄ ClassificationError
‚îÇ   Message: "Failed to classify locations. Consider adding to training..."
‚îÇ   Attributs: text, locations
‚îÇ
‚îî‚îÄ‚îÄ TokenizationError
    Message: "Tokenization failed: {original_error}"
    Attributs: text, original_error
```

### Gestion des exceptions

```python
from trip_parser import TripParser
from trip_parser.exceptions import (
    TripExtractionError,
    InvalidInputError,
    InsufficientLocationsError,
    ModelNotFoundError
)

parser = TripParser()

try:
    departure, arrival = parser.parse_trip(user_input)
    
except InvalidInputError as e:
    # Texte vide ou invalide
    print(f"Erreur de validation: {e.field} - {e.value}")
    # Action: Demander √† l'utilisateur de corriger l'entr√©e
    
except InsufficientLocationsError as e:
    # Moins de 2 villes d√©tect√©es
    print(f"Seulement {e.found_count} ville(s) d√©tect√©e(s)")
    # Action: Demander plus de d√©tails
    
except ModelNotFoundError as e:
    # Mod√®le non entra√Æn√©
    print(f"Mod√®le manquant: {e.model_path}")
    print("Ex√©cutez: trip-train")
    # Action: Afficher les instructions d'entra√Ænement
    
except TripExtractionError as e:
    # Erreur g√©n√©rique
    print(f"Erreur d'extraction: {e}")
    # Action: Logger et retourner une erreur g√©n√©rique
```

## üîß Utilitaires

### Logging

**Fichier :** `src/trip_parser/utils.py`

```python
from trip_parser.utils import setup_logging
import logging

# Configuration basique
setup_logging(level=logging.INFO)

# Configuration avec fichier
setup_logging(
    level=logging.DEBUG,
    log_file="logs/trip_parser.log"
)

# Utilisation
logger = logging.getLogger(__name__)
logger.info("Processing started")
logger.debug(f"Text: {text}")
logger.error(f"Error: {e}", exc_info=True)
```

### Formatage des r√©sultats

```python
from trip_parser.utils import format_trip_result

# Formatage pour affichage
result = format_trip_result("Paris", "Lyon")
print(result)  # ‚Üí "Paris ‚Üí Lyon"

result = format_trip_result("Paris", None)
print(result)  # ‚Üí "Paris ‚Üí ?"

result = format_trip_result(None, None)
print(result)  # ‚Üí "No trip information found"
```

## üìä Optimisations et bonnes pratiques

### Performance

**1. R√©utiliser l'instance TripParser**
```python
# ‚úÖ Bon : une seule instance
parser = TripParser()  # Charge les mod√®les une fois
for text in texts:
    result = parser.parse_trip(text)

# ‚ùå Mauvais : recharge √† chaque fois
for text in texts:
    parser = TripParser()  # 2-3s de chargement !
    result = parser.parse_trip(text)
```

**2. Utiliser GPU si disponible**
```python
import torch

if torch.cuda.is_available():
    print("GPU disponible, utilisation automatique")
else:
    print("CPU utilis√© (plus lent)")
```

**3. Batch processing pour gros volumes**
```python
# Traiter plusieurs phrases d'un coup
results = [parser.parse_trip(t) for t in texts]
```

### Qualit√©

**1. Ajouter des donn√©es d'entra√Ænement**
```json
// data/training_dataset.json
{
    "examples": [
    // Ajouter vos propres phrases probl√©matiques
    {
        "sentence": "Vol de Nantes vers Rennes",
        "departure": "Nantes",
        "arrival": "Rennes"
    }
    ]
}
```

**2. R√©entra√Æner r√©guli√®rement**
```bash
# Apr√®s avoir ajout√© des donn√©es
trip-train
```

**3. Valider les r√©sultats**
```python
departure, arrival = parser.parse_trip(text)

if not (departure and arrival):
    # Demander clarification √† l'utilisateur
    pass
```
