{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Projet interne de parsing de trajets Trip Extraction est un syst\u00e8me d'IA qui extrait automatiquement les villes de d\u00e9part et d'arriv\u00e9e \u00e0 partir de texte en fran\u00e7ais. Ce projet interne fournit une API REST et un module Python r\u00e9utilisable. \ud83c\udfaf Objectif Permettre l'extraction automatique d'informations de voyage structur\u00e9es \u00e0 partir de langage naturel en fran\u00e7ais. Entr\u00e9e : \"Je veux prendre le train de Paris \u00e0 Lyon\" Sortie : {\"departure\": \"Paris\", \"arrival\": \"Lyon\"} \u2728 Fonctionnalit\u00e9s cl\u00e9s Extraction intelligente : D\u00e9tecte les villes dans diverses formulations Classification contextuelle : Identifie automatiquement d\u00e9part vs arriv\u00e9e API REST : Exposition HTTP pour tous les langages de programmation Module Python : Int\u00e9gration directe dans le code Python Multi-syntaxe : G\u00e8re questions, syntaxe invers\u00e9e, contexte temporel \ud83d\ude80 D\u00e9marrage rapide Pour les d\u00e9veloppeurs qui rejoignent le projet # 1. Installation git clone <repo-url> && cd bootstrap python -m venv .venv && source .venv/bin/activate.fish pip install -e . && trip-train # 2. Lancer l'API trip-api # API accessible sur http://127.0.0.1:8000 # Documentation Swagger sur http://127.0.0.1:8000/docs Tester l'API curl -X POST http://127.0.0.1:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Train de Paris \u00e0 Lyon\"}' R\u00e9ponse : { \"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null } Pour utiliser le module Python directement from trip_parser import TripParser parser = TripParser() departure, arrival = parser.parse_trip(\"Je vais de Paris \u00e0 Lyon\") print(f\"{departure} \u2192 {arrival}\") # Paris \u2192 Lyon \ud83c\udfd7\ufe0f Architecture en bref \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Input \u2502 \"Je vais de Paris \u00e0 Lyon\" \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 TripParser \u2502 Orchestrateur principal \u2502 (trip_parser.py) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u251c\u2500\u2500\u25ba \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 NERExtractor \u2502 Extrait les villes \u2502 \u2502 (CamemBERT-NER) \u2502 [\"Paris\", \"Lyon\"] \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u25ba \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Classifier \u2502 Classifie d\u00e9part/arriv\u00e9e \u2502 (CamemBERT fine-tun\u00e9) \u2502 Paris=d\u00e9part, Lyon=arriv\u00e9e \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Output \u2502 (\"Paris\", \"Lyon\") \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Le syst\u00e8me utilise deux mod\u00e8les ML en s\u00e9quence : NERExtractor : D\u00e9tecte toutes les entit\u00e9s de type \"ville\" avec CamemBERT-NER Classifier : D\u00e9termine pour chaque ville si c'est un d\u00e9part ou une arriv\u00e9e Cette approche modulaire offre : - Meilleure pr\u00e9cision que des regex - Flexibilit\u00e9 (changement d'un mod\u00e8le sans toucher l'autre) - R\u00e9utilisation de mod\u00e8les pr\u00e9-entra\u00een\u00e9s de qualit\u00e9 \ud83d\udee0\ufe0f Technologies utilis\u00e9es Composant Technologie Usage API FastAPI + Uvicorn Serveur HTTP REST NER CamemBERT-NER Extraction d'entit\u00e9s nomm\u00e9es Classifier CamemBERT (fine-tun\u00e9) Classification d\u00e9part/arriv\u00e9e ML Framework Transformers + PyTorch Inf\u00e9rence des mod\u00e8les Validation Pydantic Validation de donn\u00e9es API \ud83d\udcca M\u00e9triques de performance Temps de chargement : 2-5 secondes (chargement initial des mod\u00e8les) Temps de r\u00e9ponse : 100-500ms par requ\u00eate (mod\u00e8les charg\u00e9s) M\u00e9moire requise : ~500 MB (mod\u00e8les en m\u00e9moire) Pr\u00e9cision : 90-95% sur des phrases courantes \ud83d\udcda Documentation Pour d\u00e9marrer Page Description Installation Guide d'installation complet avec pr\u00e9requis et troubleshooting Guide d'utilisation Exemples d'utilisation avec CLI, Python et API REST Documentation technique Page Description Architecture Structure du projet, patterns et pipeline de traitement Module Trip Parser D\u00e9tails du module d'extraction ML (mod\u00e8les, config, exceptions) API REST Documentation de l'API REST (endpoints, d\u00e9ploiement) R\u00e9f\u00e9rence API Documentation auto-g\u00e9n\u00e9r\u00e9e des classes et m\u00e9thodes Python \ud83d\udd17 Liens rapides En d\u00e9veloppement : - Swagger UI : http://127.0.0.1:8000/docs (quand l'API est lanc\u00e9e) - Code source : dossier src/ Commandes utiles : trip-api # Lancer l'API REST trip-demo # Interface CLI de test trip-train # Entra\u00eener le classifier","title":"Accueil"},{"location":"#objectif","text":"Permettre l'extraction automatique d'informations de voyage structur\u00e9es \u00e0 partir de langage naturel en fran\u00e7ais. Entr\u00e9e : \"Je veux prendre le train de Paris \u00e0 Lyon\" Sortie : {\"departure\": \"Paris\", \"arrival\": \"Lyon\"}","title":"\ud83c\udfaf Objectif"},{"location":"#fonctionnalites-cles","text":"Extraction intelligente : D\u00e9tecte les villes dans diverses formulations Classification contextuelle : Identifie automatiquement d\u00e9part vs arriv\u00e9e API REST : Exposition HTTP pour tous les langages de programmation Module Python : Int\u00e9gration directe dans le code Python Multi-syntaxe : G\u00e8re questions, syntaxe invers\u00e9e, contexte temporel","title":"\u2728 Fonctionnalit\u00e9s cl\u00e9s"},{"location":"#demarrage-rapide","text":"","title":"\ud83d\ude80 D\u00e9marrage rapide"},{"location":"#pour-les-developpeurs-qui-rejoignent-le-projet","text":"# 1. Installation git clone <repo-url> && cd bootstrap python -m venv .venv && source .venv/bin/activate.fish pip install -e . && trip-train # 2. Lancer l'API trip-api # API accessible sur http://127.0.0.1:8000 # Documentation Swagger sur http://127.0.0.1:8000/docs Tester l'API curl -X POST http://127.0.0.1:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Train de Paris \u00e0 Lyon\"}' R\u00e9ponse : { \"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null }","title":"Pour les d\u00e9veloppeurs qui rejoignent le projet"},{"location":"#pour-utiliser-le-module-python-directement","text":"from trip_parser import TripParser parser = TripParser() departure, arrival = parser.parse_trip(\"Je vais de Paris \u00e0 Lyon\") print(f\"{departure} \u2192 {arrival}\") # Paris \u2192 Lyon","title":"Pour utiliser le module Python directement"},{"location":"#architecture-en-bref","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Input \u2502 \"Je vais de Paris \u00e0 Lyon\" \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 TripParser \u2502 Orchestrateur principal \u2502 (trip_parser.py) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u251c\u2500\u2500\u25ba \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 NERExtractor \u2502 Extrait les villes \u2502 \u2502 (CamemBERT-NER) \u2502 [\"Paris\", \"Lyon\"] \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u25ba \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Classifier \u2502 Classifie d\u00e9part/arriv\u00e9e \u2502 (CamemBERT fine-tun\u00e9) \u2502 Paris=d\u00e9part, Lyon=arriv\u00e9e \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Output \u2502 (\"Paris\", \"Lyon\") \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Le syst\u00e8me utilise deux mod\u00e8les ML en s\u00e9quence : NERExtractor : D\u00e9tecte toutes les entit\u00e9s de type \"ville\" avec CamemBERT-NER Classifier : D\u00e9termine pour chaque ville si c'est un d\u00e9part ou une arriv\u00e9e Cette approche modulaire offre : - Meilleure pr\u00e9cision que des regex - Flexibilit\u00e9 (changement d'un mod\u00e8le sans toucher l'autre) - R\u00e9utilisation de mod\u00e8les pr\u00e9-entra\u00een\u00e9s de qualit\u00e9","title":"\ud83c\udfd7\ufe0f Architecture en bref"},{"location":"#technologies-utilisees","text":"Composant Technologie Usage API FastAPI + Uvicorn Serveur HTTP REST NER CamemBERT-NER Extraction d'entit\u00e9s nomm\u00e9es Classifier CamemBERT (fine-tun\u00e9) Classification d\u00e9part/arriv\u00e9e ML Framework Transformers + PyTorch Inf\u00e9rence des mod\u00e8les Validation Pydantic Validation de donn\u00e9es API","title":"\ud83d\udee0\ufe0f Technologies utilis\u00e9es"},{"location":"#metriques-de-performance","text":"Temps de chargement : 2-5 secondes (chargement initial des mod\u00e8les) Temps de r\u00e9ponse : 100-500ms par requ\u00eate (mod\u00e8les charg\u00e9s) M\u00e9moire requise : ~500 MB (mod\u00e8les en m\u00e9moire) Pr\u00e9cision : 90-95% sur des phrases courantes","title":"\ud83d\udcca M\u00e9triques de performance"},{"location":"#documentation","text":"","title":"\ud83d\udcda Documentation"},{"location":"#pour-demarrer","text":"Page Description Installation Guide d'installation complet avec pr\u00e9requis et troubleshooting Guide d'utilisation Exemples d'utilisation avec CLI, Python et API REST","title":"Pour d\u00e9marrer"},{"location":"#documentation-technique","text":"Page Description Architecture Structure du projet, patterns et pipeline de traitement Module Trip Parser D\u00e9tails du module d'extraction ML (mod\u00e8les, config, exceptions) API REST Documentation de l'API REST (endpoints, d\u00e9ploiement) R\u00e9f\u00e9rence API Documentation auto-g\u00e9n\u00e9r\u00e9e des classes et m\u00e9thodes Python","title":"Documentation technique"},{"location":"#liens-rapides","text":"En d\u00e9veloppement : - Swagger UI : http://127.0.0.1:8000/docs (quand l'API est lanc\u00e9e) - Code source : dossier src/ Commandes utiles : trip-api # Lancer l'API REST trip-demo # Interface CLI de test trip-train # Entra\u00eener le classifier","title":"\ud83d\udd17 Liens rapides"},{"location":"api-reference/","text":"Documentation auto-g\u00e9n\u00e9r\u00e9e Cette page contient la documentation technique compl\u00e8te de tous les modules Python du projet, g\u00e9n\u00e9r\u00e9e automatiquement \u00e0 partir des docstrings du code source. Cette r\u00e9f\u00e9rence API est destin\u00e9e aux d\u00e9veloppeurs qui souhaitent : Comprendre les signatures exactes des fonctions et m\u00e9thodes Conna\u00eetre les param\u00e8tres et valeurs de retour en d\u00e9tail Explorer les exceptions lev\u00e9es par chaque fonction Int\u00e9grer le module trip_parser dans leur propre code Module principal TripParser trip_parser.TripParser Parser for extracting trip information (departure and arrival) from text. Uses two specialized models: 1. NER model (CamemBERT) to identify locations (LOC entities) 2. Custom fine-tuned classifier to determine departure vs arrival This approach provides optimized, fast, and reliable trip extraction. __init__(ner_extractor: NERExtractor | None = None, classifier: DepartureArrivalClassifier | None = None) Initialize the trip parser. Parameters: Name Type Description Default ner_extractor NERExtractor | None NERExtractor instance. If None, creates a new one. None classifier DepartureArrivalClassifier | None DepartureArrivalClassifier instance. If None, creates a new one. None parse_trip(text: str) -> tuple[str | None, str | None] Parse trip information from text to extract departure and arrival cities. Uses specialized ML models to: 1. Extract location names using CamemBERT NER 2. Classify each location's role using custom fine-tuned classifier This optimized approach provides fast and reliable results. Parameters: Name Type Description Default text str Input text describing a trip in French. required Returns: Type Description str | None Tuple of (departure_city, arrival_city). Returns (None, None) if str | None not enough cities are detected or classification fails. Raises: Type Description InvalidInputError If text is None or empty. Examples: >>> parser = TripParser() >>> parser.parse_trip(\"Train de Paris \u00e0 Lyon\") ('Paris', 'Lyon') >>> parser.parse_trip(\"Je veux aller \u00e0 Lille depuis Paris\") ('Paris', 'Lille') Extracteurs et classifieurs NERExtractor trip_parser.models.NERExtractor Bases: BaseModel Named Entity Recognition extractor for French text using CamemBERT. This class wraps the CamemBERT NER model to extract named entities, particularly locations, from French text. Note: This class only handles location extraction (NER). Classification of departure/arrival is handled by DepartureArrivalClassifier. Attributes: Name Type Description model_name Name of the Hugging Face model used for NER. Examples: >>> extractor = NERExtractor() >>> locations = extractor.extract_locations(\"Je vais de Paris \u00e0 Lyon\") >>> print(locations) ['Paris', 'Lyon'] __init__(model_name: str | None = None) Initialize the NER extractor with a pre-trained model. Parameters: Name Type Description Default model_name str | None Name of the Hugging Face model to use for NER. Defaults to the value from config (Jean-Baptiste/camembert-ner). None Raises: Type Description ModelLoadError If the model cannot be loaded. InvalidInputError If model_name is empty. extract_entities(text: str) -> list[dict[str, any]] Extract all named entities from the given text. Parameters: Name Type Description Default text str Input text in French. required Returns: Type Description list [ dict [ str , any ]] List of entities with their type, text, and confidence score. list [ dict [ str , any ]] Each entity is a dict with keys: entity_group, word, score, start, end. Raises: Type Description InvalidInputError If text is empty or None. Examples: >>> extractor = NERExtractor() >>> entities = extractor.extract_entities(\"Paris est en France\") >>> print(entities) [{'entity_group': 'LOC', 'word': 'Paris', 'score': 0.99, ...}, ...] extract_locations(text: str) -> list[str] Extract location entities (cities, places) from text. Parameters: Name Type Description Default text str Input text in French. required Returns: Type Description list [ str ] List of location names found in the text, with compound list [ str ] locations split into individual cities. Raises: Type Description InvalidInputError If text is empty or None. Examples: >>> extractor = NERExtractor() >>> locations = extractor.extract_locations(\"Train de Paris \u00e0 Lyon\") >>> print(locations) ['Paris', 'Lyon'] DepartureArrivalClassifier trip_parser.models.DepartureArrivalClassifier Bases: BaseModel Custom classifier for identifying departure and arrival locations. This classifier uses a fine-tuned CamemBERT model trained specifically on travel sentence patterns to determine whether a location is a departure point or an arrival destination. The model is trained to classify locations marked with [LOC] tags in the context of the full sentence. Attributes: Name Type Description model_path Path to the fine-tuned model directory. device PyTorch device (cuda/cpu) used for inference. Examples: >>> classifier = DepartureArrivalClassifier() >>> role, conf = classifier.classify_location(\"Je vais de Paris \u00e0 Lyon\", \"Paris\") >>> print(f\"{role}: {conf:.2f}\") departure: 0.98 __init__(model_path: str | Path | None = None) Initialize the classifier. Parameters: Name Type Description Default model_path str | Path | None Path to the fine-tuned model directory. If None, uses the default path from config. None Raises: Type Description ModelNotFoundError If the model directory doesn't exist. ModelLoadError If the model cannot be loaded. classify_location(text: str, location: str, confidence_threshold: float | None = None) -> tuple[str, float] Classify whether a location is a departure or arrival point. Parameters: Name Type Description Default text str The full sentence context. required location str The location to classify. required confidence_threshold float | None Minimum confidence threshold (0-1). If None, uses value from config. None Returns: Type Description tuple [ str , float ] Tuple of (role, confidence) where: - role is 'departure', 'arrival', or 'unknown' - confidence is a float between 0 and 1 Raises: Type Description InvalidInputError If text or location is empty. Examples: >>> classifier = DepartureArrivalClassifier() >>> role, conf = classifier.classify_location(\"Je vais de Paris \u00e0 Lyon\", \"Paris\") >>> print(f\"{role}: {conf:.2f}\") departure: 0.98 >>> role, conf = classifier.classify_location(\"Je vais de Paris \u00e0 Lyon\", \"Lyon\") >>> print(f\"{role}: {conf:.2f}\") arrival: 0.97 classify_locations(text: str, locations: list[str]) -> tuple[str | None, str | None] Classify multiple locations and determine departure and arrival. Parameters: Name Type Description Default text str The full sentence context. required locations list [ str ] List of locations to classify. required Returns: Type Description str | None Tuple of (departure, arrival). Returns (None, None) if str | None locations cannot be classified. Raises: Type Description InvalidInputError If text is empty. InsufficientLocationsError If fewer than 2 locations provided. ClassificationError If classification fails and pattern should be added to training. Examples: >>> classifier = DepartureArrivalClassifier() >>> departure, arrival = classifier.classify_locations( ... \"Train de Paris \u00e0 Lyon\", ... [\"Paris\", \"Lyon\"] ... ) >>> print(f\"{departure} \u2192 {arrival}\") Paris \u2192 Lyon Configuration get_config trip_parser.config.get_config() -> Config Get the global configuration instance. Returns: Type Description Config The global Config object. Config trip_parser.config.Config dataclass Main configuration class that aggregates all settings. __post_init__() Ensure required directories exist. Paths trip_parser.config.Paths dataclass Centralized path configuration using absolute paths. models_dir: Path property Directory containing trained models. data_dir: Path property Directory containing datasets. logs_dir: Path property Directory for log files. departure_arrival_model: Path property Path to the departure-arrival classifier model. training_dataset: Path property Path to the training dataset. ensure_directories() Create necessary directories if they don't exist. ModelConfig trip_parser.config.ModelConfig dataclass Configuration for ML models. TrainingConfig trip_parser.config.TrainingConfig dataclass Configuration for model training. LoggingConfig trip_parser.config.LoggingConfig dataclass Configuration for logging. log_file: Path | None property Path to log file if logging to file is enabled. Exceptions Hi\u00e9rarchie des exceptions TripExtractionError (base) \u251c\u2500\u2500 ModelNotFoundError \u251c\u2500\u2500 ModelLoadError \u251c\u2500\u2500 InsufficientLocationsError \u251c\u2500\u2500 InvalidInputError \u251c\u2500\u2500 ClassificationError \u2514\u2500\u2500 TokenizationError Exceptions export\u00e9es Seules les exceptions principales sont export\u00e9es dans __init__.py . Toutes les exceptions ci-dessous sont disponibles via trip_parser.exceptions . TripExtractionError trip_parser.exceptions.TripExtractionError Bases: Exception Base exception for all trip extraction errors. ModelNotFoundError trip_parser.exceptions.ModelNotFoundError Bases: TripExtractionError Raised when a required model file cannot be found. InsufficientLocationsError trip_parser.exceptions.InsufficientLocationsError Bases: TripExtractionError Raised when not enough locations are detected in the input text. InvalidInputError trip_parser.exceptions.InvalidInputError Bases: TripExtractionError Raised when input validation fails. ClassificationError trip_parser.exceptions.ClassificationError Bases: TripExtractionError Raised when location classification fails. Utilitaires setup_logging trip_parser.utils.setup_logging(level: int | str | None = None, log_file: str | Path | None = None, force: bool = True) Configure logging for the application. Parameters: Name Type Description Default level int | str | None Logging level (e.g., logging.INFO, logging.DEBUG, \"INFO\", \"DEBUG\"). If None, uses level from config. None log_file str | Path | None Optional file path to write logs to. If None, uses config setting. None force bool If True, override existing logging configuration. True Examples: >>> setup_logging(level=\"DEBUG\") >>> setup_logging(level=logging.INFO, log_file=\"app.log\") format_trip_result trip_parser.utils.format_trip_result(departure: str | None, arrival: str | None) -> str Format trip extraction result for display. Parameters: Name Type Description Default departure str | None Departure city or None. required arrival str | None Arrival city or None. required Returns: Type Description str Formatted string representation of the trip. Notes d'utilisation Import des classes # Import principal from trip_parser import TripParser # Import des mod\u00e8les from trip_parser.models import NERExtractor, DepartureArrivalClassifier # Import de la configuration from trip_parser.config import get_config, Config # Import des exceptions from trip_parser.exceptions import ( TripExtractionError, ModelNotFoundError, InsufficientLocationsError, InvalidInputError ) Gestion des exceptions Toutes les exceptions h\u00e9ritent de TripExtractionError . Pour capturer toutes les erreurs du module : from trip_parser import TripParser from trip_parser.exceptions import TripExtractionError parser = TripParser() try: departure, arrival = parser.parse_trip(\"Je vais de Paris \u00e0 Lyon\") except TripExtractionError as e: print(f\"Erreur d'extraction : {e}\") Pour g\u00e9rer des exceptions sp\u00e9cifiques : from trip_parser.exceptions import ( InvalidInputError, InsufficientLocationsError, ModelNotFoundError ) try: departure, arrival = parser.parse_trip(user_input) except InvalidInputError: print(\"Le texte fourni est invalide\") except InsufficientLocationsError: print(\"Impossible de trouver 2 villes dans le texte\") except ModelNotFoundError: print(\"Les mod\u00e8les ne sont pas entra\u00een\u00e9s. Ex\u00e9cutez 'trip-train' d'abord\") Type hints Le module utilise les type hints modernes de Python 3.11+ : from trip_parser import TripParser parser = TripParser() # parse_trip retourne tuple[str | None, str | None] departure, arrival = parser.parse_trip(\"Paris Lyon\") # Types explicites departure: str | None arrival: str | None if departure is not None and arrival is not None: print(f\"{departure} \u2192 {arrival}\") else: print(\"Extraction partielle ou \u00e9chou\u00e9e\")","title":"R\u00e9f\u00e9rence API (Code)"},{"location":"api-reference/#module-principal","text":"","title":"Module principal"},{"location":"api-reference/#tripparser","text":"","title":"TripParser"},{"location":"api-reference/#trip_parser.TripParser","text":"Parser for extracting trip information (departure and arrival) from text. Uses two specialized models: 1. NER model (CamemBERT) to identify locations (LOC entities) 2. Custom fine-tuned classifier to determine departure vs arrival This approach provides optimized, fast, and reliable trip extraction.","title":"TripParser"},{"location":"api-reference/#trip_parser.TripParser.__init__","text":"Initialize the trip parser. Parameters: Name Type Description Default ner_extractor NERExtractor | None NERExtractor instance. If None, creates a new one. None classifier DepartureArrivalClassifier | None DepartureArrivalClassifier instance. If None, creates a new one. None","title":"__init__"},{"location":"api-reference/#trip_parser.TripParser.parse_trip","text":"Parse trip information from text to extract departure and arrival cities. Uses specialized ML models to: 1. Extract location names using CamemBERT NER 2. Classify each location's role using custom fine-tuned classifier This optimized approach provides fast and reliable results. Parameters: Name Type Description Default text str Input text describing a trip in French. required Returns: Type Description str | None Tuple of (departure_city, arrival_city). Returns (None, None) if str | None not enough cities are detected or classification fails. Raises: Type Description InvalidInputError If text is None or empty. Examples: >>> parser = TripParser() >>> parser.parse_trip(\"Train de Paris \u00e0 Lyon\") ('Paris', 'Lyon') >>> parser.parse_trip(\"Je veux aller \u00e0 Lille depuis Paris\") ('Paris', 'Lille')","title":"parse_trip"},{"location":"api-reference/#extracteurs-et-classifieurs","text":"","title":"Extracteurs et classifieurs"},{"location":"api-reference/#nerextractor","text":"","title":"NERExtractor"},{"location":"api-reference/#trip_parser.models.NERExtractor","text":"Bases: BaseModel Named Entity Recognition extractor for French text using CamemBERT. This class wraps the CamemBERT NER model to extract named entities, particularly locations, from French text. Note: This class only handles location extraction (NER). Classification of departure/arrival is handled by DepartureArrivalClassifier. Attributes: Name Type Description model_name Name of the Hugging Face model used for NER. Examples: >>> extractor = NERExtractor() >>> locations = extractor.extract_locations(\"Je vais de Paris \u00e0 Lyon\") >>> print(locations) ['Paris', 'Lyon']","title":"NERExtractor"},{"location":"api-reference/#trip_parser.models.NERExtractor.__init__","text":"Initialize the NER extractor with a pre-trained model. Parameters: Name Type Description Default model_name str | None Name of the Hugging Face model to use for NER. Defaults to the value from config (Jean-Baptiste/camembert-ner). None Raises: Type Description ModelLoadError If the model cannot be loaded. InvalidInputError If model_name is empty.","title":"__init__"},{"location":"api-reference/#trip_parser.models.NERExtractor.extract_entities","text":"Extract all named entities from the given text. Parameters: Name Type Description Default text str Input text in French. required Returns: Type Description list [ dict [ str , any ]] List of entities with their type, text, and confidence score. list [ dict [ str , any ]] Each entity is a dict with keys: entity_group, word, score, start, end. Raises: Type Description InvalidInputError If text is empty or None. Examples: >>> extractor = NERExtractor() >>> entities = extractor.extract_entities(\"Paris est en France\") >>> print(entities) [{'entity_group': 'LOC', 'word': 'Paris', 'score': 0.99, ...}, ...]","title":"extract_entities"},{"location":"api-reference/#trip_parser.models.NERExtractor.extract_locations","text":"Extract location entities (cities, places) from text. Parameters: Name Type Description Default text str Input text in French. required Returns: Type Description list [ str ] List of location names found in the text, with compound list [ str ] locations split into individual cities. Raises: Type Description InvalidInputError If text is empty or None. Examples: >>> extractor = NERExtractor() >>> locations = extractor.extract_locations(\"Train de Paris \u00e0 Lyon\") >>> print(locations) ['Paris', 'Lyon']","title":"extract_locations"},{"location":"api-reference/#departurearrivalclassifier","text":"","title":"DepartureArrivalClassifier"},{"location":"api-reference/#trip_parser.models.DepartureArrivalClassifier","text":"Bases: BaseModel Custom classifier for identifying departure and arrival locations. This classifier uses a fine-tuned CamemBERT model trained specifically on travel sentence patterns to determine whether a location is a departure point or an arrival destination. The model is trained to classify locations marked with [LOC] tags in the context of the full sentence. Attributes: Name Type Description model_path Path to the fine-tuned model directory. device PyTorch device (cuda/cpu) used for inference. Examples: >>> classifier = DepartureArrivalClassifier() >>> role, conf = classifier.classify_location(\"Je vais de Paris \u00e0 Lyon\", \"Paris\") >>> print(f\"{role}: {conf:.2f}\") departure: 0.98","title":"DepartureArrivalClassifier"},{"location":"api-reference/#trip_parser.models.DepartureArrivalClassifier.__init__","text":"Initialize the classifier. Parameters: Name Type Description Default model_path str | Path | None Path to the fine-tuned model directory. If None, uses the default path from config. None Raises: Type Description ModelNotFoundError If the model directory doesn't exist. ModelLoadError If the model cannot be loaded.","title":"__init__"},{"location":"api-reference/#trip_parser.models.DepartureArrivalClassifier.classify_location","text":"Classify whether a location is a departure or arrival point. Parameters: Name Type Description Default text str The full sentence context. required location str The location to classify. required confidence_threshold float | None Minimum confidence threshold (0-1). If None, uses value from config. None Returns: Type Description tuple [ str , float ] Tuple of (role, confidence) where: - role is 'departure', 'arrival', or 'unknown' - confidence is a float between 0 and 1 Raises: Type Description InvalidInputError If text or location is empty. Examples: >>> classifier = DepartureArrivalClassifier() >>> role, conf = classifier.classify_location(\"Je vais de Paris \u00e0 Lyon\", \"Paris\") >>> print(f\"{role}: {conf:.2f}\") departure: 0.98 >>> role, conf = classifier.classify_location(\"Je vais de Paris \u00e0 Lyon\", \"Lyon\") >>> print(f\"{role}: {conf:.2f}\") arrival: 0.97","title":"classify_location"},{"location":"api-reference/#trip_parser.models.DepartureArrivalClassifier.classify_locations","text":"Classify multiple locations and determine departure and arrival. Parameters: Name Type Description Default text str The full sentence context. required locations list [ str ] List of locations to classify. required Returns: Type Description str | None Tuple of (departure, arrival). Returns (None, None) if str | None locations cannot be classified. Raises: Type Description InvalidInputError If text is empty. InsufficientLocationsError If fewer than 2 locations provided. ClassificationError If classification fails and pattern should be added to training. Examples: >>> classifier = DepartureArrivalClassifier() >>> departure, arrival = classifier.classify_locations( ... \"Train de Paris \u00e0 Lyon\", ... [\"Paris\", \"Lyon\"] ... ) >>> print(f\"{departure} \u2192 {arrival}\") Paris \u2192 Lyon","title":"classify_locations"},{"location":"api-reference/#configuration","text":"","title":"Configuration"},{"location":"api-reference/#get_config","text":"","title":"get_config"},{"location":"api-reference/#trip_parser.config.get_config","text":"Get the global configuration instance. Returns: Type Description Config The global Config object.","title":"get_config"},{"location":"api-reference/#config","text":"","title":"Config"},{"location":"api-reference/#trip_parser.config.Config","text":"Main configuration class that aggregates all settings.","title":"Config"},{"location":"api-reference/#trip_parser.config.Config.__post_init__","text":"Ensure required directories exist.","title":"__post_init__"},{"location":"api-reference/#paths","text":"","title":"Paths"},{"location":"api-reference/#trip_parser.config.Paths","text":"Centralized path configuration using absolute paths.","title":"Paths"},{"location":"api-reference/#trip_parser.config.Paths.models_dir","text":"Directory containing trained models.","title":"models_dir"},{"location":"api-reference/#trip_parser.config.Paths.data_dir","text":"Directory containing datasets.","title":"data_dir"},{"location":"api-reference/#trip_parser.config.Paths.logs_dir","text":"Directory for log files.","title":"logs_dir"},{"location":"api-reference/#trip_parser.config.Paths.departure_arrival_model","text":"Path to the departure-arrival classifier model.","title":"departure_arrival_model"},{"location":"api-reference/#trip_parser.config.Paths.training_dataset","text":"Path to the training dataset.","title":"training_dataset"},{"location":"api-reference/#trip_parser.config.Paths.ensure_directories","text":"Create necessary directories if they don't exist.","title":"ensure_directories"},{"location":"api-reference/#modelconfig","text":"","title":"ModelConfig"},{"location":"api-reference/#trip_parser.config.ModelConfig","text":"Configuration for ML models.","title":"ModelConfig"},{"location":"api-reference/#trainingconfig","text":"","title":"TrainingConfig"},{"location":"api-reference/#trip_parser.config.TrainingConfig","text":"Configuration for model training.","title":"TrainingConfig"},{"location":"api-reference/#loggingconfig","text":"","title":"LoggingConfig"},{"location":"api-reference/#trip_parser.config.LoggingConfig","text":"Configuration for logging.","title":"LoggingConfig"},{"location":"api-reference/#trip_parser.config.LoggingConfig.log_file","text":"Path to log file if logging to file is enabled.","title":"log_file"},{"location":"api-reference/#exceptions","text":"","title":"Exceptions"},{"location":"api-reference/#hierarchie-des-exceptions","text":"TripExtractionError (base) \u251c\u2500\u2500 ModelNotFoundError \u251c\u2500\u2500 ModelLoadError \u251c\u2500\u2500 InsufficientLocationsError \u251c\u2500\u2500 InvalidInputError \u251c\u2500\u2500 ClassificationError \u2514\u2500\u2500 TokenizationError Exceptions export\u00e9es Seules les exceptions principales sont export\u00e9es dans __init__.py . Toutes les exceptions ci-dessous sont disponibles via trip_parser.exceptions .","title":"Hi\u00e9rarchie des exceptions"},{"location":"api-reference/#tripextractionerror","text":"","title":"TripExtractionError"},{"location":"api-reference/#trip_parser.exceptions.TripExtractionError","text":"Bases: Exception Base exception for all trip extraction errors.","title":"TripExtractionError"},{"location":"api-reference/#modelnotfounderror","text":"","title":"ModelNotFoundError"},{"location":"api-reference/#trip_parser.exceptions.ModelNotFoundError","text":"Bases: TripExtractionError Raised when a required model file cannot be found.","title":"ModelNotFoundError"},{"location":"api-reference/#insufficientlocationserror","text":"","title":"InsufficientLocationsError"},{"location":"api-reference/#trip_parser.exceptions.InsufficientLocationsError","text":"Bases: TripExtractionError Raised when not enough locations are detected in the input text.","title":"InsufficientLocationsError"},{"location":"api-reference/#invalidinputerror","text":"","title":"InvalidInputError"},{"location":"api-reference/#trip_parser.exceptions.InvalidInputError","text":"Bases: TripExtractionError Raised when input validation fails.","title":"InvalidInputError"},{"location":"api-reference/#classificationerror","text":"","title":"ClassificationError"},{"location":"api-reference/#trip_parser.exceptions.ClassificationError","text":"Bases: TripExtractionError Raised when location classification fails.","title":"ClassificationError"},{"location":"api-reference/#utilitaires","text":"","title":"Utilitaires"},{"location":"api-reference/#setup_logging","text":"","title":"setup_logging"},{"location":"api-reference/#trip_parser.utils.setup_logging","text":"Configure logging for the application. Parameters: Name Type Description Default level int | str | None Logging level (e.g., logging.INFO, logging.DEBUG, \"INFO\", \"DEBUG\"). If None, uses level from config. None log_file str | Path | None Optional file path to write logs to. If None, uses config setting. None force bool If True, override existing logging configuration. True Examples: >>> setup_logging(level=\"DEBUG\") >>> setup_logging(level=logging.INFO, log_file=\"app.log\")","title":"setup_logging"},{"location":"api-reference/#format_trip_result","text":"","title":"format_trip_result"},{"location":"api-reference/#trip_parser.utils.format_trip_result","text":"Format trip extraction result for display. Parameters: Name Type Description Default departure str | None Departure city or None. required arrival str | None Arrival city or None. required Returns: Type Description str Formatted string representation of the trip.","title":"format_trip_result"},{"location":"api-reference/#notes-dutilisation","text":"","title":"Notes d'utilisation"},{"location":"api-reference/#import-des-classes","text":"# Import principal from trip_parser import TripParser # Import des mod\u00e8les from trip_parser.models import NERExtractor, DepartureArrivalClassifier # Import de la configuration from trip_parser.config import get_config, Config # Import des exceptions from trip_parser.exceptions import ( TripExtractionError, ModelNotFoundError, InsufficientLocationsError, InvalidInputError )","title":"Import des classes"},{"location":"api-reference/#gestion-des-exceptions","text":"Toutes les exceptions h\u00e9ritent de TripExtractionError . Pour capturer toutes les erreurs du module : from trip_parser import TripParser from trip_parser.exceptions import TripExtractionError parser = TripParser() try: departure, arrival = parser.parse_trip(\"Je vais de Paris \u00e0 Lyon\") except TripExtractionError as e: print(f\"Erreur d'extraction : {e}\") Pour g\u00e9rer des exceptions sp\u00e9cifiques : from trip_parser.exceptions import ( InvalidInputError, InsufficientLocationsError, ModelNotFoundError ) try: departure, arrival = parser.parse_trip(user_input) except InvalidInputError: print(\"Le texte fourni est invalide\") except InsufficientLocationsError: print(\"Impossible de trouver 2 villes dans le texte\") except ModelNotFoundError: print(\"Les mod\u00e8les ne sont pas entra\u00een\u00e9s. Ex\u00e9cutez 'trip-train' d'abord\")","title":"Gestion des exceptions"},{"location":"api-reference/#type-hints","text":"Le module utilise les type hints modernes de Python 3.11+ : from trip_parser import TripParser parser = TripParser() # parse_trip retourne tuple[str | None, str | None] departure, arrival = parser.parse_trip(\"Paris Lyon\") # Types explicites departure: str | None arrival: str | None if departure is not None and arrival is not None: print(f\"{departure} \u2192 {arrival}\") else: print(\"Extraction partielle ou \u00e9chou\u00e9e\")","title":"Type hints"},{"location":"api-rest/","text":"Documentation compl\u00e8te de l'API REST Trip Extraction. Cette API expose le module trip_parser via HTTP pour permettre l'int\u00e9gration dans n'importe quel langage ou framework. \ud83c\udf10 Vue d'ensemble URL de base D\u00e9veloppement http://127.0.0.1:8000 Production https://your-domain.com Caract\u00e9ristiques Framework : FastAPI 0.109.0+ Serveur : Uvicorn (ASGI) Documentation : Swagger UI automatique Validation : Pydantic 2.5.0+ CORS : Activ\u00e9 (configurable) Endpoints disponibles Endpoint M\u00e9thode Description Auth /health GET V\u00e9rifier l'\u00e9tat de l'API Non /trip/status GET \u00c9tat des mod\u00e8les ML Non /trip/parse POST Extraire d\u00e9part et arriv\u00e9e Non /docs GET Documentation Swagger UI Non /openapi.json GET Sp\u00e9cification OpenAPI Non \ud83d\ude80 D\u00e9marrage du serveur Commande de base trip-api Sortie attendue : INFO: Starting Trip Parser API... INFO: Preloading models... INFO: Models preloaded successfully INFO: Trip Parser API ready INFO: Started server process [12345] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit) Options de configuration Port personnalis\u00e9 trip-api --port 8080 # API accessible sur http://127.0.0.1:8080 Host personnalis\u00e9 # \u00c9couter sur toutes les interfaces (pour docker/production) trip-api --host 0.0.0.0 --port 8000 # API accessible depuis l'ext\u00e9rieur Mode d\u00e9veloppement # Rechargement automatique \u00e0 chaque modification trip-api --reload # Utile pendant le d\u00e9veloppement Production (multi-workers) # Lancer 4 workers pour g\u00e9rer plus de requ\u00eates trip-api --host 0.0.0.0 --port 8000 --workers 4 # Chaque worker a sa propre instance du mod\u00e8le Script de lancement Fichier : scripts/run_api.py #!/usr/bin/env python3 \"\"\"Script de lancement de l'API Trip Parser.\"\"\" import argparse import uvicorn def main(): parser = argparse.ArgumentParser(description=\"Run Trip Parser API\") parser.add_argument(\"--host\", default=\"127.0.0.1\", help=\"Host to bind\") parser.add_argument(\"--port\", type=int, default=8000, help=\"Port to bind\") parser.add_argument(\"--reload\", action=\"store_true\", help=\"Enable auto-reload\") parser.add_argument(\"--workers\", type=int, default=1, help=\"Number of workers\") args = parser.parse_args() uvicorn.run( \"api.main:app\", host=args.host, port=args.port, reload=args.reload, workers=args.workers ) if __name__ == \"__main__\": main() \ud83d\udcbb Exemples d'int\u00e9gration cURL Basique curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' Avec jq (formatage) curl -s -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' | jq Sortie format\u00e9e : { \"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null } Batch avec boucle # Fichier phrases.txt contenant une phrase par ligne while IFS= read -r phrase; do echo \"Processing: $phrase\" curl -s -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d \"{\\\"text\\\": \\\"$phrase\\\"}\" | jq -r '\"\\(.departure) \u2192 \\(.arrival)\"' done < phrases.txt Python (requests) Basique import requests API_URL = \"http://localhost:8000\" def parse_trip(text: str): \"\"\"Appelle l'API pour extraire un trajet.\"\"\" response = requests.post( f\"{API_URL}/trip/parse\", json={\"text\": text} ) response.raise_for_status() return response.json() # Utilisation result = parse_trip(\"Je vais de Paris \u00e0 Lyon\") print(f\"D\u00e9part: {result['departure']}\") print(f\"Arriv\u00e9e: {result['arrival']}\") Avec gestion d'erreurs import requests from typing import Dict, Optional class TripParserAPI: \"\"\"Client Python pour l'API Trip Parser.\"\"\" def __init__(self, base_url: str = \"http://localhost:8000\"): self.base_url = base_url def parse_trip(self, text: str) -> Dict: \"\"\" Parse un trajet depuis du texte. Returns: Dict avec departure, arrival, success, message Raises: requests.HTTPError: Si erreur HTTP \"\"\" try: response = requests.post( f\"{self.base_url}/trip/parse\", json={\"text\": text}, timeout=10 ) response.raise_for_status() return response.json() except requests.HTTPError as e: if e.response.status_code == 422: # Erreur de validation detail = e.response.json()[\"detail\"] raise ValueError(f\"Validation error: {detail}\") elif e.response.status_code == 500: # Erreur serveur detail = e.response.json()[\"detail\"] raise RuntimeError(f\"Server error: {detail}\") else: raise def is_healthy(self) -> bool: \"\"\"V\u00e9rifie si l'API est en ligne.\"\"\" try: response = requests.get(f\"{self.base_url}/health\", timeout=5) return response.status_code == 200 except: return False def is_ready(self) -> bool: \"\"\"V\u00e9rifie si les mod\u00e8les sont charg\u00e9s.\"\"\" try: response = requests.get(f\"{self.base_url}/trip/status\", timeout=5) data = response.json() return data.get(\"ready\", False) except: return False # Utilisation api = TripParserAPI() if not api.is_healthy(): print(\"\u274c API non accessible\") exit(1) if not api.is_ready(): print(\"\u26a0\ufe0f Mod\u00e8les non charg\u00e9s, attendre...\") try: result = api.parse_trip(\"Je vais de Paris \u00e0 Lyon\") if result[\"success\"]: print(f\"\u2705 {result['departure']} \u2192 {result['arrival']}\") else: print(f\"\u26a0\ufe0f Extraction \u00e9chou\u00e9e: {result['message']}\") except ValueError as e: print(f\"\u274c Erreur de validation: {e}\") except RuntimeError as e: print(f\"\u274c Erreur serveur: {e}\") Asynchrone (aiohttp) import aiohttp import asyncio from typing import List, Dict async def parse_trip_async(session: aiohttp.ClientSession, text: str) -> Dict: \"\"\"Parse un trajet de mani\u00e8re asynchrone.\"\"\" async with session.post( \"http://localhost:8000/trip/parse\", json={\"text\": text} ) as response: response.raise_for_status() return await response.json() async def batch_parse(texts: List[str]) -> List[Dict]: \"\"\"Parse plusieurs trajets en parall\u00e8le.\"\"\" async with aiohttp.ClientSession() as session: tasks = [parse_trip_async(session, text) for text in texts] return await asyncio.gather(*tasks) # Utilisation texts = [ \"Je vais de Paris \u00e0 Lyon\", \"Train de Marseille \u00e0 Nice\", \"Vol Toulouse Bordeaux\" ] results = asyncio.run(batch_parse(texts)) for result in results: print(f\"{result['departure']} \u2192 {result['arrival']}\") JavaScript (Node.js) fetch (Node 18+) // Fonction pour parser un trajet async function parseTrip(text) { const response = await fetch('http://localhost:8000/trip/parse', { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify({ text: text }) }); if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return await response.json(); } // Utilisation parseTrip(\"Je vais de Paris \u00e0 Lyon\") .then(result => { console.log(`D\u00e9part: ${result.departure}`); console.log(`Arriv\u00e9e: ${result.arrival}`); }) .catch(error => { console.error('Erreur:', error); }); axios const axios = require('axios'); class TripParserAPI { constructor(baseURL = 'http://localhost:8000') { this.client = axios.create({ baseURL: baseURL, timeout: 10000, headers: { 'Content-Type': 'application/json' } }); } async parseTrip(text) { try { const response = await this.client.post('/trip/parse', { text: text }); return response.data; } catch (error) { if (error.response) { // Erreur HTTP (422, 500...) throw new Error( `API Error ${error.response.status}: ${ JSON.stringify(error.response.data) }` ); } else if (error.request) { // Pas de r\u00e9ponse throw new Error('No response from server'); } else { // Autre erreur throw error; } } } async isHealthy() { try { const response = await this.client.get('/health'); return response.status === 200; } catch { return false; } } } // Utilisation const api = new TripParserAPI(); (async () => { try { const result = await api.parseTrip(\"Je vais de Paris \u00e0 Lyon\"); if (result.success) { console.log(`\u2705 ${result.departure} \u2192 ${result.arrival}`); } else { console.log(`\u26a0\ufe0f ${result.message}`); } } catch (error) { console.error('\u274c Erreur:', error.message); } })(); \ud83d\udd12 S\u00e9curit\u00e9 et production CORS La configuration actuelle autorise toutes les origines (mode d\u00e9veloppement). Fichier : src/api/main.py # Configuration actuelle (DEV) app.add_middleware( CORSMiddleware, allow_origins=[\"*\"], # \u26a0\ufe0f Toutes les origines allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"], ) # Configuration recommand\u00e9e (PROD) app.add_middleware( CORSMiddleware, allow_origins=[ \"https://your-domain.com\", \"https://app.your-domain.com\" ], allow_credentials=True, allow_methods=[\"POST\", \"GET\"], allow_headers=[\"Content-Type\"], ) Rate limiting L'API actuelle n'a pas de rate limiting. Recommandations : # Utiliser slowapi from slowapi import Limiter from slowapi.util import get_remote_address limiter = Limiter(key_func=get_remote_address) app.state.limiter = limiter @app.post(\"/trip/parse\") @limiter.limit(\"10/minute\") # Max 10 requ\u00eates par minute async def parse_trip(request: Request, ...): ... Validation et sanitization Les entr\u00e9es sont d\u00e9j\u00e0 valid\u00e9es par Pydantic : Longueur min/max Type string Pas de whitespace seul Monitoring 1. Logging structur\u00e9 import logging import json logger = logging.getLogger(__name__) @app.post(\"/trip/parse\") async def parse_trip(request: TripParseRequest): logger.info(json.dumps({ \"event\": \"parse_request\", \"text_length\": len(request.text), \"timestamp\": datetime.now().isoformat() })) 2. M\u00e9triques (Prometheus) from prometheus_client import Counter, Histogram requests_total = Counter('trip_parse_requests_total', 'Total requests') request_duration = Histogram('trip_parse_duration_seconds', 'Request duration') \ud83d\udcd6 Documentation interactive Swagger UI Une fois l'API lanc\u00e9e, acc\u00e9dez \u00e0 : http://127.0.0.1:8000/docs Fonctionnalit\u00e9s : \ud83d\udcdd Tester tous les endpoints directement depuis le navigateur \ud83d\udcc4 Voir les sch\u00e9mas d\u00e9taill\u00e9s de requ\u00eate/r\u00e9ponse \ud83d\udca1 Exemples de code dans plusieurs langages \u2b07\ufe0f T\u00e9l\u00e9charger la sp\u00e9cification OpenAPI OpenAPI Spec La sp\u00e9cification compl\u00e8te est disponible \u00e0 : http://127.0.0.1:8000/openapi.json Utilisable avec des outils comme : Postman (import OpenAPI) Insomnia API clients auto-g\u00e9n\u00e9r\u00e9s","title":"API REST"},{"location":"api-rest/#vue-densemble","text":"","title":"\ud83c\udf10 Vue d'ensemble"},{"location":"api-rest/#url-de-base","text":"D\u00e9veloppement http://127.0.0.1:8000 Production https://your-domain.com","title":"URL de base"},{"location":"api-rest/#caracteristiques","text":"Framework : FastAPI 0.109.0+ Serveur : Uvicorn (ASGI) Documentation : Swagger UI automatique Validation : Pydantic 2.5.0+ CORS : Activ\u00e9 (configurable)","title":"Caract\u00e9ristiques"},{"location":"api-rest/#endpoints-disponibles","text":"Endpoint M\u00e9thode Description Auth /health GET V\u00e9rifier l'\u00e9tat de l'API Non /trip/status GET \u00c9tat des mod\u00e8les ML Non /trip/parse POST Extraire d\u00e9part et arriv\u00e9e Non /docs GET Documentation Swagger UI Non /openapi.json GET Sp\u00e9cification OpenAPI Non","title":"Endpoints disponibles"},{"location":"api-rest/#demarrage-du-serveur","text":"","title":"\ud83d\ude80 D\u00e9marrage du serveur"},{"location":"api-rest/#commande-de-base","text":"trip-api Sortie attendue : INFO: Starting Trip Parser API... INFO: Preloading models... INFO: Models preloaded successfully INFO: Trip Parser API ready INFO: Started server process [12345] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)","title":"Commande de base"},{"location":"api-rest/#options-de-configuration","text":"Port personnalis\u00e9 trip-api --port 8080 # API accessible sur http://127.0.0.1:8080 Host personnalis\u00e9 # \u00c9couter sur toutes les interfaces (pour docker/production) trip-api --host 0.0.0.0 --port 8000 # API accessible depuis l'ext\u00e9rieur Mode d\u00e9veloppement # Rechargement automatique \u00e0 chaque modification trip-api --reload # Utile pendant le d\u00e9veloppement Production (multi-workers) # Lancer 4 workers pour g\u00e9rer plus de requ\u00eates trip-api --host 0.0.0.0 --port 8000 --workers 4 # Chaque worker a sa propre instance du mod\u00e8le","title":"Options de configuration"},{"location":"api-rest/#script-de-lancement","text":"Fichier : scripts/run_api.py #!/usr/bin/env python3 \"\"\"Script de lancement de l'API Trip Parser.\"\"\" import argparse import uvicorn def main(): parser = argparse.ArgumentParser(description=\"Run Trip Parser API\") parser.add_argument(\"--host\", default=\"127.0.0.1\", help=\"Host to bind\") parser.add_argument(\"--port\", type=int, default=8000, help=\"Port to bind\") parser.add_argument(\"--reload\", action=\"store_true\", help=\"Enable auto-reload\") parser.add_argument(\"--workers\", type=int, default=1, help=\"Number of workers\") args = parser.parse_args() uvicorn.run( \"api.main:app\", host=args.host, port=args.port, reload=args.reload, workers=args.workers ) if __name__ == \"__main__\": main()","title":"Script de lancement"},{"location":"api-rest/#exemples-dintegration","text":"","title":"\ud83d\udcbb Exemples d'int\u00e9gration"},{"location":"api-rest/#curl","text":"Basique curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' Avec jq (formatage) curl -s -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' | jq Sortie format\u00e9e : { \"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null } Batch avec boucle # Fichier phrases.txt contenant une phrase par ligne while IFS= read -r phrase; do echo \"Processing: $phrase\" curl -s -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d \"{\\\"text\\\": \\\"$phrase\\\"}\" | jq -r '\"\\(.departure) \u2192 \\(.arrival)\"' done < phrases.txt","title":"cURL"},{"location":"api-rest/#python-requests","text":"Basique import requests API_URL = \"http://localhost:8000\" def parse_trip(text: str): \"\"\"Appelle l'API pour extraire un trajet.\"\"\" response = requests.post( f\"{API_URL}/trip/parse\", json={\"text\": text} ) response.raise_for_status() return response.json() # Utilisation result = parse_trip(\"Je vais de Paris \u00e0 Lyon\") print(f\"D\u00e9part: {result['departure']}\") print(f\"Arriv\u00e9e: {result['arrival']}\") Avec gestion d'erreurs import requests from typing import Dict, Optional class TripParserAPI: \"\"\"Client Python pour l'API Trip Parser.\"\"\" def __init__(self, base_url: str = \"http://localhost:8000\"): self.base_url = base_url def parse_trip(self, text: str) -> Dict: \"\"\" Parse un trajet depuis du texte. Returns: Dict avec departure, arrival, success, message Raises: requests.HTTPError: Si erreur HTTP \"\"\" try: response = requests.post( f\"{self.base_url}/trip/parse\", json={\"text\": text}, timeout=10 ) response.raise_for_status() return response.json() except requests.HTTPError as e: if e.response.status_code == 422: # Erreur de validation detail = e.response.json()[\"detail\"] raise ValueError(f\"Validation error: {detail}\") elif e.response.status_code == 500: # Erreur serveur detail = e.response.json()[\"detail\"] raise RuntimeError(f\"Server error: {detail}\") else: raise def is_healthy(self) -> bool: \"\"\"V\u00e9rifie si l'API est en ligne.\"\"\" try: response = requests.get(f\"{self.base_url}/health\", timeout=5) return response.status_code == 200 except: return False def is_ready(self) -> bool: \"\"\"V\u00e9rifie si les mod\u00e8les sont charg\u00e9s.\"\"\" try: response = requests.get(f\"{self.base_url}/trip/status\", timeout=5) data = response.json() return data.get(\"ready\", False) except: return False # Utilisation api = TripParserAPI() if not api.is_healthy(): print(\"\u274c API non accessible\") exit(1) if not api.is_ready(): print(\"\u26a0\ufe0f Mod\u00e8les non charg\u00e9s, attendre...\") try: result = api.parse_trip(\"Je vais de Paris \u00e0 Lyon\") if result[\"success\"]: print(f\"\u2705 {result['departure']} \u2192 {result['arrival']}\") else: print(f\"\u26a0\ufe0f Extraction \u00e9chou\u00e9e: {result['message']}\") except ValueError as e: print(f\"\u274c Erreur de validation: {e}\") except RuntimeError as e: print(f\"\u274c Erreur serveur: {e}\") Asynchrone (aiohttp) import aiohttp import asyncio from typing import List, Dict async def parse_trip_async(session: aiohttp.ClientSession, text: str) -> Dict: \"\"\"Parse un trajet de mani\u00e8re asynchrone.\"\"\" async with session.post( \"http://localhost:8000/trip/parse\", json={\"text\": text} ) as response: response.raise_for_status() return await response.json() async def batch_parse(texts: List[str]) -> List[Dict]: \"\"\"Parse plusieurs trajets en parall\u00e8le.\"\"\" async with aiohttp.ClientSession() as session: tasks = [parse_trip_async(session, text) for text in texts] return await asyncio.gather(*tasks) # Utilisation texts = [ \"Je vais de Paris \u00e0 Lyon\", \"Train de Marseille \u00e0 Nice\", \"Vol Toulouse Bordeaux\" ] results = asyncio.run(batch_parse(texts)) for result in results: print(f\"{result['departure']} \u2192 {result['arrival']}\")","title":"Python (requests)"},{"location":"api-rest/#javascript-nodejs","text":"fetch (Node 18+) // Fonction pour parser un trajet async function parseTrip(text) { const response = await fetch('http://localhost:8000/trip/parse', { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify({ text: text }) }); if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return await response.json(); } // Utilisation parseTrip(\"Je vais de Paris \u00e0 Lyon\") .then(result => { console.log(`D\u00e9part: ${result.departure}`); console.log(`Arriv\u00e9e: ${result.arrival}`); }) .catch(error => { console.error('Erreur:', error); }); axios const axios = require('axios'); class TripParserAPI { constructor(baseURL = 'http://localhost:8000') { this.client = axios.create({ baseURL: baseURL, timeout: 10000, headers: { 'Content-Type': 'application/json' } }); } async parseTrip(text) { try { const response = await this.client.post('/trip/parse', { text: text }); return response.data; } catch (error) { if (error.response) { // Erreur HTTP (422, 500...) throw new Error( `API Error ${error.response.status}: ${ JSON.stringify(error.response.data) }` ); } else if (error.request) { // Pas de r\u00e9ponse throw new Error('No response from server'); } else { // Autre erreur throw error; } } } async isHealthy() { try { const response = await this.client.get('/health'); return response.status === 200; } catch { return false; } } } // Utilisation const api = new TripParserAPI(); (async () => { try { const result = await api.parseTrip(\"Je vais de Paris \u00e0 Lyon\"); if (result.success) { console.log(`\u2705 ${result.departure} \u2192 ${result.arrival}`); } else { console.log(`\u26a0\ufe0f ${result.message}`); } } catch (error) { console.error('\u274c Erreur:', error.message); } })();","title":"JavaScript (Node.js)"},{"location":"api-rest/#securite-et-production","text":"","title":"\ud83d\udd12 S\u00e9curit\u00e9 et production"},{"location":"api-rest/#cors","text":"La configuration actuelle autorise toutes les origines (mode d\u00e9veloppement). Fichier : src/api/main.py # Configuration actuelle (DEV) app.add_middleware( CORSMiddleware, allow_origins=[\"*\"], # \u26a0\ufe0f Toutes les origines allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"], ) # Configuration recommand\u00e9e (PROD) app.add_middleware( CORSMiddleware, allow_origins=[ \"https://your-domain.com\", \"https://app.your-domain.com\" ], allow_credentials=True, allow_methods=[\"POST\", \"GET\"], allow_headers=[\"Content-Type\"], )","title":"CORS"},{"location":"api-rest/#rate-limiting","text":"L'API actuelle n'a pas de rate limiting. Recommandations : # Utiliser slowapi from slowapi import Limiter from slowapi.util import get_remote_address limiter = Limiter(key_func=get_remote_address) app.state.limiter = limiter @app.post(\"/trip/parse\") @limiter.limit(\"10/minute\") # Max 10 requ\u00eates par minute async def parse_trip(request: Request, ...): ...","title":"Rate limiting"},{"location":"api-rest/#validation-et-sanitization","text":"Les entr\u00e9es sont d\u00e9j\u00e0 valid\u00e9es par Pydantic : Longueur min/max Type string Pas de whitespace seul","title":"Validation et sanitization"},{"location":"api-rest/#monitoring","text":"1. Logging structur\u00e9 import logging import json logger = logging.getLogger(__name__) @app.post(\"/trip/parse\") async def parse_trip(request: TripParseRequest): logger.info(json.dumps({ \"event\": \"parse_request\", \"text_length\": len(request.text), \"timestamp\": datetime.now().isoformat() })) 2. M\u00e9triques (Prometheus) from prometheus_client import Counter, Histogram requests_total = Counter('trip_parse_requests_total', 'Total requests') request_duration = Histogram('trip_parse_duration_seconds', 'Request duration')","title":"Monitoring"},{"location":"api-rest/#documentation-interactive","text":"","title":"\ud83d\udcd6 Documentation interactive"},{"location":"api-rest/#swagger-ui","text":"Une fois l'API lanc\u00e9e, acc\u00e9dez \u00e0 : http://127.0.0.1:8000/docs Fonctionnalit\u00e9s : \ud83d\udcdd Tester tous les endpoints directement depuis le navigateur \ud83d\udcc4 Voir les sch\u00e9mas d\u00e9taill\u00e9s de requ\u00eate/r\u00e9ponse \ud83d\udca1 Exemples de code dans plusieurs langages \u2b07\ufe0f T\u00e9l\u00e9charger la sp\u00e9cification OpenAPI","title":"Swagger UI"},{"location":"api-rest/#openapi-spec","text":"La sp\u00e9cification compl\u00e8te est disponible \u00e0 : http://127.0.0.1:8000/openapi.json Utilisable avec des outils comme : Postman (import OpenAPI) Insomnia API clients auto-g\u00e9n\u00e9r\u00e9s","title":"OpenAPI Spec"},{"location":"architecture/","text":"Ce document d\u00e9crit l'architecture compl\u00e8te du projet Trip Extraction, sa structure de code, les design patterns utilis\u00e9s et le pipeline de traitement. \ud83d\udcc1 Structure du projet Vue d'ensemble bootstrap/ \u251c\u2500\u2500 src/ \u2502 \u251c\u2500\u2500 trip_parser/ # Module d'extraction ML \u2502 \u2502 \u251c\u2500\u2500 trip_parser.py # Orchestrateur principal \u2502 \u2502 \u251c\u2500\u2500 config.py # Configuration centralis\u00e9e \u2502 \u2502 \u251c\u2500\u2500 exceptions.py # Exceptions m\u00e9tier \u2502 \u2502 \u251c\u2500\u2500 utils.py # Utilitaires (logging, etc) \u2502 \u2502 \u2514\u2500\u2500 models/ # Mod\u00e8les ML \u2502 \u2502 \u251c\u2500\u2500 base.py # Classe de base abstraite \u2502 \u2502 \u251c\u2500\u2500 ner.py # NER Extractor (CamemBERT) \u2502 \u2502 \u2514\u2500\u2500 classifier.py # Classifier d\u00e9part/arriv\u00e9e \u2502 \u2502 \u2502 \u2514\u2500\u2500 api/ # API REST FastAPI \u2502 \u251c\u2500\u2500 main.py # Application FastAPI \u2502 \u251c\u2500\u2500 routers/ # Routes HTTP \u2502 \u2502 \u2514\u2500\u2500 trip.py # Routes /trip/* \u2502 \u251c\u2500\u2500 schemas/ # Mod\u00e8les Pydantic \u2502 \u2502 \u2514\u2500\u2500 trip.py # Sch\u00e9mas request/response \u2502 \u2514\u2500\u2500 services/ # Logique m\u00e9tier API \u2502 \u2514\u2500\u2500 trip_service.py # Service singleton \u2502 \u251c\u2500\u2500 scripts/ # Scripts d'entr\u00e9e \u2502 \u251c\u2500\u2500 demo.py # Interface CLI interactive \u2502 \u251c\u2500\u2500 train.py # Entra\u00eenement du classifier \u2502 \u2514\u2500\u2500 run_api.py # Lanceur de l'API \u2502 \u251c\u2500\u2500 models/ # Mod\u00e8les ML entra\u00een\u00e9s \u2502 \u2514\u2500\u2500 departure_arrival_classifier/ \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 data/ # Donn\u00e9es d'entra\u00eenement \u2502 \u2514\u2500\u2500 training_dataset.json \u2502 \u251c\u2500\u2500 docs/ # Documentation MkDocs \u2502 \u2514\u2500\u2500 xxx.md \u2502 \u251c\u2500\u2500 logs/ # Fichiers de logs \u2502 \u251c\u2500\u2500 pyproject.toml # Configuration Python/pip \u251c\u2500\u2500 mkdocs.yml # Configuration documentation \u2514\u2500\u2500 README.md # Quick start Organisation des responsabilit\u00e9s Dossier Responsabilit\u00e9 D\u00e9pendances src/trip_parser/ Logique d'extraction ML transformers, torch, sentencepiece src/api/ Exposition REST fastapi, uvicorn, pydantic scripts/ Points d'entr\u00e9e CLI trip_parser, api models/ Mod\u00e8les entra\u00een\u00e9s G\u00e9n\u00e9r\u00e9 par trip-train data/ Datasets Fourni manuellement docs/ Documentation mkdocs, shadcn \ud83c\udfd7\ufe0f Pipeline de traitement Vue d\u00e9taill\u00e9e du flux \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 USER INPUT : Texte fran\u00e7ais \u2502 \u2502 \"Je veux aller de Paris \u00e0 Lyon\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 1. Validation \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 TripParser.parse_trip() \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 \u2022 V\u00e9rifie que text est non vide \u2502 \u2502 \u2022 Limite la longueur (max 1000 caract\u00e8res) \u2502 \u2502 \u2022 Log l'entr\u00e9e pour debugging \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 2. Extraction des entit\u00e9s \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 NERExtractor.extract_locations() \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 MOD\u00c8LE : Jean-Baptiste/camembert-ner (Hugging Face) \u2502 \u2502 INPUT : \"Je veux aller de Paris \u00e0 Lyon\" \u2502 \u2502 \u2502 \u2502 \u00c9TAPES : \u2502 \u2502 1. Tokenisation avec CamembertTokenizer \u2502 \u2502 \u2192 [\"Je\", \"veux\", \"aller\", \"de\", \"Paris\", \"\u00e0\", \"Lyon\"] \u2502 \u2502 \u2502 \u2502 2. NER Pipeline (detection d'entit\u00e9s) \u2502 \u2502 \u2192 [ \u2502 \u2502 {\"entity\": \"LOC\", \"word\": \"Paris\", \"score\": 0.99}, \u2502 \u2502 {\"entity\": \"LOC\", \"word\": \"Lyon\", \"score\": 0.98} \u2502 \u2502 ] \u2502 \u2502 \u2502 \u2502 3. Filtrage (garder uniquement type LOC) \u2502 \u2502 \u2192 [\"Paris\", \"Lyon\"] \u2502 \u2502 \u2502 \u2502 4. Split des locations compos\u00e9es \u2502 \u2502 Ex: \"Paris Marseille\" \u2192 [\"Paris\", \"Marseille\"] \u2502 \u2502 \u2502 \u2502 OUTPUT : [\"Paris\", \"Lyon\"] \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 3. V\u00e9rification nombre de villes \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Validation du nombre \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 if len(cities) < 2: \u2502 \u2502 return (None, None) # Pas assez de villes \u2502 \u2502 \u2502 \u2502 if len(cities) == 2: \u2502 \u2502 continue # Cas simple \u2502 \u2502 \u2502 \u2502 if len(cities) > 2: \u2502 \u2502 # Le classifier d\u00e9terminera lesquelles sont d\u00e9part/arriv\u00e9e \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 4. Classification \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 DepartureArrivalClassifier.classify_locations() \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 MOD\u00c8LE : CamemBERT fine-tun\u00e9 (models/departure_arrival_...) \u2502 \u2502 INPUT : text=\"Je veux aller de Paris \u00e0 Lyon\" \u2502 \u2502 cities=[\"Paris\", \"Lyon\"] \u2502 \u2502 \u2502 \u2502 \u00c9TAPES : Pour chaque ville \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ville: \"Paris\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 1. Marquer la ville dans le texte \u2502 \u2502 \u2502 \u2502 \"Je veux aller de [LOC] \u00e0 Lyon\" \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 2. Tokeniser avec CamembertTokenizer \u2502 \u2502 \u2502 \u2502 \u2192 input_ids, attention_mask \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 3. Forward pass dans le mod\u00e8le \u2502 \u2502 \u2502 \u2502 logits = model(**inputs) \u2502 \u2502 \u2502 \u2502 \u2192 [4.2, -3.8] (0=departure, 1=arrival) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 4. Softmax pour probabilit\u00e9s \u2502 \u2502 \u2502 \u2502 \u2192 [0.98, 0.02] \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 5. Classification \u2502 \u2502 \u2502 \u2502 argmax(logits) = 0 \u2502 \u2502 \u2502 \u2502 role = \"departure\" \u2502 \u2502 \u2502 \u2502 confidence = 0.98 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ville: \"Lyon\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 1. \"Je veux aller de Paris \u00e0 [LOC]\" \u2502 \u2502 \u2502 \u2502 2. Tokenize \u2502 \u2502 \u2502 \u2502 3. Forward \u2192 [-3.5, 4.1] \u2502 \u2502 \u2502 \u2502 4. Softmax \u2192 [0.01, 0.99] \u2502 \u2502 \u2502 \u2502 5. role = \"arrival\", confidence = 0.99 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 R\u00c9SULTAT : \u2502 \u2502 departure_candidates = [(\"Paris\", 0.98)] \u2502 \u2502 arrival_candidates = [(\"Lyon\", 0.99)] \u2502 \u2502 \u2502 \u2502 OUTPUT : (\"Paris\", \"Lyon\") \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 5. Retour final \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 RESULT \u2502 \u2502 (\"Paris\", \"Lyon\") \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Gestion des cas limites Cas 1 : Moins de 2 villes # Input text = \"Je veux aller \u00e0 Paris\" # \u00c9tape 1 : NER d\u00e9tecte [\"Paris\"] # \u00c9tape 2 : len(cities) < 2 \u2192 STOP # Output : (None, None) Cas 2 : Plus de 2 villes # Input text = \"De Paris \u00e0 Lyon puis Marseille\" # \u00c9tape 1 : NER d\u00e9tecte [\"Paris\", \"Lyon\", \"Marseille\"] # \u00c9tape 2 : Classifier \u00e9value chaque ville # Paris: departure (0.95) # Lyon: arrival (0.60) # Marseille: arrival (0.85) # \u00c9tape 3 : S\u00e9lection du meilleur d\u00e9part et arriv\u00e9e # Best departure: Paris (0.95) # Best arrival: Marseille (0.85) # Output : (\"Paris\", \"Marseille\") Cas 3 : Ambigu\u00eft\u00e9 # Input text = \"Paris Lyon\" # Pas de pr\u00e9position # \u00c9tape 1 : NER d\u00e9tecte [\"Paris\", \"Lyon\"] # \u00c9tape 2 : Classifier essaie de deviner # \"[LOC] Lyon\" \u2192 Paris: departure (0.55) # \"Paris [LOC]\" \u2192 Lyon: arrival (0.60) # \u00c9tape 3 : Confiance faible mais utilisable # Output : (\"Paris\", \"Lyon\") \ud83e\udde9 Composants d\u00e9taill\u00e9s 1. TripParser (Orchestrateur) Fichier : src/trip_parser/trip_parser.py R\u00f4le : Point d'entr\u00e9e principal qui coordonne NER et Classifier. Responsabilit\u00e9s : Validation des entr\u00e9es Orchestration du pipeline Gestion des erreurs Logging des op\u00e9rations 2. NERExtractor (D\u00e9tection d'entit\u00e9s) Fichier : src/trip_parser/models/ner.py R\u00f4le : D\u00e9tecter les entit\u00e9s g\u00e9ographiques dans le texte. Mod\u00e8le utilis\u00e9 : Jean-Baptiste/camembert-ner Pr\u00e9-entra\u00een\u00e9 sur corpus fran\u00e7ais D\u00e9tecte 4 types d'entit\u00e9s : PER (personnes), LOC (lieux), ORG (organisations), MISC Architecture : CamemBERT + couche de classification (4 classes) Exemple de tokenisation : text = \"Je vais de Paris \u00e0 Lyon\" # Tokenisation CamemBERT (subword) tokens = [\"\u2581Je\", \"\u2581vais\", \"\u2581de\", \"\u2581Paris\", \"\u2581\u00e0\", \"\u2581Lyon\"] # NER labels (B=Begin, I=Inside, O=Outside) labels = [\"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"B-LOC\"] # Agr\u00e9gation (strategy=\"simple\") entities = [ {\"entity_group\": \"LOC\", \"word\": \"Paris\", \"score\": 0.99}, {\"entity_group\": \"LOC\", \"word\": \"Lyon\", \"score\": 0.98} ] 3. DepartureArrivalClassifier (Classification) Fichier : src/trip_parser/models/classifier.py R\u00f4le : D\u00e9terminer si une ville est un d\u00e9part ou une arriv\u00e9e. Mod\u00e8le : CamemBERT fine-tun\u00e9 Mod\u00e8le de base : camembert-base Fine-tuning : Classification binaire (0=departure, 1=arrival) Training data : data/training_dataset.json Exemple d'inf\u00e9rence : text = \"Je vais de Paris \u00e0 Lyon\" location = \"Paris\" # 1. Marquer marked = \"Je vais de [LOC] \u00e0 Lyon\" # 2. Tokenize input_ids = [5, 123, 456, 789, 12, 34, 6] # IDs CamemBERT # 3. Forward logits = model(input_ids) # \u2192 tensor([[4.2, -3.8]]) # 4. Softmax probs = softmax([[4.2, -3.8]]) # \u2192 tensor([[0.9982, 0.0018]]) # 5. Classification label = argmax([0.9982, 0.0018]) # \u2192 0 (departure) confidence = 0.9982 # 99.82% return (\"departure\", 0.9982) 4. Configuration centralis\u00e9e Fichier : src/trip_parser/config.py R\u00f4le : Centraliser toute la configuration du projet. Pattern : Singleton + Dataclass Usage : from trip_parser import get_config config = get_config() print(config.paths.models_dir) print(config.model.ner_model_name) 5. Hi\u00e9rarchie d'exceptions Fichier : src/trip_parser/exceptions.py Pattern : Exception hierarchy TripExtractionError (Exception) \u2502 \u251c\u2500\u2500 ModelNotFoundError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand le mod\u00e8le n'existe pas sur disque \u2502 \u251c\u2500\u2500 ModelLoadError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand le chargement du mod\u00e8le \u00e9choue \u2502 \u251c\u2500\u2500 InsufficientLocationsError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand < 2 villes d\u00e9tect\u00e9es \u2502 \u251c\u2500\u2500 InvalidInputError \u2502 \u2514\u2500\u2500 Lev\u00e9e pour validation d'entr\u00e9e \u2502 \u251c\u2500\u2500 ClassificationError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand la classification \u00e9choue \u2502 \u2514\u2500\u2500 TokenizationError \u2514\u2500\u2500 Lev\u00e9e lors d'erreurs de tokenisation Usage : try: departure, arrival = parser.parse_trip(text) except InvalidInputError: print(\"Texte invalide\") except InsufficientLocationsError: print(\"Au moins 2 villes requises\") except ModelNotFoundError: print(\"Ex\u00e9cutez 'trip-train' d'abord\") except TripExtractionError as e: print(f\"Erreur g\u00e9n\u00e9rique: {e}\") \ud83d\udd0c API REST Architecture \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Client Request \u2502 \u2502 POST /trip/parse {\"text\": \"...\"} \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 FastAPI Middleware \u2502 \u2502 \u2022 CORS (allow all origins en dev) \u2502 \u2502 \u2022 Exception handlers (globaux) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router : trip_router \u2502 \u2502 \u2022 Route: POST /trip/parse \u2502 \u2502 \u2022 Validation Pydantic automatique \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Service : TripParserService \u2502 \u2502 \u2022 Pattern Singleton \u2502 \u2502 \u2022 Cache de l'instance TripParser \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 TripParser (module ML) \u2502 \u2502 \u2022 NER \u2192 Classifier \u2192 R\u00e9sultat \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Response JSON \u2502 \u2502 {\"departure\": \"Paris\", \"arrival\": \"Lyon\"} \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \ud83c\udfa8 Design Patterns utilis\u00e9s 1. Facade Pattern O\u00f9 : TripParser Pourquoi : Simplifier l'interface complexe des mod\u00e8les ML. # Sans Facade (complexe) ner = NERExtractor() classifier = DepartureArrivalClassifier() cities = ner.extract_locations(text) if len(cities) >= 2: departure, arrival = classifier.classify_locations(text, cities) # Avec Facade (simple) parser = TripParser() departure, arrival = parser.parse_trip(text) 2. Dependency Injection O\u00f9 : TripParser.__init__ Pourquoi : Faciliter les tests et la personnalisation. # Production : utilise les mod\u00e8les r\u00e9els parser = TripParser() # Test : utilise des mocks mock_ner = Mock(spec=NERExtractor) mock_classifier = Mock(spec=DepartureArrivalClassifier) parser = TripParser(ner_extractor=mock_ner, classifier=mock_classifier) 3. Singleton Pattern O\u00f9 : TripParserService , get_config() Pourquoi : \u00c9viter de recharger les mod\u00e8les plusieurs fois. # Le mod\u00e8le n'est charg\u00e9 qu'une fois service1 = TripParserService() # Charge le mod\u00e8le service2 = TripParserService() # R\u00e9utilise l'instance assert service1.parser is service2.parser # M\u00eame instance 4. Template Method Pattern O\u00f9 : DepartureArrivalClassifier.classify_locations Pourquoi : D\u00e9finir le squelette de l'algorithme. def classify_locations(self, text, cities): # Template : d\u00e9finit les \u00e9tapes candidates = self._classify_all(text, cities) departure = self._select_best_departure(candidates) arrival = self._select_best_arrival(candidates) return (departure, arrival) 5. Lazy Loading O\u00f9 : NERExtractor._load_model Pourquoi : Ne charger le mod\u00e8le que si n\u00e9cessaire. class NERExtractor: def __init__(self): self._pipeline = None # Pas encore charg\u00e9 def extract_locations(self, text): if self._pipeline is None: self._load_model() # Charge \u00e0 la premi\u00e8re utilisation return self._pipeline(text) <","title":"Architecture"},{"location":"architecture/#structure-du-projet","text":"","title":"\ud83d\udcc1 Structure du projet"},{"location":"architecture/#vue-densemble","text":"bootstrap/ \u251c\u2500\u2500 src/ \u2502 \u251c\u2500\u2500 trip_parser/ # Module d'extraction ML \u2502 \u2502 \u251c\u2500\u2500 trip_parser.py # Orchestrateur principal \u2502 \u2502 \u251c\u2500\u2500 config.py # Configuration centralis\u00e9e \u2502 \u2502 \u251c\u2500\u2500 exceptions.py # Exceptions m\u00e9tier \u2502 \u2502 \u251c\u2500\u2500 utils.py # Utilitaires (logging, etc) \u2502 \u2502 \u2514\u2500\u2500 models/ # Mod\u00e8les ML \u2502 \u2502 \u251c\u2500\u2500 base.py # Classe de base abstraite \u2502 \u2502 \u251c\u2500\u2500 ner.py # NER Extractor (CamemBERT) \u2502 \u2502 \u2514\u2500\u2500 classifier.py # Classifier d\u00e9part/arriv\u00e9e \u2502 \u2502 \u2502 \u2514\u2500\u2500 api/ # API REST FastAPI \u2502 \u251c\u2500\u2500 main.py # Application FastAPI \u2502 \u251c\u2500\u2500 routers/ # Routes HTTP \u2502 \u2502 \u2514\u2500\u2500 trip.py # Routes /trip/* \u2502 \u251c\u2500\u2500 schemas/ # Mod\u00e8les Pydantic \u2502 \u2502 \u2514\u2500\u2500 trip.py # Sch\u00e9mas request/response \u2502 \u2514\u2500\u2500 services/ # Logique m\u00e9tier API \u2502 \u2514\u2500\u2500 trip_service.py # Service singleton \u2502 \u251c\u2500\u2500 scripts/ # Scripts d'entr\u00e9e \u2502 \u251c\u2500\u2500 demo.py # Interface CLI interactive \u2502 \u251c\u2500\u2500 train.py # Entra\u00eenement du classifier \u2502 \u2514\u2500\u2500 run_api.py # Lanceur de l'API \u2502 \u251c\u2500\u2500 models/ # Mod\u00e8les ML entra\u00een\u00e9s \u2502 \u2514\u2500\u2500 departure_arrival_classifier/ \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 data/ # Donn\u00e9es d'entra\u00eenement \u2502 \u2514\u2500\u2500 training_dataset.json \u2502 \u251c\u2500\u2500 docs/ # Documentation MkDocs \u2502 \u2514\u2500\u2500 xxx.md \u2502 \u251c\u2500\u2500 logs/ # Fichiers de logs \u2502 \u251c\u2500\u2500 pyproject.toml # Configuration Python/pip \u251c\u2500\u2500 mkdocs.yml # Configuration documentation \u2514\u2500\u2500 README.md # Quick start","title":"Vue d'ensemble"},{"location":"architecture/#organisation-des-responsabilites","text":"Dossier Responsabilit\u00e9 D\u00e9pendances src/trip_parser/ Logique d'extraction ML transformers, torch, sentencepiece src/api/ Exposition REST fastapi, uvicorn, pydantic scripts/ Points d'entr\u00e9e CLI trip_parser, api models/ Mod\u00e8les entra\u00een\u00e9s G\u00e9n\u00e9r\u00e9 par trip-train data/ Datasets Fourni manuellement docs/ Documentation mkdocs, shadcn","title":"Organisation des responsabilit\u00e9s"},{"location":"architecture/#pipeline-de-traitement","text":"","title":"\ud83c\udfd7\ufe0f Pipeline de traitement"},{"location":"architecture/#vue-detaillee-du-flux","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 USER INPUT : Texte fran\u00e7ais \u2502 \u2502 \"Je veux aller de Paris \u00e0 Lyon\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 1. Validation \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 TripParser.parse_trip() \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 \u2022 V\u00e9rifie que text est non vide \u2502 \u2502 \u2022 Limite la longueur (max 1000 caract\u00e8res) \u2502 \u2502 \u2022 Log l'entr\u00e9e pour debugging \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 2. Extraction des entit\u00e9s \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 NERExtractor.extract_locations() \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 MOD\u00c8LE : Jean-Baptiste/camembert-ner (Hugging Face) \u2502 \u2502 INPUT : \"Je veux aller de Paris \u00e0 Lyon\" \u2502 \u2502 \u2502 \u2502 \u00c9TAPES : \u2502 \u2502 1. Tokenisation avec CamembertTokenizer \u2502 \u2502 \u2192 [\"Je\", \"veux\", \"aller\", \"de\", \"Paris\", \"\u00e0\", \"Lyon\"] \u2502 \u2502 \u2502 \u2502 2. NER Pipeline (detection d'entit\u00e9s) \u2502 \u2502 \u2192 [ \u2502 \u2502 {\"entity\": \"LOC\", \"word\": \"Paris\", \"score\": 0.99}, \u2502 \u2502 {\"entity\": \"LOC\", \"word\": \"Lyon\", \"score\": 0.98} \u2502 \u2502 ] \u2502 \u2502 \u2502 \u2502 3. Filtrage (garder uniquement type LOC) \u2502 \u2502 \u2192 [\"Paris\", \"Lyon\"] \u2502 \u2502 \u2502 \u2502 4. Split des locations compos\u00e9es \u2502 \u2502 Ex: \"Paris Marseille\" \u2192 [\"Paris\", \"Marseille\"] \u2502 \u2502 \u2502 \u2502 OUTPUT : [\"Paris\", \"Lyon\"] \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 3. V\u00e9rification nombre de villes \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Validation du nombre \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 if len(cities) < 2: \u2502 \u2502 return (None, None) # Pas assez de villes \u2502 \u2502 \u2502 \u2502 if len(cities) == 2: \u2502 \u2502 continue # Cas simple \u2502 \u2502 \u2502 \u2502 if len(cities) > 2: \u2502 \u2502 # Le classifier d\u00e9terminera lesquelles sont d\u00e9part/arriv\u00e9e \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 4. Classification \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 DepartureArrivalClassifier.classify_locations() \u2502 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 MOD\u00c8LE : CamemBERT fine-tun\u00e9 (models/departure_arrival_...) \u2502 \u2502 INPUT : text=\"Je veux aller de Paris \u00e0 Lyon\" \u2502 \u2502 cities=[\"Paris\", \"Lyon\"] \u2502 \u2502 \u2502 \u2502 \u00c9TAPES : Pour chaque ville \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ville: \"Paris\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 1. Marquer la ville dans le texte \u2502 \u2502 \u2502 \u2502 \"Je veux aller de [LOC] \u00e0 Lyon\" \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 2. Tokeniser avec CamembertTokenizer \u2502 \u2502 \u2502 \u2502 \u2192 input_ids, attention_mask \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 3. Forward pass dans le mod\u00e8le \u2502 \u2502 \u2502 \u2502 logits = model(**inputs) \u2502 \u2502 \u2502 \u2502 \u2192 [4.2, -3.8] (0=departure, 1=arrival) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 4. Softmax pour probabilit\u00e9s \u2502 \u2502 \u2502 \u2502 \u2192 [0.98, 0.02] \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 5. Classification \u2502 \u2502 \u2502 \u2502 argmax(logits) = 0 \u2502 \u2502 \u2502 \u2502 role = \"departure\" \u2502 \u2502 \u2502 \u2502 confidence = 0.98 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ville: \"Lyon\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 1. \"Je veux aller de Paris \u00e0 [LOC]\" \u2502 \u2502 \u2502 \u2502 2. Tokenize \u2502 \u2502 \u2502 \u2502 3. Forward \u2192 [-3.5, 4.1] \u2502 \u2502 \u2502 \u2502 4. Softmax \u2192 [0.01, 0.99] \u2502 \u2502 \u2502 \u2502 5. role = \"arrival\", confidence = 0.99 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 R\u00c9SULTAT : \u2502 \u2502 departure_candidates = [(\"Paris\", 0.98)] \u2502 \u2502 arrival_candidates = [(\"Lyon\", 0.99)] \u2502 \u2502 \u2502 \u2502 OUTPUT : (\"Paris\", \"Lyon\") \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 5. Retour final \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 RESULT \u2502 \u2502 (\"Paris\", \"Lyon\") \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Vue d\u00e9taill\u00e9e du flux"},{"location":"architecture/#gestion-des-cas-limites","text":"Cas 1 : Moins de 2 villes # Input text = \"Je veux aller \u00e0 Paris\" # \u00c9tape 1 : NER d\u00e9tecte [\"Paris\"] # \u00c9tape 2 : len(cities) < 2 \u2192 STOP # Output : (None, None) Cas 2 : Plus de 2 villes # Input text = \"De Paris \u00e0 Lyon puis Marseille\" # \u00c9tape 1 : NER d\u00e9tecte [\"Paris\", \"Lyon\", \"Marseille\"] # \u00c9tape 2 : Classifier \u00e9value chaque ville # Paris: departure (0.95) # Lyon: arrival (0.60) # Marseille: arrival (0.85) # \u00c9tape 3 : S\u00e9lection du meilleur d\u00e9part et arriv\u00e9e # Best departure: Paris (0.95) # Best arrival: Marseille (0.85) # Output : (\"Paris\", \"Marseille\") Cas 3 : Ambigu\u00eft\u00e9 # Input text = \"Paris Lyon\" # Pas de pr\u00e9position # \u00c9tape 1 : NER d\u00e9tecte [\"Paris\", \"Lyon\"] # \u00c9tape 2 : Classifier essaie de deviner # \"[LOC] Lyon\" \u2192 Paris: departure (0.55) # \"Paris [LOC]\" \u2192 Lyon: arrival (0.60) # \u00c9tape 3 : Confiance faible mais utilisable # Output : (\"Paris\", \"Lyon\")","title":"Gestion des cas limites"},{"location":"architecture/#composants-detailles","text":"","title":"\ud83e\udde9 Composants d\u00e9taill\u00e9s"},{"location":"architecture/#1-tripparser-orchestrateur","text":"Fichier : src/trip_parser/trip_parser.py R\u00f4le : Point d'entr\u00e9e principal qui coordonne NER et Classifier. Responsabilit\u00e9s : Validation des entr\u00e9es Orchestration du pipeline Gestion des erreurs Logging des op\u00e9rations","title":"1. TripParser (Orchestrateur)"},{"location":"architecture/#2-nerextractor-detection-dentites","text":"Fichier : src/trip_parser/models/ner.py R\u00f4le : D\u00e9tecter les entit\u00e9s g\u00e9ographiques dans le texte. Mod\u00e8le utilis\u00e9 : Jean-Baptiste/camembert-ner Pr\u00e9-entra\u00een\u00e9 sur corpus fran\u00e7ais D\u00e9tecte 4 types d'entit\u00e9s : PER (personnes), LOC (lieux), ORG (organisations), MISC Architecture : CamemBERT + couche de classification (4 classes) Exemple de tokenisation : text = \"Je vais de Paris \u00e0 Lyon\" # Tokenisation CamemBERT (subword) tokens = [\"\u2581Je\", \"\u2581vais\", \"\u2581de\", \"\u2581Paris\", \"\u2581\u00e0\", \"\u2581Lyon\"] # NER labels (B=Begin, I=Inside, O=Outside) labels = [\"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"B-LOC\"] # Agr\u00e9gation (strategy=\"simple\") entities = [ {\"entity_group\": \"LOC\", \"word\": \"Paris\", \"score\": 0.99}, {\"entity_group\": \"LOC\", \"word\": \"Lyon\", \"score\": 0.98} ]","title":"2. NERExtractor (D\u00e9tection d'entit\u00e9s)"},{"location":"architecture/#3-departurearrivalclassifier-classification","text":"Fichier : src/trip_parser/models/classifier.py R\u00f4le : D\u00e9terminer si une ville est un d\u00e9part ou une arriv\u00e9e. Mod\u00e8le : CamemBERT fine-tun\u00e9 Mod\u00e8le de base : camembert-base Fine-tuning : Classification binaire (0=departure, 1=arrival) Training data : data/training_dataset.json Exemple d'inf\u00e9rence : text = \"Je vais de Paris \u00e0 Lyon\" location = \"Paris\" # 1. Marquer marked = \"Je vais de [LOC] \u00e0 Lyon\" # 2. Tokenize input_ids = [5, 123, 456, 789, 12, 34, 6] # IDs CamemBERT # 3. Forward logits = model(input_ids) # \u2192 tensor([[4.2, -3.8]]) # 4. Softmax probs = softmax([[4.2, -3.8]]) # \u2192 tensor([[0.9982, 0.0018]]) # 5. Classification label = argmax([0.9982, 0.0018]) # \u2192 0 (departure) confidence = 0.9982 # 99.82% return (\"departure\", 0.9982)","title":"3. DepartureArrivalClassifier (Classification)"},{"location":"architecture/#4-configuration-centralisee","text":"Fichier : src/trip_parser/config.py R\u00f4le : Centraliser toute la configuration du projet. Pattern : Singleton + Dataclass Usage : from trip_parser import get_config config = get_config() print(config.paths.models_dir) print(config.model.ner_model_name)","title":"4. Configuration centralis\u00e9e"},{"location":"architecture/#5-hierarchie-dexceptions","text":"Fichier : src/trip_parser/exceptions.py Pattern : Exception hierarchy TripExtractionError (Exception) \u2502 \u251c\u2500\u2500 ModelNotFoundError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand le mod\u00e8le n'existe pas sur disque \u2502 \u251c\u2500\u2500 ModelLoadError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand le chargement du mod\u00e8le \u00e9choue \u2502 \u251c\u2500\u2500 InsufficientLocationsError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand < 2 villes d\u00e9tect\u00e9es \u2502 \u251c\u2500\u2500 InvalidInputError \u2502 \u2514\u2500\u2500 Lev\u00e9e pour validation d'entr\u00e9e \u2502 \u251c\u2500\u2500 ClassificationError \u2502 \u2514\u2500\u2500 Lev\u00e9e quand la classification \u00e9choue \u2502 \u2514\u2500\u2500 TokenizationError \u2514\u2500\u2500 Lev\u00e9e lors d'erreurs de tokenisation Usage : try: departure, arrival = parser.parse_trip(text) except InvalidInputError: print(\"Texte invalide\") except InsufficientLocationsError: print(\"Au moins 2 villes requises\") except ModelNotFoundError: print(\"Ex\u00e9cutez 'trip-train' d'abord\") except TripExtractionError as e: print(f\"Erreur g\u00e9n\u00e9rique: {e}\")","title":"5. Hi\u00e9rarchie d'exceptions"},{"location":"architecture/#api-rest","text":"","title":"\ud83d\udd0c API REST"},{"location":"architecture/#architecture","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Client Request \u2502 \u2502 POST /trip/parse {\"text\": \"...\"} \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 FastAPI Middleware \u2502 \u2502 \u2022 CORS (allow all origins en dev) \u2502 \u2502 \u2022 Exception handlers (globaux) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router : trip_router \u2502 \u2502 \u2022 Route: POST /trip/parse \u2502 \u2502 \u2022 Validation Pydantic automatique \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Service : TripParserService \u2502 \u2502 \u2022 Pattern Singleton \u2502 \u2502 \u2022 Cache de l'instance TripParser \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 TripParser (module ML) \u2502 \u2502 \u2022 NER \u2192 Classifier \u2192 R\u00e9sultat \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Response JSON \u2502 \u2502 {\"departure\": \"Paris\", \"arrival\": \"Lyon\"} \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Architecture"},{"location":"architecture/#design-patterns-utilises","text":"","title":"\ud83c\udfa8 Design Patterns utilis\u00e9s"},{"location":"architecture/#1-facade-pattern","text":"O\u00f9 : TripParser Pourquoi : Simplifier l'interface complexe des mod\u00e8les ML. # Sans Facade (complexe) ner = NERExtractor() classifier = DepartureArrivalClassifier() cities = ner.extract_locations(text) if len(cities) >= 2: departure, arrival = classifier.classify_locations(text, cities) # Avec Facade (simple) parser = TripParser() departure, arrival = parser.parse_trip(text)","title":"1. Facade Pattern"},{"location":"architecture/#2-dependency-injection","text":"O\u00f9 : TripParser.__init__ Pourquoi : Faciliter les tests et la personnalisation. # Production : utilise les mod\u00e8les r\u00e9els parser = TripParser() # Test : utilise des mocks mock_ner = Mock(spec=NERExtractor) mock_classifier = Mock(spec=DepartureArrivalClassifier) parser = TripParser(ner_extractor=mock_ner, classifier=mock_classifier)","title":"2. Dependency Injection"},{"location":"architecture/#3-singleton-pattern","text":"O\u00f9 : TripParserService , get_config() Pourquoi : \u00c9viter de recharger les mod\u00e8les plusieurs fois. # Le mod\u00e8le n'est charg\u00e9 qu'une fois service1 = TripParserService() # Charge le mod\u00e8le service2 = TripParserService() # R\u00e9utilise l'instance assert service1.parser is service2.parser # M\u00eame instance","title":"3. Singleton Pattern"},{"location":"architecture/#4-template-method-pattern","text":"O\u00f9 : DepartureArrivalClassifier.classify_locations Pourquoi : D\u00e9finir le squelette de l'algorithme. def classify_locations(self, text, cities): # Template : d\u00e9finit les \u00e9tapes candidates = self._classify_all(text, cities) departure = self._select_best_departure(candidates) arrival = self._select_best_arrival(candidates) return (departure, arrival)","title":"4. Template Method Pattern"},{"location":"architecture/#5-lazy-loading","text":"O\u00f9 : NERExtractor._load_model Pourquoi : Ne charger le mod\u00e8le que si n\u00e9cessaire. class NERExtractor: def __init__(self): self._pipeline = None # Pas encore charg\u00e9 def extract_locations(self, text): if self._pipeline is None: self._load_model() # Charge \u00e0 la premi\u00e8re utilisation return self._pipeline(text) <","title":"5. Lazy Loading"},{"location":"guide-usage/","text":"Ce guide vous pr\u00e9sente toutes les fa\u00e7ons d'utiliser Trip Extraction avec des exemples d\u00e9taill\u00e9s et des cas d'usage r\u00e9els. \ud83c\udfaf Modes d'utilisation Trip Extraction peut \u00eatre utilis\u00e9 de 3 fa\u00e7ons diff\u00e9rentes selon vos besoins : Mode Usage Avantages Module Python Import dans code Python Int\u00e9gration directe, performances optimales CLI (Interface terminal) Ligne de commande Tests rapides, d\u00e9monstration API REST Requ\u00eates HTTP Multi-langage, microservices, scalabilit\u00e9 \ud83d\udc0d Module Python Utilisation basique L'utilisation la plus simple pour int\u00e9grer Trip Extraction dans votre code Python : from trip_parser import TripParser # Initialiser le parser (charge les mod\u00e8les) parser = TripParser() # Extraire un trajet departure, arrival = parser.parse_trip(\"Je vais de Paris \u00e0 Lyon\") print(f\"D\u00e9part: {departure}\") # D\u00e9part: Paris print(f\"Arriv\u00e9e: {arrival}\") # Arriv\u00e9e: Lyon Initialisation unique Cr\u00e9ez une seule instance de TripParser et r\u00e9utilisez-la. Le chargement des mod\u00e8les prend ~2-3 secondes. Gestion des cas d'erreur Production-ready avec gestion compl\u00e8te des erreurs : from trip_parser import TripParser from trip_parser.exceptions import ( TripExtractionError, InvalidInputError, InsufficientLocationsError, ModelNotFoundError ) parser = TripParser() def extract_trip_safe(text: str) -> dict: \"\"\"Extraction s\u00e9curis\u00e9e avec gestion d'erreurs.\"\"\" try: departure, arrival = parser.parse_trip(text) if departure and arrival: return { \"status\": \"success\", \"departure\": departure, \"arrival\": arrival } else: return { \"status\": \"partial\", \"departure\": departure, \"arrival\": arrival, \"message\": \"Trajet incomplet d\u00e9tect\u00e9\" } except InvalidInputError as e: return { \"status\": \"error\", \"error\": \"invalid_input\", \"message\": str(e) } except InsufficientLocationsError as e: return { \"status\": \"error\", \"error\": \"insufficient_locations\", \"message\": \"Au moins 2 villes requises\" } except ModelNotFoundError as e: return { \"status\": \"error\", \"error\": \"model_not_found\", \"message\": \"Ex\u00e9cutez 'trip-train' d'abord\" } except TripExtractionError as e: return { \"status\": \"error\", \"error\": \"extraction_failed\", \"message\": str(e) } # Utilisation result = extract_trip_safe(\"Je vais de Paris \u00e0 Lyon\") print(result) # \u2192 {\"status\": \"success\", \"departure\": \"Paris\", \"arrival\": \"Lyon\"} result = extract_trip_safe(\"Je veux aller \u00e0 Paris\") print(result) # \u2192 {\"status\": \"error\", \"error\": \"insufficient_locations\", ...} Exemples de phrases support\u00e9es Syntaxe simple test_cases = [ \"De Paris \u00e0 Lyon\", \"Paris Lyon\", \"Train de Marseille vers Nice\", \"Vol Toulouse Bordeaux\", \"Aller de Lille \u00e0 Strasbourg\" ] for phrase in test_cases: d, a = parser.parse_trip(phrase) print(f\"{phrase:40} \u2192 {d} \u2192 {a}\") Sortie : De Paris \u00e0 Lyon \u2192 Paris \u2192 Lyon Paris Lyon \u2192 Paris \u2192 Lyon Train de Marseille vers Nice \u2192 Marseille \u2192 Nice Vol Toulouse Bordeaux \u2192 Toulouse \u2192 Bordeaux Aller de Lille \u00e0 Strasbourg \u2192 Lille \u2192 Strasbourg Questions questions = [ \"Comment aller \u00e0 Marseille depuis Toulouse ?\", \"O\u00f9 prendre le train pour Nice depuis Paris ?\", \"Quel est le chemin de Bordeaux vers Nantes ?\", \"Comment je fais pour aller \u00e0 Lille depuis Paris ?\" ] for q in questions: d, a = parser.parse_trip(q) print(f\"{d:15} \u2192 {a:15} | {q}\") Sortie : Toulouse \u2192 Marseille | Comment aller \u00e0 Marseille depuis Toulouse ? Paris \u2192 Nice | O\u00f9 prendre le train pour Nice depuis Paris ? Bordeaux \u2192 Nantes | Quel est le chemin de Bordeaux vers Nantes ? Paris \u2192 Lille | Comment je fais pour aller \u00e0 Lille depuis Paris ? Contexte temporel phrases_contexte = [ \"Demain je vais de Nice \u00e0 Cannes\", \"Train de 8h de Paris \u00e0 Lyon\", \"Vol du matin Toulouse Bordeaux\", \"Je pars lundi de Marseille pour aller \u00e0 Paris\" ] for phrase in phrases_contexte: d, a = parser.parse_trip(phrase) print(f\"{phrase:50} \u2192 {d} \u2192 {a}\") Sortie : Demain je vais de Nice \u00e0 Cannes \u2192 Nice \u2192 Cannes Train de 8h de Paris \u00e0 Lyon \u2192 Paris \u2192 Lyon Vol du matin Toulouse Bordeaux \u2192 Toulouse \u2192 Bordeaux Je pars lundi de Marseille pour aller \u00e0 Paris \u2192 Marseille \u2192 Paris Syntaxe invers\u00e9e inversions = [ \"\u00c0 Lille depuis Paris\", \"Vers Lyon de Paris\", \"Direction Marseille de Toulouse\", \"Pour Nice en partant de Paris\" ] for phrase in inversions: d, a = parser.parse_trip(phrase) print(f\"{phrase:45} \u2192 {d} \u2192 {a}\") Sortie : \u00c0 Lille depuis Paris \u2192 Paris \u2192 Lille Vers Lyon de Paris \u2192 Paris \u2192 Lyon Direction Marseille de Toulouse \u2192 Toulouse \u2192 Marseille Pour Nice en partant de Paris \u2192 Paris \u2192 Nice Traitement par batch Pour traiter plusieurs phrases efficacement : from typing import List, Tuple, Optional from trip_parser import TripParser parser = TripParser() def batch_extract(phrases: List[str]) -> List[Tuple[str, Optional[str], Optional[str]]]: \"\"\" Extrait les trajets pour plusieurs phrases. Args: phrases: Liste de phrases \u00e0 traiter Returns: Liste de tuples (phrase, departure, arrival) \"\"\" results = [] for phrase in phrases: try: departure, arrival = parser.parse_trip(phrase) results.append((phrase, departure, arrival)) except Exception as e: # En cas d'erreur, ajouter None, None results.append((phrase, None, None)) return results # Exemple d'utilisation phrases = [ \"Je vais de Paris \u00e0 Lyon\", \"Train de Marseille \u00e0 Nice\", \"Vol Toulouse Bordeaux\", \"Comment aller \u00e0 Lille ?\", # Ville manquante ] results = batch_extract(phrases) print(\"R\u00c9SULTATS BATCH\") print(\"=\" * 80) for phrase, d, a in results: status = \"\u2705\" if d and a else \"\u274c\" print(f\"{status} {phrase:45} \u2192 {d or '?':12} \u2192 {a or '?'}\") Sortie : R\u00c9SULTATS BATCH ================================================================================ \u2705 Je vais de Paris \u00e0 Lyon \u2192 Paris \u2192 Lyon \u2705 Train de Marseille \u00e0 Nice \u2192 Marseille \u2192 Nice \u2705 Vol Toulouse Bordeaux \u2192 Toulouse \u2192 Bordeaux \u274c Comment aller \u00e0 Lille ? \u2192 ? \u2192 ? Statistiques sur un corpus Analyser un ensemble de phrases pour extraire des statistiques : from collections import Counter from trip_parser import TripParser parser = TripParser() phrases = [ \"De Paris \u00e0 Lyon\", \"Paris Marseille\", \"Lyon Nice\", \"Paris Toulouse\", \"Marseille Paris\", \"Lyon Marseille\", \"Bordeaux Paris\", \"Paris Lyon\" ] # Extraire tous les trajets routes = [] departures = [] arrivals = [] for phrase in phrases: d, a = parser.parse_trip(phrase) if d and a: routes.append(f\"{d} \u2192 {a}\") departures.append(d) arrivals.append(a) # Calculer les statistiques print(\"\ud83d\udcca STATISTIQUES\") print(\"=\" * 60) print(f\"Total phrases: {len(phrases)}\") print(f\"Trajets extraits: {len(routes)}\") print(f\"Taux de succ\u00e8s: {len(routes)/len(phrases)*100:.1f}%\") print(f\"\\n\ud83d\udeeb Villes de d\u00e9part les plus fr\u00e9quentes:\") for city, count in Counter(departures).most_common(3): print(f\" {city:15} : {count} fois\") print(f\"\\n\ud83d\udeec Villes d'arriv\u00e9e les plus fr\u00e9quentes:\") for city, count in Counter(arrivals).most_common(3): print(f\" {city:15} : {count} fois\") print(f\"\\n\ud83d\udd04 Routes les plus fr\u00e9quentes:\") for route, count in Counter(routes).most_common(3): print(f\" {route:25} : {count} fois\") Sortie : \ud83d\udcca STATISTIQUES ============================================================ Total phrases: 8 Trajets extraits: 8 Taux de succ\u00e8s: 100.0% \ud83d\udeeb Villes de d\u00e9part les plus fr\u00e9quentes: Paris : 4 fois Lyon : 2 fois Marseille : 1 fois \ud83d\udeec Villes d'arriv\u00e9e les plus fr\u00e9quentes: Lyon : 2 fois Marseille : 2 fois Paris : 2 fois \ud83d\udd04 Routes les plus fr\u00e9quentes: Paris \u2192 Lyon : 2 fois Lyon \u2192 Marseille : 1 fois Paris \u2192 Marseille : 1 fois Int\u00e9gration dans une classe Exemple d'int\u00e9gration dans une application orient\u00e9e objet : from trip_parser import TripParser from typing import Optional, Dict import logging class TravelService: \"\"\"Service de gestion de voyages avec extraction automatique.\"\"\" def __init__(self): \"\"\"Initialise le service avec le parser.\"\"\" self.parser = TripParser() self.logger = logging.getLogger(__name__) def parse_user_query(self, query: str) -> Dict: \"\"\" Parse une requ\u00eate utilisateur et extrait le trajet. Args: query: Requ\u00eate en langage naturel Returns: Dictionnaire avec les informations du trajet \"\"\" self.logger.info(f\"Processing query: {query}\") try: departure, arrival = self.parser.parse_trip(query) if departure and arrival: return { \"success\": True, \"departure\": departure, \"arrival\": arrival, \"original_query\": query } else: return { \"success\": False, \"error\": \"incomplete_trip\", \"message\": \"Impossible d'extraire un trajet complet\" } except Exception as e: self.logger.error(f\"Error processing query: {e}\") return { \"success\": False, \"error\": \"processing_error\", \"message\": str(e) } def suggest_response(self, query: str) -> str: \"\"\"G\u00e9n\u00e8re une r\u00e9ponse automatique bas\u00e9e sur le trajet extrait.\"\"\" result = self.parse_user_query(query) if result[\"success\"]: d, a = result[\"departure\"], result[\"arrival\"] return ( f\"Je comprends que vous souhaitez voyager \" f\"de {d} \u00e0 {a}. \" f\"Recherche des options disponibles...\" ) else: return \"Pouvez-vous pr\u00e9ciser votre trajet (d\u00e9part et arriv\u00e9e) ?\" # Utilisation service = TravelService() response = service.suggest_response(\"Je veux aller \u00e0 Paris depuis Lyon\") print(response) # \u2192 \"Je comprends que vous souhaitez voyager de Lyon \u00e0 Paris. Recherche...\" response = service.suggest_response(\"Je veux voyager\") print(response) # \u2192 \"Pouvez-vous pr\u00e9ciser votre trajet (d\u00e9part et arriv\u00e9e) ?\" \ud83d\udcbb Interface CLI Lancement de l'interface # Lancer le mode interactif trip-demo Interface compl\u00e8te \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 Trip Extraction Demo v0.1.0 \u2551 \u2551 \u2551 \u2551 Extracts departure & arrival cities \u2551 \u2551 from French sentences using NLP \u2551 \u2551 \u2551 \u2551 Type 'quit' or 'exit' to quit \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d Loading models... Models loaded successfully \u2708\ufe0f Phrase > Je vais de Paris \u00e0 Lyon \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Lyon \u2708\ufe0f Phrase > Comment aller \u00e0 Marseille depuis Toulouse ? \u27a1\ufe0f R\u00e9sultat: Toulouse \u2192 Marseille \u2708\ufe0f Phrase > Demain train de Nice \u00e0 Cannes \u27a1\ufe0f R\u00e9sultat: Nice \u2192 Cannes \u2708\ufe0f Phrase > quit \ud83d\udc4b Au revoir! Cas d'usage de l'interface CLI Tests rapides Id\u00e9al pour : Tester rapidement de nouvelles formulations trip-demo \u2708\ufe0f Phrase > Vol Paris-Marseille demain matin \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Marseille \u2708\ufe0f Phrase > Direction Lyon depuis Toulouse \u27a1\ufe0f R\u00e9sultat: Toulouse \u2192 Lyon D\u00e9monstration Id\u00e9al pour : Montrer les capacit\u00e9s du syst\u00e8me # Pr\u00e9parer une liste de phrases impressionnantes trip-demo \u2708\ufe0f Phrase > Je voudrais prendre le TGV de Paris pour aller \u00e0 Marseille \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Marseille \u2708\ufe0f Phrase > Est-ce qu'il y a un train qui va \u00e0 Nice depuis Lyon ? \u27a1\ufe0f R\u00e9sultat: Lyon \u2192 Nice Debugging Id\u00e9al pour : Identifier les cas probl\u00e9matiques trip-demo \u2708\ufe0f Phrase > Paris \u27a1\ufe0f R\u00e9sultat: \u2717 Pas assez de villes d\u00e9tect\u00e9es \u2708\ufe0f Phrase > Je veux voyager \u27a1\ufe0f R\u00e9sultat: \u2717 Aucune ville d\u00e9tect\u00e9e \ud83c\udf10 API REST D\u00e9marrage du serveur Basique # D\u00e9marrer sur le port par d\u00e9faut (8000) trip-api Port personnalis\u00e9 # D\u00e9marrer sur un port sp\u00e9cifique trip-api --port 8080 Mode d\u00e9veloppement # Mode d\u00e9veloppement avec rechargement automatique trip-api --reload Production # Mode production avec plusieurs workers trip-api --host 0.0.0.0 --port 8000 --workers 4 Sortie attendue : INFO: Starting Trip Parser API... INFO: Preloading models... INFO: Models preloaded successfully INFO: Trip Parser API ready INFO: Started server process [12345] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit) Endpoints disponibles Endpoint M\u00e9thode Description /health GET V\u00e9rifier la sant\u00e9 de l'API /trip/status GET V\u00e9rifier si les mod\u00e8les sont charg\u00e9s /trip/parse POST Extraire d\u00e9part et arriv\u00e9e d'un texte /docs GET Documentation Swagger UI interactive /openapi.json GET Sp\u00e9cification OpenAPI Exemples avec curl Health check curl http://localhost:8000/health R\u00e9ponse : { \"status\": \"healthy\", \"version\": \"0.1.0\" } Status check curl http://localhost:8000/trip/status R\u00e9ponse : { \"models_loaded\": true, \"ready\": true } Parse trip (succ\u00e8s) curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' R\u00e9ponse : { \"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null } Parse trip (\u00e9chec) curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je veux voyager\"}' R\u00e9ponse : { \"departure\": null, \"arrival\": null, \"success\": false, \"message\": \"Could not extract departure and arrival cities from the text\" } Validation error curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"\"}' R\u00e9ponse (HTTP 422) : { \"detail\": [ { \"type\": \"string_too_short\", \"loc\": [\"body\", \"text\"], \"msg\": \"String should have at least 1 character\", \"input\": \"\", \"ctx\": {\"min_length\": 1} } ] } Exemples avec Python (requests) import requests API_URL = \"http://localhost:8000\" def parse_trip_api(text: str) -> dict: \"\"\"Appelle l'API pour extraire un trajet.\"\"\" response = requests.post( f\"{API_URL}/trip/parse\", json={\"text\": text}, headers={\"Content-Type\": \"application/json\"} ) response.raise_for_status() return response.json() # Utilisation result = parse_trip_api(\"Je vais de Paris \u00e0 Lyon\") print(result) # \u2192 {\"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null} # Gestion d'erreurs try: result = parse_trip_api(\"\") except requests.HTTPError as e: print(f\"Erreur HTTP: {e.response.status_code}\") print(e.response.json()) Exemples avec JavaScript (fetch) const API_URL = \"http://localhost:8000\"; async function parseTripAPI(text) { const response = await fetch(`${API_URL}/trip/parse`, { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify({ text: text }) }); if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return await response.json(); } // Utilisation parseTripAPI(\"Je vais de Paris \u00e0 Lyon\") .then(result => { console.log(`D\u00e9part: ${result.departure}`); console.log(`Arriv\u00e9e: ${result.arrival}`); }) .catch(error => { console.error('Erreur:', error); }); Interface Swagger L'API expose automatiquement une interface interactive Swagger UI : http://127.0.0.1:8000/docs Fonctionnalit\u00e9s : Tester tous les endpoints directement depuis le navigateur Voir les sch\u00e9mas de requ\u00eate/r\u00e9ponse G\u00e9n\u00e9rer des exemples de code T\u00e9l\u00e9charger la sp\u00e9cification OpenAPI \u26a1 Bonnes pratiques Performance 1. R\u00e9utiliser l'instance de TripParser # \u274c Mauvais (charge les mod\u00e8les \u00e0 chaque fois) def process(text): parser = TripParser() # ~2-3s de chargement return parser.parse_trip(text) # \u2705 Bon (charge une seule fois) parser = TripParser() # Chargement unique def process(text): return parser.parse_trip(text) # ~100-300ms 2. Utiliser le batch processing pour gros volumes # Traiter 1000 phrases phrases = [...] results = [parser.parse_trip(p) for p in phrases] 3. Consid\u00e9rer l'API REST pour la scalabilit\u00e9 # L'API peut g\u00e9rer plusieurs workers en parall\u00e8le trip-api --workers 4 Gestion d'erreurs from trip_parser.exceptions import TripExtractionError try: departure, arrival = parser.parse_trip(user_input) except TripExtractionError as e: # Gestion sp\u00e9cifique aux erreurs du parser logger.error(f\"Parsing failed: {e}\") except Exception as e: # Gestion des erreurs inattendues logger.error(f\"Unexpected error: {e}\") Validation departure, arrival = parser.parse_trip(text) # V\u00e9rifier que les deux villes sont pr\u00e9sentes if not (departure and arrival): # Demander plus d'informations \u00e0 l'utilisateur return \"Veuillez pr\u00e9ciser votre trajet complet\" # V\u00e9rifier qu'elles sont diff\u00e9rentes if departure == arrival: return \"La ville de d\u00e9part et d'arriv\u00e9e sont identiques\" # Valider que ce sont des villes connues (optionnel) KNOWN_CITIES = [\"Paris\", \"Lyon\", \"Marseille\", ...] if departure not in KNOWN_CITIES: logger.warning(f\"Unknown departure city: {departure}\") \ud83d\udcd6 Ressources suppl\u00e9mentaires Architecture du projet - Comprendre la structure du code Documentation technique - D\u00e9tails des mod\u00e8les ML API REST compl\u00e8te - R\u00e9f\u00e9rence compl\u00e8te de l'API","title":"Guide d'utilisation"},{"location":"guide-usage/#modes-dutilisation","text":"Trip Extraction peut \u00eatre utilis\u00e9 de 3 fa\u00e7ons diff\u00e9rentes selon vos besoins : Mode Usage Avantages Module Python Import dans code Python Int\u00e9gration directe, performances optimales CLI (Interface terminal) Ligne de commande Tests rapides, d\u00e9monstration API REST Requ\u00eates HTTP Multi-langage, microservices, scalabilit\u00e9","title":"\ud83c\udfaf Modes d'utilisation"},{"location":"guide-usage/#module-python","text":"","title":"\ud83d\udc0d Module Python"},{"location":"guide-usage/#utilisation-basique","text":"L'utilisation la plus simple pour int\u00e9grer Trip Extraction dans votre code Python : from trip_parser import TripParser # Initialiser le parser (charge les mod\u00e8les) parser = TripParser() # Extraire un trajet departure, arrival = parser.parse_trip(\"Je vais de Paris \u00e0 Lyon\") print(f\"D\u00e9part: {departure}\") # D\u00e9part: Paris print(f\"Arriv\u00e9e: {arrival}\") # Arriv\u00e9e: Lyon Initialisation unique Cr\u00e9ez une seule instance de TripParser et r\u00e9utilisez-la. Le chargement des mod\u00e8les prend ~2-3 secondes.","title":"Utilisation basique"},{"location":"guide-usage/#gestion-des-cas-derreur","text":"Production-ready avec gestion compl\u00e8te des erreurs : from trip_parser import TripParser from trip_parser.exceptions import ( TripExtractionError, InvalidInputError, InsufficientLocationsError, ModelNotFoundError ) parser = TripParser() def extract_trip_safe(text: str) -> dict: \"\"\"Extraction s\u00e9curis\u00e9e avec gestion d'erreurs.\"\"\" try: departure, arrival = parser.parse_trip(text) if departure and arrival: return { \"status\": \"success\", \"departure\": departure, \"arrival\": arrival } else: return { \"status\": \"partial\", \"departure\": departure, \"arrival\": arrival, \"message\": \"Trajet incomplet d\u00e9tect\u00e9\" } except InvalidInputError as e: return { \"status\": \"error\", \"error\": \"invalid_input\", \"message\": str(e) } except InsufficientLocationsError as e: return { \"status\": \"error\", \"error\": \"insufficient_locations\", \"message\": \"Au moins 2 villes requises\" } except ModelNotFoundError as e: return { \"status\": \"error\", \"error\": \"model_not_found\", \"message\": \"Ex\u00e9cutez 'trip-train' d'abord\" } except TripExtractionError as e: return { \"status\": \"error\", \"error\": \"extraction_failed\", \"message\": str(e) } # Utilisation result = extract_trip_safe(\"Je vais de Paris \u00e0 Lyon\") print(result) # \u2192 {\"status\": \"success\", \"departure\": \"Paris\", \"arrival\": \"Lyon\"} result = extract_trip_safe(\"Je veux aller \u00e0 Paris\") print(result) # \u2192 {\"status\": \"error\", \"error\": \"insufficient_locations\", ...}","title":"Gestion des cas d'erreur"},{"location":"guide-usage/#exemples-de-phrases-supportees","text":"Syntaxe simple test_cases = [ \"De Paris \u00e0 Lyon\", \"Paris Lyon\", \"Train de Marseille vers Nice\", \"Vol Toulouse Bordeaux\", \"Aller de Lille \u00e0 Strasbourg\" ] for phrase in test_cases: d, a = parser.parse_trip(phrase) print(f\"{phrase:40} \u2192 {d} \u2192 {a}\") Sortie : De Paris \u00e0 Lyon \u2192 Paris \u2192 Lyon Paris Lyon \u2192 Paris \u2192 Lyon Train de Marseille vers Nice \u2192 Marseille \u2192 Nice Vol Toulouse Bordeaux \u2192 Toulouse \u2192 Bordeaux Aller de Lille \u00e0 Strasbourg \u2192 Lille \u2192 Strasbourg Questions questions = [ \"Comment aller \u00e0 Marseille depuis Toulouse ?\", \"O\u00f9 prendre le train pour Nice depuis Paris ?\", \"Quel est le chemin de Bordeaux vers Nantes ?\", \"Comment je fais pour aller \u00e0 Lille depuis Paris ?\" ] for q in questions: d, a = parser.parse_trip(q) print(f\"{d:15} \u2192 {a:15} | {q}\") Sortie : Toulouse \u2192 Marseille | Comment aller \u00e0 Marseille depuis Toulouse ? Paris \u2192 Nice | O\u00f9 prendre le train pour Nice depuis Paris ? Bordeaux \u2192 Nantes | Quel est le chemin de Bordeaux vers Nantes ? Paris \u2192 Lille | Comment je fais pour aller \u00e0 Lille depuis Paris ? Contexte temporel phrases_contexte = [ \"Demain je vais de Nice \u00e0 Cannes\", \"Train de 8h de Paris \u00e0 Lyon\", \"Vol du matin Toulouse Bordeaux\", \"Je pars lundi de Marseille pour aller \u00e0 Paris\" ] for phrase in phrases_contexte: d, a = parser.parse_trip(phrase) print(f\"{phrase:50} \u2192 {d} \u2192 {a}\") Sortie : Demain je vais de Nice \u00e0 Cannes \u2192 Nice \u2192 Cannes Train de 8h de Paris \u00e0 Lyon \u2192 Paris \u2192 Lyon Vol du matin Toulouse Bordeaux \u2192 Toulouse \u2192 Bordeaux Je pars lundi de Marseille pour aller \u00e0 Paris \u2192 Marseille \u2192 Paris Syntaxe invers\u00e9e inversions = [ \"\u00c0 Lille depuis Paris\", \"Vers Lyon de Paris\", \"Direction Marseille de Toulouse\", \"Pour Nice en partant de Paris\" ] for phrase in inversions: d, a = parser.parse_trip(phrase) print(f\"{phrase:45} \u2192 {d} \u2192 {a}\") Sortie : \u00c0 Lille depuis Paris \u2192 Paris \u2192 Lille Vers Lyon de Paris \u2192 Paris \u2192 Lyon Direction Marseille de Toulouse \u2192 Toulouse \u2192 Marseille Pour Nice en partant de Paris \u2192 Paris \u2192 Nice","title":"Exemples de phrases support\u00e9es"},{"location":"guide-usage/#traitement-par-batch","text":"Pour traiter plusieurs phrases efficacement : from typing import List, Tuple, Optional from trip_parser import TripParser parser = TripParser() def batch_extract(phrases: List[str]) -> List[Tuple[str, Optional[str], Optional[str]]]: \"\"\" Extrait les trajets pour plusieurs phrases. Args: phrases: Liste de phrases \u00e0 traiter Returns: Liste de tuples (phrase, departure, arrival) \"\"\" results = [] for phrase in phrases: try: departure, arrival = parser.parse_trip(phrase) results.append((phrase, departure, arrival)) except Exception as e: # En cas d'erreur, ajouter None, None results.append((phrase, None, None)) return results # Exemple d'utilisation phrases = [ \"Je vais de Paris \u00e0 Lyon\", \"Train de Marseille \u00e0 Nice\", \"Vol Toulouse Bordeaux\", \"Comment aller \u00e0 Lille ?\", # Ville manquante ] results = batch_extract(phrases) print(\"R\u00c9SULTATS BATCH\") print(\"=\" * 80) for phrase, d, a in results: status = \"\u2705\" if d and a else \"\u274c\" print(f\"{status} {phrase:45} \u2192 {d or '?':12} \u2192 {a or '?'}\") Sortie : R\u00c9SULTATS BATCH ================================================================================ \u2705 Je vais de Paris \u00e0 Lyon \u2192 Paris \u2192 Lyon \u2705 Train de Marseille \u00e0 Nice \u2192 Marseille \u2192 Nice \u2705 Vol Toulouse Bordeaux \u2192 Toulouse \u2192 Bordeaux \u274c Comment aller \u00e0 Lille ? \u2192 ? \u2192 ?","title":"Traitement par batch"},{"location":"guide-usage/#statistiques-sur-un-corpus","text":"Analyser un ensemble de phrases pour extraire des statistiques : from collections import Counter from trip_parser import TripParser parser = TripParser() phrases = [ \"De Paris \u00e0 Lyon\", \"Paris Marseille\", \"Lyon Nice\", \"Paris Toulouse\", \"Marseille Paris\", \"Lyon Marseille\", \"Bordeaux Paris\", \"Paris Lyon\" ] # Extraire tous les trajets routes = [] departures = [] arrivals = [] for phrase in phrases: d, a = parser.parse_trip(phrase) if d and a: routes.append(f\"{d} \u2192 {a}\") departures.append(d) arrivals.append(a) # Calculer les statistiques print(\"\ud83d\udcca STATISTIQUES\") print(\"=\" * 60) print(f\"Total phrases: {len(phrases)}\") print(f\"Trajets extraits: {len(routes)}\") print(f\"Taux de succ\u00e8s: {len(routes)/len(phrases)*100:.1f}%\") print(f\"\\n\ud83d\udeeb Villes de d\u00e9part les plus fr\u00e9quentes:\") for city, count in Counter(departures).most_common(3): print(f\" {city:15} : {count} fois\") print(f\"\\n\ud83d\udeec Villes d'arriv\u00e9e les plus fr\u00e9quentes:\") for city, count in Counter(arrivals).most_common(3): print(f\" {city:15} : {count} fois\") print(f\"\\n\ud83d\udd04 Routes les plus fr\u00e9quentes:\") for route, count in Counter(routes).most_common(3): print(f\" {route:25} : {count} fois\") Sortie : \ud83d\udcca STATISTIQUES ============================================================ Total phrases: 8 Trajets extraits: 8 Taux de succ\u00e8s: 100.0% \ud83d\udeeb Villes de d\u00e9part les plus fr\u00e9quentes: Paris : 4 fois Lyon : 2 fois Marseille : 1 fois \ud83d\udeec Villes d'arriv\u00e9e les plus fr\u00e9quentes: Lyon : 2 fois Marseille : 2 fois Paris : 2 fois \ud83d\udd04 Routes les plus fr\u00e9quentes: Paris \u2192 Lyon : 2 fois Lyon \u2192 Marseille : 1 fois Paris \u2192 Marseille : 1 fois","title":"Statistiques sur un corpus"},{"location":"guide-usage/#integration-dans-une-classe","text":"Exemple d'int\u00e9gration dans une application orient\u00e9e objet : from trip_parser import TripParser from typing import Optional, Dict import logging class TravelService: \"\"\"Service de gestion de voyages avec extraction automatique.\"\"\" def __init__(self): \"\"\"Initialise le service avec le parser.\"\"\" self.parser = TripParser() self.logger = logging.getLogger(__name__) def parse_user_query(self, query: str) -> Dict: \"\"\" Parse une requ\u00eate utilisateur et extrait le trajet. Args: query: Requ\u00eate en langage naturel Returns: Dictionnaire avec les informations du trajet \"\"\" self.logger.info(f\"Processing query: {query}\") try: departure, arrival = self.parser.parse_trip(query) if departure and arrival: return { \"success\": True, \"departure\": departure, \"arrival\": arrival, \"original_query\": query } else: return { \"success\": False, \"error\": \"incomplete_trip\", \"message\": \"Impossible d'extraire un trajet complet\" } except Exception as e: self.logger.error(f\"Error processing query: {e}\") return { \"success\": False, \"error\": \"processing_error\", \"message\": str(e) } def suggest_response(self, query: str) -> str: \"\"\"G\u00e9n\u00e8re une r\u00e9ponse automatique bas\u00e9e sur le trajet extrait.\"\"\" result = self.parse_user_query(query) if result[\"success\"]: d, a = result[\"departure\"], result[\"arrival\"] return ( f\"Je comprends que vous souhaitez voyager \" f\"de {d} \u00e0 {a}. \" f\"Recherche des options disponibles...\" ) else: return \"Pouvez-vous pr\u00e9ciser votre trajet (d\u00e9part et arriv\u00e9e) ?\" # Utilisation service = TravelService() response = service.suggest_response(\"Je veux aller \u00e0 Paris depuis Lyon\") print(response) # \u2192 \"Je comprends que vous souhaitez voyager de Lyon \u00e0 Paris. Recherche...\" response = service.suggest_response(\"Je veux voyager\") print(response) # \u2192 \"Pouvez-vous pr\u00e9ciser votre trajet (d\u00e9part et arriv\u00e9e) ?\"","title":"Int\u00e9gration dans une classe"},{"location":"guide-usage/#interface-cli","text":"","title":"\ud83d\udcbb Interface CLI"},{"location":"guide-usage/#lancement-de-linterface","text":"# Lancer le mode interactif trip-demo","title":"Lancement de l'interface"},{"location":"guide-usage/#interface-complete","text":"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 Trip Extraction Demo v0.1.0 \u2551 \u2551 \u2551 \u2551 Extracts departure & arrival cities \u2551 \u2551 from French sentences using NLP \u2551 \u2551 \u2551 \u2551 Type 'quit' or 'exit' to quit \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d Loading models... Models loaded successfully \u2708\ufe0f Phrase > Je vais de Paris \u00e0 Lyon \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Lyon \u2708\ufe0f Phrase > Comment aller \u00e0 Marseille depuis Toulouse ? \u27a1\ufe0f R\u00e9sultat: Toulouse \u2192 Marseille \u2708\ufe0f Phrase > Demain train de Nice \u00e0 Cannes \u27a1\ufe0f R\u00e9sultat: Nice \u2192 Cannes \u2708\ufe0f Phrase > quit \ud83d\udc4b Au revoir!","title":"Interface compl\u00e8te"},{"location":"guide-usage/#cas-dusage-de-linterface-cli","text":"Tests rapides Id\u00e9al pour : Tester rapidement de nouvelles formulations trip-demo \u2708\ufe0f Phrase > Vol Paris-Marseille demain matin \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Marseille \u2708\ufe0f Phrase > Direction Lyon depuis Toulouse \u27a1\ufe0f R\u00e9sultat: Toulouse \u2192 Lyon D\u00e9monstration Id\u00e9al pour : Montrer les capacit\u00e9s du syst\u00e8me # Pr\u00e9parer une liste de phrases impressionnantes trip-demo \u2708\ufe0f Phrase > Je voudrais prendre le TGV de Paris pour aller \u00e0 Marseille \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Marseille \u2708\ufe0f Phrase > Est-ce qu'il y a un train qui va \u00e0 Nice depuis Lyon ? \u27a1\ufe0f R\u00e9sultat: Lyon \u2192 Nice Debugging Id\u00e9al pour : Identifier les cas probl\u00e9matiques trip-demo \u2708\ufe0f Phrase > Paris \u27a1\ufe0f R\u00e9sultat: \u2717 Pas assez de villes d\u00e9tect\u00e9es \u2708\ufe0f Phrase > Je veux voyager \u27a1\ufe0f R\u00e9sultat: \u2717 Aucune ville d\u00e9tect\u00e9e","title":"Cas d'usage de l'interface CLI"},{"location":"guide-usage/#api-rest","text":"","title":"\ud83c\udf10 API REST"},{"location":"guide-usage/#demarrage-du-serveur","text":"Basique # D\u00e9marrer sur le port par d\u00e9faut (8000) trip-api Port personnalis\u00e9 # D\u00e9marrer sur un port sp\u00e9cifique trip-api --port 8080 Mode d\u00e9veloppement # Mode d\u00e9veloppement avec rechargement automatique trip-api --reload Production # Mode production avec plusieurs workers trip-api --host 0.0.0.0 --port 8000 --workers 4 Sortie attendue : INFO: Starting Trip Parser API... INFO: Preloading models... INFO: Models preloaded successfully INFO: Trip Parser API ready INFO: Started server process [12345] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)","title":"D\u00e9marrage du serveur"},{"location":"guide-usage/#endpoints-disponibles","text":"Endpoint M\u00e9thode Description /health GET V\u00e9rifier la sant\u00e9 de l'API /trip/status GET V\u00e9rifier si les mod\u00e8les sont charg\u00e9s /trip/parse POST Extraire d\u00e9part et arriv\u00e9e d'un texte /docs GET Documentation Swagger UI interactive /openapi.json GET Sp\u00e9cification OpenAPI","title":"Endpoints disponibles"},{"location":"guide-usage/#exemples-avec-curl","text":"Health check curl http://localhost:8000/health R\u00e9ponse : { \"status\": \"healthy\", \"version\": \"0.1.0\" } Status check curl http://localhost:8000/trip/status R\u00e9ponse : { \"models_loaded\": true, \"ready\": true } Parse trip (succ\u00e8s) curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' R\u00e9ponse : { \"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null } Parse trip (\u00e9chec) curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je veux voyager\"}' R\u00e9ponse : { \"departure\": null, \"arrival\": null, \"success\": false, \"message\": \"Could not extract departure and arrival cities from the text\" } Validation error curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"\"}' R\u00e9ponse (HTTP 422) : { \"detail\": [ { \"type\": \"string_too_short\", \"loc\": [\"body\", \"text\"], \"msg\": \"String should have at least 1 character\", \"input\": \"\", \"ctx\": {\"min_length\": 1} } ] }","title":"Exemples avec curl"},{"location":"guide-usage/#exemples-avec-python-requests","text":"import requests API_URL = \"http://localhost:8000\" def parse_trip_api(text: str) -> dict: \"\"\"Appelle l'API pour extraire un trajet.\"\"\" response = requests.post( f\"{API_URL}/trip/parse\", json={\"text\": text}, headers={\"Content-Type\": \"application/json\"} ) response.raise_for_status() return response.json() # Utilisation result = parse_trip_api(\"Je vais de Paris \u00e0 Lyon\") print(result) # \u2192 {\"departure\": \"Paris\", \"arrival\": \"Lyon\", \"success\": true, \"message\": null} # Gestion d'erreurs try: result = parse_trip_api(\"\") except requests.HTTPError as e: print(f\"Erreur HTTP: {e.response.status_code}\") print(e.response.json())","title":"Exemples avec Python (requests)"},{"location":"guide-usage/#exemples-avec-javascript-fetch","text":"const API_URL = \"http://localhost:8000\"; async function parseTripAPI(text) { const response = await fetch(`${API_URL}/trip/parse`, { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify({ text: text }) }); if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return await response.json(); } // Utilisation parseTripAPI(\"Je vais de Paris \u00e0 Lyon\") .then(result => { console.log(`D\u00e9part: ${result.departure}`); console.log(`Arriv\u00e9e: ${result.arrival}`); }) .catch(error => { console.error('Erreur:', error); });","title":"Exemples avec JavaScript (fetch)"},{"location":"guide-usage/#interface-swagger","text":"L'API expose automatiquement une interface interactive Swagger UI : http://127.0.0.1:8000/docs Fonctionnalit\u00e9s : Tester tous les endpoints directement depuis le navigateur Voir les sch\u00e9mas de requ\u00eate/r\u00e9ponse G\u00e9n\u00e9rer des exemples de code T\u00e9l\u00e9charger la sp\u00e9cification OpenAPI","title":"Interface Swagger"},{"location":"guide-usage/#bonnes-pratiques","text":"","title":"\u26a1 Bonnes pratiques"},{"location":"guide-usage/#performance","text":"1. R\u00e9utiliser l'instance de TripParser # \u274c Mauvais (charge les mod\u00e8les \u00e0 chaque fois) def process(text): parser = TripParser() # ~2-3s de chargement return parser.parse_trip(text) # \u2705 Bon (charge une seule fois) parser = TripParser() # Chargement unique def process(text): return parser.parse_trip(text) # ~100-300ms 2. Utiliser le batch processing pour gros volumes # Traiter 1000 phrases phrases = [...] results = [parser.parse_trip(p) for p in phrases] 3. Consid\u00e9rer l'API REST pour la scalabilit\u00e9 # L'API peut g\u00e9rer plusieurs workers en parall\u00e8le trip-api --workers 4","title":"Performance"},{"location":"guide-usage/#gestion-derreurs","text":"from trip_parser.exceptions import TripExtractionError try: departure, arrival = parser.parse_trip(user_input) except TripExtractionError as e: # Gestion sp\u00e9cifique aux erreurs du parser logger.error(f\"Parsing failed: {e}\") except Exception as e: # Gestion des erreurs inattendues logger.error(f\"Unexpected error: {e}\")","title":"Gestion d'erreurs"},{"location":"guide-usage/#validation","text":"departure, arrival = parser.parse_trip(text) # V\u00e9rifier que les deux villes sont pr\u00e9sentes if not (departure and arrival): # Demander plus d'informations \u00e0 l'utilisateur return \"Veuillez pr\u00e9ciser votre trajet complet\" # V\u00e9rifier qu'elles sont diff\u00e9rentes if departure == arrival: return \"La ville de d\u00e9part et d'arriv\u00e9e sont identiques\" # Valider que ce sont des villes connues (optionnel) KNOWN_CITIES = [\"Paris\", \"Lyon\", \"Marseille\", ...] if departure not in KNOWN_CITIES: logger.warning(f\"Unknown departure city: {departure}\")","title":"Validation"},{"location":"guide-usage/#ressources-supplementaires","text":"Architecture du projet - Comprendre la structure du code Documentation technique - D\u00e9tails des mod\u00e8les ML API REST compl\u00e8te - R\u00e9f\u00e9rence compl\u00e8te de l'API","title":"\ud83d\udcd6 Ressources suppl\u00e9mentaires"},{"location":"installation/","text":"Ce guide vous accompagne pas \u00e0 pas dans l'installation et la configuration de Trip Extraction sur votre machine de d\u00e9veloppement. \u2699\ufe0f Pr\u00e9requis syst\u00e8me Versions requises Python Version minimale : Python 3.11 V\u00e9rification : python --version # ou python3 --version Python 3.10 et inf\u00e9rieur Le projet utilise des fonctionnalit\u00e9s modernes de Python (Union types avec | , etc.) qui n\u00e9cessitent Python 3.11+. Si vous avez une version inf\u00e9rieure, mettez \u00e0 jour Python avant de continuer. Installation de Python 3.11+ : # macOS (via Homebrew) brew install python@3.11 # Linux (Ubuntu/Debian) sudo apt update sudo apt install python3.11 python3.11-venv python3.11-dev # Windows # T\u00e9l\u00e9charger depuis python.org Git Pour : Cloner le repository # V\u00e9rification git --version # Installation si n\u00e9cessaire # macOS brew install git # Linux sudo apt install git # Windows # T\u00e9l\u00e9charger depuis git-scm.com pip Pour : Gestion des d\u00e9pendances Python # V\u00e9rification pip --version # ou pip3 --version # Mise \u00e0 jour python -m pip install --upgrade pip Espace disque requis Composant Taille Description Code source ~10 MB Fichiers Python, configuration D\u00e9pendances Python ~500 MB PyTorch, Transformers, etc. Mod\u00e8les ML ~1.5 GB CamemBERT NER + Classifier Total estim\u00e9 ~2 GB Espace total n\u00e9cessaire Configuration mat\u00e9rielle recommand\u00e9e CPU seulement Minimum : CPU : 2 c\u0153urs RAM : 4 GB Temps de traitement : ~300ms par phrase Recommand\u00e9 : CPU : 4+ c\u0153urs RAM : 8 GB Temps de traitement : ~150ms par phrase Avec GPU (optionnel) Si vous avez un GPU CUDA : GPU : NVIDIA avec 4+ GB VRAM CUDA : 11.8 ou 12.x Temps de traitement : ~50-100ms par phrase Installation CUDA : # V\u00e9rifier si CUDA est disponible python -c \"import torch; print(torch.cuda.is_available())\" # Si False, installer PyTorch avec CUDA pip install torch --index-url https://download.pytorch.org/whl/cu118 GPU non requis Le syst\u00e8me fonctionne parfaitement sur CPU. Le GPU n'est utile que pour acc\u00e9l\u00e9rer les traitements en production avec gros volume. \ud83d\udce5 Installation du projet \u00c9tape 1 : Cloner le repository # Cloner le projet git clone <repo-url> cd bootstrap # V\u00e9rifier que vous \u00eates dans le bon dossier pwd # Devrait afficher : .../bootstrap ls # Devrait montrer : src/ docs/ scripts/ pyproject.toml README.md etc. \u00c9tape 2 : Cr\u00e9er l'environnement virtuel Pourquoi un environnement virtuel ? Un environnement virtuel isole les d\u00e9pendances du projet et \u00e9vite les conflits avec d'autres projets Python sur votre machine. fish shell # Cr\u00e9er l'environnement python -m venv .venv # Activer l'environnement source .venv/bin/activate.fish # V\u00e9rifier l'activation (le prompt doit changer) # (.venv) ~/bootstrap $ bash/zsh # Cr\u00e9er l'environnement python -m venv .venv # Activer l'environnement source .venv/bin/activate # V\u00e9rifier l'activation (le prompt doit changer) # (.venv) ~/bootstrap $ Windows # Cr\u00e9er l'environnement python -m venv .venv # Activer l'environnement .venv\\Scripts\\activate # V\u00e9rifier l'activation (le prompt doit changer) # (.venv) C:\\...\\bootstrap> Toujours activer l'environnement Vous devez activer l'environnement virtuel \u00e0 chaque nouvelle session terminal avant d'utiliser le projet. \u00c9tape 3 : Installer les d\u00e9pendances # S'assurer que pip est \u00e0 jour pip install --upgrade pip # Installer le projet en mode \u00e9ditable pip install -e . Installation en mode \u00e9ditable ( -e ) Le flag -e permet de modifier le code source sans r\u00e9installer le package. Parfait pour le d\u00e9veloppement ! D\u00e9tails des d\u00e9pendances install\u00e9es D\u00e9pendances principales (voir pyproject.toml ) : transformers (4.36.0+) : Biblioth\u00e8que Hugging Face pour les mod\u00e8les NLP torch (2.1.0+) : PyTorch pour le deep learning sentencepiece (0.1.99+) : Tokenizer pour CamemBERT numpy (1.24.0+) : Calculs num\u00e9riques scikit-learn (1.3.0+) : M\u00e9triques et split de donn\u00e9es fastapi (0.109.0+) : Framework API REST uvicorn (0.27.0+) : Serveur ASGI pour FastAPI pydantic (2.5.0+) : Validation de donn\u00e9es Optionnelles : # Outils de d\u00e9veloppement pip install -e \".[dev]\" # black, ruff, mypy, ipython # Documentation pip install -e \".[docs]\" # mkdocs, mkdocs-shadcn \u00c9tape 4 : Entra\u00eener le classifier \u00c9tape obligatoire Le classifier de d\u00e9part/arriv\u00e9e doit \u00eatre entra\u00een\u00e9 avant la premi\u00e8re utilisation . Le mod\u00e8le NER sera t\u00e9l\u00e9charg\u00e9 automatiquement depuis Hugging Face, mais le classifier personnalis\u00e9 doit \u00eatre cr\u00e9\u00e9 localement. # Entra\u00eener le classifier trip-train Ce que fait cette commande : Charge les donn\u00e9es depuis data/training_dataset.json Split en train/validation (80/20) Fine-tune CamemBERT sur vos donn\u00e9es Sauvegarde le mod\u00e8le dans models/departure_arrival_classifier/ Affiche les m\u00e9triques de performance Sortie attendue : Loading training data from data/training_dataset.json... Loaded 1200 examples Preparing dataset... Train size: 960, Validation size: 240 Training model... Epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:23<00:00] Epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:21<00:00] Epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:22<00:00] Evaluating model... Accuracy: 96.25% Precision: 97.1% Recall: 96.8% F1-Score: 96.9% Model saved to models/departure_arrival_classifier/ Training completed successfully! Troubleshooting : Erreur durant l'entra\u00eenement Probl\u00e8me : FileNotFoundError: data/training_dataset.json # V\u00e9rifier que le fichier existe ls data/training_dataset.json # S'il manque, le dataset doit \u00eatre fourni Probl\u00e8me : RuntimeError: CUDA out of memory # R\u00e9duire la batch size dans scripts/train.py # Ligne ~200 : per_device_train_batch_size=8 \u2192 per_device_train_batch_size=4 Probl\u00e8me : ImportError: No module named 'transformers' # R\u00e9installer les d\u00e9pendances pip install -e . \u00c9tape 5 : V\u00e9rifier l'installation # Test 1 : V\u00e9rifier que les commandes sont disponibles which trip-demo which trip-train which trip-api # Test 2 : Lancer le mode d\u00e9mo trip-demo Interface demo attendue : \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 Trip Extraction Demo v0.1.0 \u2551 \u2551 \u2551 \u2551 Extracts departure & arrival cities \u2551 \u2551 from French sentences using NLP \u2551 \u2551 \u2551 \u2551 Type 'quit' or 'exit' to quit \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d Loading models... Models loaded successfully \u2708\ufe0f Phrase > Je vais de Paris \u00e0 Lyon \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Lyon \u2708\ufe0f Phrase > quit \ud83d\udc4b Au revoir! Installation termin\u00e9e ! Si trip-demo fonctionne correctement, votre installation est compl\u00e8te ! \ud83c\udf89 \ud83d\udd27 Configuration post-installation Configuration des chemins Le syst\u00e8me utilise des chemins absolus configur\u00e9s dans src/trip_parser/config.py . from trip_parser import get_config config = get_config() # Afficher les chemins print(f\"Project root: {config.paths.PROJECT_ROOT}\") print(f\"Models dir: {config.paths.models_dir}\") print(f\"Data dir: {config.paths.data_dir}\") print(f\"Logs dir: {config.paths.logs_dir}\") Sortie exemple : Project root: /Users/natchi/Epitech/T-AIA-911/bootstrap Models dir: /Users/natchi/Epitech/T-AIA-911/bootstrap/models Data dir: /Users/natchi/Epitech/T-AIA-911/bootstrap/data Logs dir: /Users/natchi/Epitech/T-AIA-911/bootstrap/logs Chemins relatifs automatiques Les chemins sont calcul\u00e9s automatiquement depuis PROJECT_ROOT . Pas besoin de configuration manuelle ! Configuration des mod\u00e8les from trip_parser import get_config config = get_config() # Mod\u00e8le NER print(config.model.ner_model_name) # \u2192 \"Jean-Baptiste/camembert-ner\" # Seuil de confiance print(config.model.confidence_threshold) # \u2192 0.5 # Modifier le seuil (optionnel) config.model.confidence_threshold = 0.7 Configurer le logging Niveau de logging from trip_parser.utils import setup_logging import logging # Mode d\u00e9veloppement (verbose) setup_logging(level=logging.DEBUG) # Mode production (erreurs seulement) setup_logging(level=logging.ERROR) Fichier de logs from trip_parser.utils import setup_logging # \u00c9crire les logs dans un fichier setup_logging( level=logging.INFO, log_file=\"logs/trip_parser.log\" ) Format personnalis\u00e9 import logging logging.basicConfig( level=logging.INFO, format=\"%(asctime)s | %(name)s | %(levelname)s | %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\" ) \ud83e\uddea Tests de validation Test du module trip_parser # test_installation.py from trip_parser import TripParser def test_basic_parsing(): parser = TripParser() # Test 1 : Syntaxe simple d, a = parser.parse_trip(\"De Paris \u00e0 Lyon\") assert d == \"Paris\" and a == \"Lyon\", \"Failed: simple syntax\" # Test 2 : Question d, a = parser.parse_trip(\"Comment aller \u00e0 Marseille depuis Toulouse ?\") assert d == \"Toulouse\" and a == \"Marseille\", \"Failed: question syntax\" # Test 3 : Contexte temporel d, a = parser.parse_trip(\"Demain je vais de Nice \u00e0 Cannes\") assert d == \"Nice\" and a == \"Cannes\", \"Failed: temporal context\" print(\"\u2705 All tests passed!\") if __name__ == \"__main__\": test_basic_parsing() # Ex\u00e9cuter les tests python test_installation.py Test de l'API REST Terminal 1 : D\u00e9marrer l'API # Lancer le serveur trip-api # Devrait afficher : # INFO: Started server process # INFO: Uvicorn running on http://127.0.0.1:8000 Terminal 2 : Tester avec curl # Test de sant\u00e9 curl http://localhost:8000/health # \u2192 {\"status\":\"healthy\",\"version\":\"0.1.0\"} # Test d'extraction curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' # \u2192 {\"departure\":\"Paris\",\"arrival\":\"Lyon\",\"success\":true,\"message\":null} # Test de statut curl http://localhost:8000/trip/status # \u2192 {\"models_loaded\":true,\"ready\":true} Navigateur : Swagger UI Ouvrir dans un navigateur : http://127.0.0.1:8000/docs Tester directement depuis l'interface Swagger : Cliquer sur POST /trip/parse Cliquer sur \"Try it out\" Entrer {\"text\": \"Je vais de Paris \u00e0 Lyon\"} Cliquer sur \"Execute\" V\u00e9rifier la r\u00e9ponse \ud83d\udd0d D\u00e9pannage (Troubleshooting) Probl\u00e8me : ModuleNotFoundError ModuleNotFoundError: No module named 'trip_parser' Cause : Le package n'est pas install\u00e9 ou l'environnement virtuel n'est pas activ\u00e9 Solution : # 1. V\u00e9rifier que l'environnement est activ\u00e9 which python # Doit afficher : .../bootstrap/.venv/bin/python # 2. R\u00e9installer le package pip install -e . # 3. V\u00e9rifier l'installation pip list | grep trip-parser Probl\u00e8me : ModelNotFoundError ModelNotFoundError: Model not found at 'models/departure_arrival_classifier' Cause : Le classifier n'a pas \u00e9t\u00e9 entra\u00een\u00e9 Solution : # Entra\u00eener le classifier trip-train # V\u00e9rifier que le mod\u00e8le existe ls models/departure_arrival_classifier/ # Doit montrer : config.json, model.safetensors, tokenizer_config.json, etc. Probl\u00e8me : T\u00e9l\u00e9chargement lent du mod\u00e8le NER Downloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 440M/440M [15:23<00:00, 476kB/s] Cause : Premi\u00e8re utilisation, le mod\u00e8le CamemBERT NER est t\u00e9l\u00e9charg\u00e9 depuis Hugging Face Solution : # Option 1 : Patienter (t\u00e9l\u00e9chargement unique) # Les prochaines utilisations seront instantan\u00e9es (cache) # Option 2 : T\u00e9l\u00e9charger manuellement python -c \" from transformers import pipeline ner = pipeline('ner', model='Jean-Baptiste/camembert-ner') print('Model cached!') \" Probl\u00e8me : CUDA out of memory RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB Cause : GPU n'a pas assez de VRAM Solution : # Option 1 : Forcer l'utilisation du CPU export CUDA_VISIBLE_DEVICES=\"\" python scripts/train.py # Option 2 : R\u00e9duire la batch size # \u00c9diter scripts/train.py ligne ~200 # per_device_train_batch_size=8 \u2192 per_device_train_batch_size=2 Probl\u00e8me : Permission denied sur scripts -bash: trip-demo: command not found Cause : Les scripts ne sont pas dans le PATH ou pas ex\u00e9cutables Solution : # R\u00e9installer le package pip install -e . # V\u00e9rifier que les scripts sont install\u00e9s pip show trip-parser | grep Location ls $(pip show trip-parser | grep Location | cut -d' ' -f2)/../../../bin/trip-* Probl\u00e8me : Port 8000 d\u00e9j\u00e0 utilis\u00e9 ERROR: [Errno 48] Address already in use Cause : Un autre processus utilise le port 8000 Solution : # Option 1 : Utiliser un autre port trip-api --port 8001 # Option 2 : Tuer le processus qui utilise le port 8000 # macOS/Linux lsof -ti:8000 | xargs kill -9 # V\u00e9rifier que le port est libre lsof -i:8000","title":"Installation"},{"location":"installation/#prerequis-systeme","text":"","title":"\u2699\ufe0f Pr\u00e9requis syst\u00e8me"},{"location":"installation/#versions-requises","text":"Python Version minimale : Python 3.11 V\u00e9rification : python --version # ou python3 --version Python 3.10 et inf\u00e9rieur Le projet utilise des fonctionnalit\u00e9s modernes de Python (Union types avec | , etc.) qui n\u00e9cessitent Python 3.11+. Si vous avez une version inf\u00e9rieure, mettez \u00e0 jour Python avant de continuer. Installation de Python 3.11+ : # macOS (via Homebrew) brew install python@3.11 # Linux (Ubuntu/Debian) sudo apt update sudo apt install python3.11 python3.11-venv python3.11-dev # Windows # T\u00e9l\u00e9charger depuis python.org Git Pour : Cloner le repository # V\u00e9rification git --version # Installation si n\u00e9cessaire # macOS brew install git # Linux sudo apt install git # Windows # T\u00e9l\u00e9charger depuis git-scm.com pip Pour : Gestion des d\u00e9pendances Python # V\u00e9rification pip --version # ou pip3 --version # Mise \u00e0 jour python -m pip install --upgrade pip","title":"Versions requises"},{"location":"installation/#espace-disque-requis","text":"Composant Taille Description Code source ~10 MB Fichiers Python, configuration D\u00e9pendances Python ~500 MB PyTorch, Transformers, etc. Mod\u00e8les ML ~1.5 GB CamemBERT NER + Classifier Total estim\u00e9 ~2 GB Espace total n\u00e9cessaire","title":"Espace disque requis"},{"location":"installation/#configuration-materielle-recommandee","text":"CPU seulement Minimum : CPU : 2 c\u0153urs RAM : 4 GB Temps de traitement : ~300ms par phrase Recommand\u00e9 : CPU : 4+ c\u0153urs RAM : 8 GB Temps de traitement : ~150ms par phrase Avec GPU (optionnel) Si vous avez un GPU CUDA : GPU : NVIDIA avec 4+ GB VRAM CUDA : 11.8 ou 12.x Temps de traitement : ~50-100ms par phrase Installation CUDA : # V\u00e9rifier si CUDA est disponible python -c \"import torch; print(torch.cuda.is_available())\" # Si False, installer PyTorch avec CUDA pip install torch --index-url https://download.pytorch.org/whl/cu118 GPU non requis Le syst\u00e8me fonctionne parfaitement sur CPU. Le GPU n'est utile que pour acc\u00e9l\u00e9rer les traitements en production avec gros volume.","title":"Configuration mat\u00e9rielle recommand\u00e9e"},{"location":"installation/#installation-du-projet","text":"","title":"\ud83d\udce5 Installation du projet"},{"location":"installation/#etape-1-cloner-le-repository","text":"# Cloner le projet git clone <repo-url> cd bootstrap # V\u00e9rifier que vous \u00eates dans le bon dossier pwd # Devrait afficher : .../bootstrap ls # Devrait montrer : src/ docs/ scripts/ pyproject.toml README.md etc.","title":"\u00c9tape 1 : Cloner le repository"},{"location":"installation/#etape-2-creer-lenvironnement-virtuel","text":"Pourquoi un environnement virtuel ? Un environnement virtuel isole les d\u00e9pendances du projet et \u00e9vite les conflits avec d'autres projets Python sur votre machine. fish shell # Cr\u00e9er l'environnement python -m venv .venv # Activer l'environnement source .venv/bin/activate.fish # V\u00e9rifier l'activation (le prompt doit changer) # (.venv) ~/bootstrap $ bash/zsh # Cr\u00e9er l'environnement python -m venv .venv # Activer l'environnement source .venv/bin/activate # V\u00e9rifier l'activation (le prompt doit changer) # (.venv) ~/bootstrap $ Windows # Cr\u00e9er l'environnement python -m venv .venv # Activer l'environnement .venv\\Scripts\\activate # V\u00e9rifier l'activation (le prompt doit changer) # (.venv) C:\\...\\bootstrap> Toujours activer l'environnement Vous devez activer l'environnement virtuel \u00e0 chaque nouvelle session terminal avant d'utiliser le projet.","title":"\u00c9tape 2 : Cr\u00e9er l'environnement virtuel"},{"location":"installation/#etape-3-installer-les-dependances","text":"# S'assurer que pip est \u00e0 jour pip install --upgrade pip # Installer le projet en mode \u00e9ditable pip install -e . Installation en mode \u00e9ditable ( -e ) Le flag -e permet de modifier le code source sans r\u00e9installer le package. Parfait pour le d\u00e9veloppement ! D\u00e9tails des d\u00e9pendances install\u00e9es D\u00e9pendances principales (voir pyproject.toml ) : transformers (4.36.0+) : Biblioth\u00e8que Hugging Face pour les mod\u00e8les NLP torch (2.1.0+) : PyTorch pour le deep learning sentencepiece (0.1.99+) : Tokenizer pour CamemBERT numpy (1.24.0+) : Calculs num\u00e9riques scikit-learn (1.3.0+) : M\u00e9triques et split de donn\u00e9es fastapi (0.109.0+) : Framework API REST uvicorn (0.27.0+) : Serveur ASGI pour FastAPI pydantic (2.5.0+) : Validation de donn\u00e9es Optionnelles : # Outils de d\u00e9veloppement pip install -e \".[dev]\" # black, ruff, mypy, ipython # Documentation pip install -e \".[docs]\" # mkdocs, mkdocs-shadcn","title":"\u00c9tape 3 : Installer les d\u00e9pendances"},{"location":"installation/#etape-4-entrainer-le-classifier","text":"\u00c9tape obligatoire Le classifier de d\u00e9part/arriv\u00e9e doit \u00eatre entra\u00een\u00e9 avant la premi\u00e8re utilisation . Le mod\u00e8le NER sera t\u00e9l\u00e9charg\u00e9 automatiquement depuis Hugging Face, mais le classifier personnalis\u00e9 doit \u00eatre cr\u00e9\u00e9 localement. # Entra\u00eener le classifier trip-train Ce que fait cette commande : Charge les donn\u00e9es depuis data/training_dataset.json Split en train/validation (80/20) Fine-tune CamemBERT sur vos donn\u00e9es Sauvegarde le mod\u00e8le dans models/departure_arrival_classifier/ Affiche les m\u00e9triques de performance Sortie attendue : Loading training data from data/training_dataset.json... Loaded 1200 examples Preparing dataset... Train size: 960, Validation size: 240 Training model... Epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:23<00:00] Epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:21<00:00] Epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:22<00:00] Evaluating model... Accuracy: 96.25% Precision: 97.1% Recall: 96.8% F1-Score: 96.9% Model saved to models/departure_arrival_classifier/ Training completed successfully! Troubleshooting : Erreur durant l'entra\u00eenement Probl\u00e8me : FileNotFoundError: data/training_dataset.json # V\u00e9rifier que le fichier existe ls data/training_dataset.json # S'il manque, le dataset doit \u00eatre fourni Probl\u00e8me : RuntimeError: CUDA out of memory # R\u00e9duire la batch size dans scripts/train.py # Ligne ~200 : per_device_train_batch_size=8 \u2192 per_device_train_batch_size=4 Probl\u00e8me : ImportError: No module named 'transformers' # R\u00e9installer les d\u00e9pendances pip install -e .","title":"\u00c9tape 4 : Entra\u00eener le classifier"},{"location":"installation/#etape-5-verifier-linstallation","text":"# Test 1 : V\u00e9rifier que les commandes sont disponibles which trip-demo which trip-train which trip-api # Test 2 : Lancer le mode d\u00e9mo trip-demo Interface demo attendue : \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 Trip Extraction Demo v0.1.0 \u2551 \u2551 \u2551 \u2551 Extracts departure & arrival cities \u2551 \u2551 from French sentences using NLP \u2551 \u2551 \u2551 \u2551 Type 'quit' or 'exit' to quit \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d Loading models... Models loaded successfully \u2708\ufe0f Phrase > Je vais de Paris \u00e0 Lyon \u27a1\ufe0f R\u00e9sultat: Paris \u2192 Lyon \u2708\ufe0f Phrase > quit \ud83d\udc4b Au revoir! Installation termin\u00e9e ! Si trip-demo fonctionne correctement, votre installation est compl\u00e8te ! \ud83c\udf89","title":"\u00c9tape 5 : V\u00e9rifier l'installation"},{"location":"installation/#configuration-post-installation","text":"","title":"\ud83d\udd27 Configuration post-installation"},{"location":"installation/#configuration-des-chemins","text":"Le syst\u00e8me utilise des chemins absolus configur\u00e9s dans src/trip_parser/config.py . from trip_parser import get_config config = get_config() # Afficher les chemins print(f\"Project root: {config.paths.PROJECT_ROOT}\") print(f\"Models dir: {config.paths.models_dir}\") print(f\"Data dir: {config.paths.data_dir}\") print(f\"Logs dir: {config.paths.logs_dir}\") Sortie exemple : Project root: /Users/natchi/Epitech/T-AIA-911/bootstrap Models dir: /Users/natchi/Epitech/T-AIA-911/bootstrap/models Data dir: /Users/natchi/Epitech/T-AIA-911/bootstrap/data Logs dir: /Users/natchi/Epitech/T-AIA-911/bootstrap/logs Chemins relatifs automatiques Les chemins sont calcul\u00e9s automatiquement depuis PROJECT_ROOT . Pas besoin de configuration manuelle !","title":"Configuration des chemins"},{"location":"installation/#configuration-des-modeles","text":"from trip_parser import get_config config = get_config() # Mod\u00e8le NER print(config.model.ner_model_name) # \u2192 \"Jean-Baptiste/camembert-ner\" # Seuil de confiance print(config.model.confidence_threshold) # \u2192 0.5 # Modifier le seuil (optionnel) config.model.confidence_threshold = 0.7","title":"Configuration des mod\u00e8les"},{"location":"installation/#configurer-le-logging","text":"Niveau de logging from trip_parser.utils import setup_logging import logging # Mode d\u00e9veloppement (verbose) setup_logging(level=logging.DEBUG) # Mode production (erreurs seulement) setup_logging(level=logging.ERROR) Fichier de logs from trip_parser.utils import setup_logging # \u00c9crire les logs dans un fichier setup_logging( level=logging.INFO, log_file=\"logs/trip_parser.log\" ) Format personnalis\u00e9 import logging logging.basicConfig( level=logging.INFO, format=\"%(asctime)s | %(name)s | %(levelname)s | %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\" )","title":"Configurer le logging"},{"location":"installation/#tests-de-validation","text":"","title":"\ud83e\uddea Tests de validation"},{"location":"installation/#test-du-module-trip_parser","text":"# test_installation.py from trip_parser import TripParser def test_basic_parsing(): parser = TripParser() # Test 1 : Syntaxe simple d, a = parser.parse_trip(\"De Paris \u00e0 Lyon\") assert d == \"Paris\" and a == \"Lyon\", \"Failed: simple syntax\" # Test 2 : Question d, a = parser.parse_trip(\"Comment aller \u00e0 Marseille depuis Toulouse ?\") assert d == \"Toulouse\" and a == \"Marseille\", \"Failed: question syntax\" # Test 3 : Contexte temporel d, a = parser.parse_trip(\"Demain je vais de Nice \u00e0 Cannes\") assert d == \"Nice\" and a == \"Cannes\", \"Failed: temporal context\" print(\"\u2705 All tests passed!\") if __name__ == \"__main__\": test_basic_parsing() # Ex\u00e9cuter les tests python test_installation.py","title":"Test du module trip_parser"},{"location":"installation/#test-de-lapi-rest","text":"Terminal 1 : D\u00e9marrer l'API # Lancer le serveur trip-api # Devrait afficher : # INFO: Started server process # INFO: Uvicorn running on http://127.0.0.1:8000 Terminal 2 : Tester avec curl # Test de sant\u00e9 curl http://localhost:8000/health # \u2192 {\"status\":\"healthy\",\"version\":\"0.1.0\"} # Test d'extraction curl -X POST http://localhost:8000/trip/parse \\ -H \"Content-Type: application/json\" \\ -d '{\"text\": \"Je vais de Paris \u00e0 Lyon\"}' # \u2192 {\"departure\":\"Paris\",\"arrival\":\"Lyon\",\"success\":true,\"message\":null} # Test de statut curl http://localhost:8000/trip/status # \u2192 {\"models_loaded\":true,\"ready\":true} Navigateur : Swagger UI Ouvrir dans un navigateur : http://127.0.0.1:8000/docs Tester directement depuis l'interface Swagger : Cliquer sur POST /trip/parse Cliquer sur \"Try it out\" Entrer {\"text\": \"Je vais de Paris \u00e0 Lyon\"} Cliquer sur \"Execute\" V\u00e9rifier la r\u00e9ponse","title":"Test de l'API REST"},{"location":"installation/#depannage-troubleshooting","text":"","title":"\ud83d\udd0d D\u00e9pannage (Troubleshooting)"},{"location":"installation/#probleme-modulenotfounderror","text":"ModuleNotFoundError: No module named 'trip_parser' Cause : Le package n'est pas install\u00e9 ou l'environnement virtuel n'est pas activ\u00e9 Solution : # 1. V\u00e9rifier que l'environnement est activ\u00e9 which python # Doit afficher : .../bootstrap/.venv/bin/python # 2. R\u00e9installer le package pip install -e . # 3. V\u00e9rifier l'installation pip list | grep trip-parser","title":"Probl\u00e8me : ModuleNotFoundError"},{"location":"installation/#probleme-modelnotfounderror","text":"ModelNotFoundError: Model not found at 'models/departure_arrival_classifier' Cause : Le classifier n'a pas \u00e9t\u00e9 entra\u00een\u00e9 Solution : # Entra\u00eener le classifier trip-train # V\u00e9rifier que le mod\u00e8le existe ls models/departure_arrival_classifier/ # Doit montrer : config.json, model.safetensors, tokenizer_config.json, etc.","title":"Probl\u00e8me : ModelNotFoundError"},{"location":"installation/#probleme-telechargement-lent-du-modele-ner","text":"Downloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 440M/440M [15:23<00:00, 476kB/s] Cause : Premi\u00e8re utilisation, le mod\u00e8le CamemBERT NER est t\u00e9l\u00e9charg\u00e9 depuis Hugging Face Solution : # Option 1 : Patienter (t\u00e9l\u00e9chargement unique) # Les prochaines utilisations seront instantan\u00e9es (cache) # Option 2 : T\u00e9l\u00e9charger manuellement python -c \" from transformers import pipeline ner = pipeline('ner', model='Jean-Baptiste/camembert-ner') print('Model cached!') \"","title":"Probl\u00e8me : T\u00e9l\u00e9chargement lent du mod\u00e8le NER"},{"location":"installation/#probleme-cuda-out-of-memory","text":"RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB Cause : GPU n'a pas assez de VRAM Solution : # Option 1 : Forcer l'utilisation du CPU export CUDA_VISIBLE_DEVICES=\"\" python scripts/train.py # Option 2 : R\u00e9duire la batch size # \u00c9diter scripts/train.py ligne ~200 # per_device_train_batch_size=8 \u2192 per_device_train_batch_size=2","title":"Probl\u00e8me : CUDA out of memory"},{"location":"installation/#probleme-permission-denied-sur-scripts","text":"-bash: trip-demo: command not found Cause : Les scripts ne sont pas dans le PATH ou pas ex\u00e9cutables Solution : # R\u00e9installer le package pip install -e . # V\u00e9rifier que les scripts sont install\u00e9s pip show trip-parser | grep Location ls $(pip show trip-parser | grep Location | cut -d' ' -f2)/../../../bin/trip-*","title":"Probl\u00e8me : Permission denied sur scripts"},{"location":"installation/#probleme-port-8000-deja-utilise","text":"ERROR: [Errno 48] Address already in use Cause : Un autre processus utilise le port 8000 Solution : # Option 1 : Utiliser un autre port trip-api --port 8001 # Option 2 : Tuer le processus qui utilise le port 8000 # macOS/Linux lsof -ti:8000 | xargs kill -9 # V\u00e9rifier que le port est libre lsof -i:8000","title":"Probl\u00e8me : Port 8000 d\u00e9j\u00e0 utilis\u00e9"},{"location":"trip-parser/","text":"Documentation technique compl\u00e8te du module trip_parser , incluant les d\u00e9tails des mod\u00e8les ML, l'entra\u00eenement, et la configuration. \ud83d\udce6 Vue d'ensemble Le module trip_parser est le c\u0153ur du syst\u00e8me d'extraction de trajets. Il combine deux mod\u00e8les de Machine Learning pour transformer du texte en fran\u00e7ais en informations structur\u00e9es de voyage. Composants principaux : Composant Type R\u00f4le NERExtractor Mod\u00e8le pr\u00e9-entra\u00een\u00e9 D\u00e9tection des entit\u00e9s g\u00e9ographiques DepartureArrivalClassifier Mod\u00e8le fine-tun\u00e9 Classification d\u00e9part vs arriv\u00e9e TripParser Orchestrateur Coordination des mod\u00e8les Config Configuration Chemins et param\u00e8tres Exceptions Gestion d'erreurs Exceptions typ\u00e9es \ud83e\udd16 NERExtractor (D\u00e9tection d'entit\u00e9s) Mod\u00e8le utilis\u00e9 Nom : Jean-Baptiste/camembert-ner Source : Hugging Face Hub Architecture : CamemBERT Base (110M param\u00e8tres) \u2193 [Embedding Layer] \u2193 [12 Transformer Blocks] \u2193 [Token Classification Head] \u2193 4 classes : PER, LOC, ORG, MISC Capacit\u00e9s : \u2705 D\u00e9tecte les noms de villes fran\u00e7aises (Paris, Lyon, Marseille...) \u2705 D\u00e9tecte les lieux (gares, a\u00e9roports...) \u2705 G\u00e8re les variations orthographiques \u26a0\ufe0f Moins pr\u00e9cis sur les petites villes peu connues Tokenisation d\u00e9taill\u00e9e Exemple basique text = \"Je vais de Paris \u00e0 Lyon\" # \u00c9tape 1 : Tokenisation subword tokens = [\"\u2581Je\", \"\u2581vais\", \"\u2581de\", \"\u2581Paris\", \"\u2581\u00e0\", \"\u2581Lyon\"] # Note : \u2581 indique le d\u00e9but d'un mot # \u00c9tape 2 : Conversion en IDs input_ids = [5, 123, 456, 789, 12, 567] # \u00c9tape 3 : Forward pass CamemBERT # Chaque token obtient un score pour chaque classe logits = [ [0.1, 0.05, 0.05, 0.8], # \"\u2581Je\" \u2192 O (Outside) [0.15, 0.1, 0.05, 0.7], # \"\u2581vais\" \u2192 O [0.2, 0.05, 0.05, 0.7], # \"\u2581de\" \u2192 O [0.05, 0.9, 0.03, 0.02], # \"\u2581Paris\" \u2192 LOC (B-LOC) [0.3, 0.05, 0.05, 0.6], # \"\u2581\u00e0\" \u2192 O [0.05, 0.92, 0.02, 0.01] # \"\u2581Lyon\" \u2192 LOC (B-LOC) ] # Classes : [PER, LOC, ORG, MISC] # \u00c9tape 4 : Agr\u00e9gation entities = [ {\"entity_group\": \"LOC\", \"word\": \"Paris\", \"score\": 0.90}, {\"entity_group\": \"LOC\", \"word\": \"Lyon\", \"score\": 0.92} ] # \u00c9tape 5 : Extraction finale locations = [\"Paris\", \"Lyon\"] Cas complexe : tokens multiples text = \"Je vais \u00e0 Saint-\u00c9tienne\" # Tokenisation subword (Saint-\u00c9tienne en plusieurs tokens) tokens = [\"\u2581Je\", \"\u2581vais\", \"\u2581\u00e0\", \"\u2581Saint\", \"-\", \"\u00c9t\", \"ienne\"] # NER labels (B=Begin, I=Inside) labels = [\"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"I-LOC\", \"I-LOC\"] # Agr\u00e9gation (strategy=\"simple\" fusionne B-LOC + I-LOC) entities = [ { \"entity_group\": \"LOC\", \"word\": \"Saint-\u00c9tienne\", # Reconstruit automatiquement \"score\": 0.87 } ] locations = [\"Saint-\u00c9tienne\"] Gestion des locations compos\u00e9es text = \"Paris Marseille demain\" # NER d\u00e9tecte les deux villes coll\u00e9es entities = [ {\"entity_group\": \"LOC\", \"word\": \"Paris Marseille\", \"score\": 0.75} ] # Split automatique des locations compos\u00e9es # (fonction _split_compound_locations) locations = [\"Paris\", \"Marseille\"] # Split car 2 mots majuscules M\u00e9triques de performance Dataset de test : ~1000 phrases vari\u00e9es M\u00e9trique Score Description Precision 95% 95% des entit\u00e9s d\u00e9tect\u00e9es sont correctes Recall 93% 93% des villes pr\u00e9sentes sont d\u00e9tect\u00e9es F1-Score 94% Moyenne harmonique pr\u00e9cision/rappel Temps d'inf\u00e9rence : CPU : ~100-150ms par phrase GPU (CUDA) : ~20-30ms par phrase Limitations connues 1. Noms communs ambigus \"Train de Paris-Gare-de-Lyon\" # Risque de d\u00e9tecter \"Lyon\" comme ville 2. Petites villes rares \"De Tiny-Village \u00e0 Unknown-Town\" # Peut ne pas d\u00e9tecter les villages peu connus 3. Noms de lieux non-villes \"A\u00e9roport Charles de Gaulle \u00e0 Orly\" # Peut confondre a\u00e9roports et villes \ud83c\udfaf DepartureArrivalClassifier (Classification) Mod\u00e8le fine-tun\u00e9 Mod\u00e8le de base : camembert-base (Hugging Face) Fine-tuning : Dataset : data/training_dataset.json Task : Classification binaire (2 classes) Classes : 0 = departure, 1 = arrival Epochs : 3 Learning rate : 2e-5 Batch size : 8 Architecture : CamemBERT Base (110M param\u00e8tres) \u2193 [Embedding Layer] \u2193 [12 Transformer Blocks] \u2193 [Dropout 0.1] \u2193 [Linear Layer : 768 \u2192 2] \u2193 2 classes : departure, arrival Format du dataset d'entra\u00eenement Fichier : data/training_dataset.json [ { \"text\": \"Je veux aller de [LOC] Paris [/LOC] \u00e0 Lyon\", \"label\": 0 }, { \"text\": \"Je veux aller de Paris \u00e0 [LOC] Lyon [/LOC]\", \"label\": 1 }, { \"text\": \"Train de [LOC] Marseille [/LOC] vers Nice\", \"label\": 0 }, { \"text\": \"Train de Marseille vers [LOC] Nice [/LOC]\", \"label\": 1 } ] Structure des exemples : Chaque exemple contient : text : La phrase avec une ville marqu\u00e9e entre [LOC] et [/LOC] label : 0 pour departure (d\u00e9part), 1 pour arrival (arriv\u00e9e) Format des labels : # Exemple 1 : Ville de d\u00e9part marqu\u00e9e { \"text\": \"Je veux aller de [LOC] Paris [/LOC] \u00e0 Lyon\", \"label\": 0 # 0 = departure (Paris est le d\u00e9part) } # Exemple 2 : Ville d'arriv\u00e9e marqu\u00e9e { \"text\": \"Je veux aller de Paris \u00e0 [LOC] Lyon [/LOC]\", \"label\": 1 # 1 = arrival (Lyon est l'arriv\u00e9e) } Entra\u00eenement du classifier Script : scripts/train.py Commande : trip-train \u00c9tapes d'entra\u00eenement : 1. Chargement des donn\u00e9es # Charger le dataset with open(\"data/training_dataset.json\") as f: data = json.load(f) print(f\"Loaded {len(data)} examples\") # Exemple de sortie : # Loaded 140 examples 2. Extraction des textes et labels # Extraire les textes et labels du dataset training_texts = [item[\"text\"] for item in data] training_labels = [item[\"label\"] for item in data] print(f\"Training texts: {len(training_texts)}\") print(f\"Training labels: {len(training_labels)}\") # Exemple de sortie : # Training texts: 140 # Training labels: 140 3. Split train/validation from sklearn.model_selection import train_test_split X_train, X_val, y_train, y_val = train_test_split( training_texts, training_labels, test_size=0.2, random_state=42, stratify=training_labels # \u00c9quilibre les classes ) print(f\"Train: {len(X_train)}, Validation: {len(X_val)}\") # Train: 1920, Validation: 480 4. Cr\u00e9ation du dataset PyTorch from torch.utils.data import Dataset class TripDataset(Dataset): def __init__(self, texts, labels, tokenizer): self.texts = texts self.labels = labels self.tokenizer = tokenizer def __getitem__(self, idx): text = self.texts[idx] label = self.labels[idx] encoding = self.tokenizer( text, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\" ) return { \"input_ids\": encoding[\"input_ids\"].squeeze(), \"attention_mask\": encoding[\"attention_mask\"].squeeze(), \"labels\": torch.tensor(label) } train_dataset = TripDataset(X_train, y_train, tokenizer) val_dataset = TripDataset(X_val, y_val, tokenizer) 5. Configuration d'entra\u00eenement from transformers import TrainingArguments, Trainer training_args = TrainingArguments( output_dir=\"models/departure_arrival_classifier\", num_train_epochs=3, per_device_train_batch_size=8, per_device_eval_batch_size=16, learning_rate=2e-5, weight_decay=0.01, logging_steps=10, evaluation_strategy=\"epoch\", save_strategy=\"epoch\", load_best_model_at_end=True, metric_for_best_model=\"accuracy\" ) trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metrics ) 6. Lancement de l'entra\u00eenement # Lancer l'entra\u00eenement trainer.train() # Sortie attendue : # Epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [01:23<00:00] # Train Loss: 0.142 # Eval Loss: 0.098 # Eval Accuracy: 96.2% # # Epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [01:21<00:00] # Train Loss: 0.067 # Eval Loss: 0.084 # Eval Accuracy: 97.5% # # Epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [01:22<00:00] # Train Loss: 0.034 # Eval Loss: 0.079 # Eval Accuracy: 98.1% 7. Sauvegarde du mod\u00e8le # Sauvegarder le meilleur mod\u00e8le trainer.save_model(\"models/departure_arrival_classifier\") tokenizer.save_pretrained(\"models/departure_arrival_classifier\") # Fichiers sauvegard\u00e9s : # models/departure_arrival_classifier/ # \u251c\u2500\u2500 config.json # \u251c\u2500\u2500 model.safetensors # \u251c\u2500\u2500 tokenizer_config.json # \u251c\u2500\u2500 sentencepiece.bpe.model # \u251c\u2500\u2500 special_tokens_map.json # \u2514\u2500\u2500 added_tokens.json M\u00e9triques de performance Dataset de validation : 480 exemples M\u00e9trique Score Description Accuracy 98.1% Taux de classification correcte Precision 97.8% Pr\u00e9cision (departure) Recall 98.5% Rappel (departure) F1-Score 98.2% F1 global Matrice de confusion : Predicted Dep Arr Actual Dep 236 4 \u2192 98.3% recall Arr 3 237 \u2192 98.7% recall Precision: 98.7% 98.3% Inf\u00e9rence d\u00e9taill\u00e9e text = \"Je vais de Paris \u00e0 Lyon\" location = \"Paris\" # 1. Marquer la location marked_text = text.replace(location, \"[LOC]\") # \u2192 \"Je vais de [LOC] \u00e0 Lyon\" # 2. Tokeniser inputs = tokenizer(marked_text, return_tensors=\"pt\") # \u2192 { # \"input_ids\": tensor([[5, 123, 456, 789, 12, 567, 6]]), # \"attention_mask\": tensor([[1, 1, 1, 1, 1, 1, 1]]) # } # 3. Forward pass with torch.no_grad(): outputs = model(**inputs) logits = outputs.logits # \u2192 tensor([[4.2, -3.8]]) # [score_departure, score_arrival] # 4. Softmax pour probabilit\u00e9s probs = torch.softmax(logits, dim=1) # \u2192 tensor([[0.9982, 0.0018]]) # 5. Pr\u00e9diction label = logits.argmax().item() # \u2192 0 (departure) confidence = probs[0, label].item() # \u2192 0.9982 return (\"departure\", 0.9982) \u2699\ufe0f Configuration Fichier de configuration Fichier : src/trip_parser/config.py @dataclass class Paths: \"\"\"Configuration des chemins (absolus).\"\"\" # Racine du projet (calcul\u00e9e automatiquement) PROJECT_ROOT: Path = field( default_factory=lambda: Path(__file__).parent.parent.parent ) @property def models_dir(self) -> Path: \"\"\"Dossier des mod\u00e8les : PROJECT_ROOT/models/\"\"\" return self.PROJECT_ROOT / \"models\" @property def data_dir(self) -> Path: \"\"\"Dossier des donn\u00e9es : PROJECT_ROOT/data/\"\"\" return self.PROJECT_ROOT / \"data\" @property def logs_dir(self) -> Path: \"\"\"Dossier des logs : PROJECT_ROOT/logs/\"\"\" return self.PROJECT_ROOT / \"logs\" @property def departure_arrival_model(self) -> Path: \"\"\"Chemin du classifier fine-tun\u00e9.\"\"\" return self.models_dir / \"departure_arrival_classifier\" @property def training_dataset(self) -> Path: \"\"\"Chemin du dataset d'entra\u00eenement.\"\"\" return self.data_dir / \"training_dataset.json\" @dataclass class ModelConfig: \"\"\"Configuration des mod\u00e8les ML.\"\"\" # Nom du mod\u00e8le NER sur Hugging Face ner_model_name: str = \"Jean-Baptiste/camembert-ner\" # Seuil de confiance pour la classification confidence_threshold: float = 0.5 # Device (None = auto-d\u00e9tection) device: str | None = None # \"cuda\" ou \"cpu\" @dataclass class Config: \"\"\"Configuration globale.\"\"\" paths: Paths = field(default_factory=Paths) model: ModelConfig = field(default_factory=ModelConfig) Utilisation de la configuration from trip_parser import get_config config = get_config() # Acc\u00e9der aux chemins print(config.paths.PROJECT_ROOT) # \u2192 /Users/natchi/Epitech/T-AIA-911/bootstrap print(config.paths.models_dir) # \u2192 /Users/natchi/Epitech/T-AIA-911/bootstrap/models print(config.paths.departure_arrival_model) # \u2192 /Users/natchi/Epitech/T-AIA-911/bootstrap/models/departure_arrival_classifier # Acc\u00e9der \u00e0 la config des mod\u00e8les print(config.model.ner_model_name) # \u2192 Jean-Baptiste/camembert-ner print(config.model.confidence_threshold) # \u2192 0.5 # Modifier la configuration config.model.confidence_threshold = 0.7 config.model.device = \"cuda\" \ud83d\udea8 Exceptions Hi\u00e9rarchie compl\u00e8te TripExtractionError (Exception) \u2502 \u251c\u2500\u2500 ModelNotFoundError \u2502 Message: \"Model not found at '{path}'. Please train the model first...\" \u2502 Attributs: model_path \u2502 \u251c\u2500\u2500 ModelLoadError \u2502 Message: \"Failed to load model '{name}': {original_error}\" \u2502 Attributs: model_name, original_error \u2502 \u251c\u2500\u2500 InsufficientLocationsError \u2502 Message: \"Need at least {required} locations, but only found {found}\" \u2502 Attributs: found_count, required_count \u2502 \u251c\u2500\u2500 InvalidInputError \u2502 Message: \"Invalid input for '{field}': {reason}\" \u2502 Attributs: field, value, reason \u2502 \u251c\u2500\u2500 ClassificationError \u2502 Message: \"Failed to classify locations. Consider adding to training...\" \u2502 Attributs: text, locations \u2502 \u2514\u2500\u2500 TokenizationError Message: \"Tokenization failed: {original_error}\" Attributs: text, original_error Gestion des exceptions from trip_parser import TripParser from trip_parser.exceptions import ( TripExtractionError, InvalidInputError, InsufficientLocationsError, ModelNotFoundError ) parser = TripParser() try: departure, arrival = parser.parse_trip(user_input) except InvalidInputError as e: # Texte vide ou invalide print(f\"Erreur de validation: {e.field} - {e.value}\") # Action: Demander \u00e0 l'utilisateur de corriger l'entr\u00e9e except InsufficientLocationsError as e: # Moins de 2 villes d\u00e9tect\u00e9es print(f\"Seulement {e.found_count} ville(s) d\u00e9tect\u00e9e(s)\") # Action: Demander plus de d\u00e9tails except ModelNotFoundError as e: # Mod\u00e8le non entra\u00een\u00e9 print(f\"Mod\u00e8le manquant: {e.model_path}\") print(\"Ex\u00e9cutez: trip-train\") # Action: Afficher les instructions d'entra\u00eenement except TripExtractionError as e: # Erreur g\u00e9n\u00e9rique print(f\"Erreur d'extraction: {e}\") # Action: Logger et retourner une erreur g\u00e9n\u00e9rique \ud83d\udd27 Utilitaires Logging Fichier : src/trip_parser/utils.py from trip_parser.utils import setup_logging import logging # Configuration basique setup_logging(level=logging.INFO) # Configuration avec fichier setup_logging( level=logging.DEBUG, log_file=\"logs/trip_parser.log\" ) # Utilisation logger = logging.getLogger(__name__) logger.info(\"Processing started\") logger.debug(f\"Text: {text}\") logger.error(f\"Error: {e}\", exc_info=True) Formatage des r\u00e9sultats from trip_parser.utils import format_trip_result # Formatage pour affichage result = format_trip_result(\"Paris\", \"Lyon\") print(result) # \u2192 \"Paris \u2192 Lyon\" result = format_trip_result(\"Paris\", None) print(result) # \u2192 \"Paris \u2192 ?\" result = format_trip_result(None, None) print(result) # \u2192 \"No trip information found\" \ud83d\udcca Optimisations et bonnes pratiques Performance 1. R\u00e9utiliser l'instance TripParser # \u2705 Bon : une seule instance parser = TripParser() # Charge les mod\u00e8les une fois for text in texts: result = parser.parse_trip(text) # \u274c Mauvais : recharge \u00e0 chaque fois for text in texts: parser = TripParser() # 2-3s de chargement ! result = parser.parse_trip(text) 2. Utiliser GPU si disponible import torch if torch.cuda.is_available(): print(\"GPU disponible, utilisation automatique\") else: print(\"CPU utilis\u00e9 (plus lent)\") 3. Batch processing pour gros volumes # Traiter plusieurs phrases d'un coup results = [parser.parse_trip(t) for t in texts] Qualit\u00e9 1. Ajouter des donn\u00e9es d'entra\u00eenement // data/training_dataset.json { \"examples\": [ // Ajouter vos propres phrases probl\u00e9matiques { \"sentence\": \"Vol de Nantes vers Rennes\", \"departure\": \"Nantes\", \"arrival\": \"Rennes\" } ] } 2. R\u00e9entra\u00eener r\u00e9guli\u00e8rement # Apr\u00e8s avoir ajout\u00e9 des donn\u00e9es trip-train 3. Valider les r\u00e9sultats departure, arrival = parser.parse_trip(text) if not (departure and arrival): # Demander clarification \u00e0 l'utilisateur pass","title":"Module Trip Parser"},{"location":"trip-parser/#vue-densemble","text":"Le module trip_parser est le c\u0153ur du syst\u00e8me d'extraction de trajets. Il combine deux mod\u00e8les de Machine Learning pour transformer du texte en fran\u00e7ais en informations structur\u00e9es de voyage. Composants principaux : Composant Type R\u00f4le NERExtractor Mod\u00e8le pr\u00e9-entra\u00een\u00e9 D\u00e9tection des entit\u00e9s g\u00e9ographiques DepartureArrivalClassifier Mod\u00e8le fine-tun\u00e9 Classification d\u00e9part vs arriv\u00e9e TripParser Orchestrateur Coordination des mod\u00e8les Config Configuration Chemins et param\u00e8tres Exceptions Gestion d'erreurs Exceptions typ\u00e9es","title":"\ud83d\udce6 Vue d'ensemble"},{"location":"trip-parser/#nerextractor-detection-dentites","text":"","title":"\ud83e\udd16 NERExtractor (D\u00e9tection d'entit\u00e9s)"},{"location":"trip-parser/#modele-utilise","text":"Nom : Jean-Baptiste/camembert-ner Source : Hugging Face Hub Architecture : CamemBERT Base (110M param\u00e8tres) \u2193 [Embedding Layer] \u2193 [12 Transformer Blocks] \u2193 [Token Classification Head] \u2193 4 classes : PER, LOC, ORG, MISC Capacit\u00e9s : \u2705 D\u00e9tecte les noms de villes fran\u00e7aises (Paris, Lyon, Marseille...) \u2705 D\u00e9tecte les lieux (gares, a\u00e9roports...) \u2705 G\u00e8re les variations orthographiques \u26a0\ufe0f Moins pr\u00e9cis sur les petites villes peu connues","title":"Mod\u00e8le utilis\u00e9"},{"location":"trip-parser/#tokenisation-detaillee","text":"Exemple basique text = \"Je vais de Paris \u00e0 Lyon\" # \u00c9tape 1 : Tokenisation subword tokens = [\"\u2581Je\", \"\u2581vais\", \"\u2581de\", \"\u2581Paris\", \"\u2581\u00e0\", \"\u2581Lyon\"] # Note : \u2581 indique le d\u00e9but d'un mot # \u00c9tape 2 : Conversion en IDs input_ids = [5, 123, 456, 789, 12, 567] # \u00c9tape 3 : Forward pass CamemBERT # Chaque token obtient un score pour chaque classe logits = [ [0.1, 0.05, 0.05, 0.8], # \"\u2581Je\" \u2192 O (Outside) [0.15, 0.1, 0.05, 0.7], # \"\u2581vais\" \u2192 O [0.2, 0.05, 0.05, 0.7], # \"\u2581de\" \u2192 O [0.05, 0.9, 0.03, 0.02], # \"\u2581Paris\" \u2192 LOC (B-LOC) [0.3, 0.05, 0.05, 0.6], # \"\u2581\u00e0\" \u2192 O [0.05, 0.92, 0.02, 0.01] # \"\u2581Lyon\" \u2192 LOC (B-LOC) ] # Classes : [PER, LOC, ORG, MISC] # \u00c9tape 4 : Agr\u00e9gation entities = [ {\"entity_group\": \"LOC\", \"word\": \"Paris\", \"score\": 0.90}, {\"entity_group\": \"LOC\", \"word\": \"Lyon\", \"score\": 0.92} ] # \u00c9tape 5 : Extraction finale locations = [\"Paris\", \"Lyon\"] Cas complexe : tokens multiples text = \"Je vais \u00e0 Saint-\u00c9tienne\" # Tokenisation subword (Saint-\u00c9tienne en plusieurs tokens) tokens = [\"\u2581Je\", \"\u2581vais\", \"\u2581\u00e0\", \"\u2581Saint\", \"-\", \"\u00c9t\", \"ienne\"] # NER labels (B=Begin, I=Inside) labels = [\"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"I-LOC\", \"I-LOC\"] # Agr\u00e9gation (strategy=\"simple\" fusionne B-LOC + I-LOC) entities = [ { \"entity_group\": \"LOC\", \"word\": \"Saint-\u00c9tienne\", # Reconstruit automatiquement \"score\": 0.87 } ] locations = [\"Saint-\u00c9tienne\"] Gestion des locations compos\u00e9es text = \"Paris Marseille demain\" # NER d\u00e9tecte les deux villes coll\u00e9es entities = [ {\"entity_group\": \"LOC\", \"word\": \"Paris Marseille\", \"score\": 0.75} ] # Split automatique des locations compos\u00e9es # (fonction _split_compound_locations) locations = [\"Paris\", \"Marseille\"] # Split car 2 mots majuscules","title":"Tokenisation d\u00e9taill\u00e9e"},{"location":"trip-parser/#metriques-de-performance","text":"Dataset de test : ~1000 phrases vari\u00e9es M\u00e9trique Score Description Precision 95% 95% des entit\u00e9s d\u00e9tect\u00e9es sont correctes Recall 93% 93% des villes pr\u00e9sentes sont d\u00e9tect\u00e9es F1-Score 94% Moyenne harmonique pr\u00e9cision/rappel Temps d'inf\u00e9rence : CPU : ~100-150ms par phrase GPU (CUDA) : ~20-30ms par phrase","title":"M\u00e9triques de performance"},{"location":"trip-parser/#limitations-connues","text":"1. Noms communs ambigus \"Train de Paris-Gare-de-Lyon\" # Risque de d\u00e9tecter \"Lyon\" comme ville 2. Petites villes rares \"De Tiny-Village \u00e0 Unknown-Town\" # Peut ne pas d\u00e9tecter les villages peu connus 3. Noms de lieux non-villes \"A\u00e9roport Charles de Gaulle \u00e0 Orly\" # Peut confondre a\u00e9roports et villes","title":"Limitations connues"},{"location":"trip-parser/#departurearrivalclassifier-classification","text":"","title":"\ud83c\udfaf DepartureArrivalClassifier (Classification)"},{"location":"trip-parser/#modele-fine-tune","text":"Mod\u00e8le de base : camembert-base (Hugging Face) Fine-tuning : Dataset : data/training_dataset.json Task : Classification binaire (2 classes) Classes : 0 = departure, 1 = arrival Epochs : 3 Learning rate : 2e-5 Batch size : 8 Architecture : CamemBERT Base (110M param\u00e8tres) \u2193 [Embedding Layer] \u2193 [12 Transformer Blocks] \u2193 [Dropout 0.1] \u2193 [Linear Layer : 768 \u2192 2] \u2193 2 classes : departure, arrival","title":"Mod\u00e8le fine-tun\u00e9"},{"location":"trip-parser/#format-du-dataset-dentrainement","text":"Fichier : data/training_dataset.json [ { \"text\": \"Je veux aller de [LOC] Paris [/LOC] \u00e0 Lyon\", \"label\": 0 }, { \"text\": \"Je veux aller de Paris \u00e0 [LOC] Lyon [/LOC]\", \"label\": 1 }, { \"text\": \"Train de [LOC] Marseille [/LOC] vers Nice\", \"label\": 0 }, { \"text\": \"Train de Marseille vers [LOC] Nice [/LOC]\", \"label\": 1 } ] Structure des exemples : Chaque exemple contient : text : La phrase avec une ville marqu\u00e9e entre [LOC] et [/LOC] label : 0 pour departure (d\u00e9part), 1 pour arrival (arriv\u00e9e) Format des labels : # Exemple 1 : Ville de d\u00e9part marqu\u00e9e { \"text\": \"Je veux aller de [LOC] Paris [/LOC] \u00e0 Lyon\", \"label\": 0 # 0 = departure (Paris est le d\u00e9part) } # Exemple 2 : Ville d'arriv\u00e9e marqu\u00e9e { \"text\": \"Je veux aller de Paris \u00e0 [LOC] Lyon [/LOC]\", \"label\": 1 # 1 = arrival (Lyon est l'arriv\u00e9e) }","title":"Format du dataset d'entra\u00eenement"},{"location":"trip-parser/#entrainement-du-classifier","text":"Script : scripts/train.py Commande : trip-train \u00c9tapes d'entra\u00eenement : 1. Chargement des donn\u00e9es # Charger le dataset with open(\"data/training_dataset.json\") as f: data = json.load(f) print(f\"Loaded {len(data)} examples\") # Exemple de sortie : # Loaded 140 examples 2. Extraction des textes et labels # Extraire les textes et labels du dataset training_texts = [item[\"text\"] for item in data] training_labels = [item[\"label\"] for item in data] print(f\"Training texts: {len(training_texts)}\") print(f\"Training labels: {len(training_labels)}\") # Exemple de sortie : # Training texts: 140 # Training labels: 140 3. Split train/validation from sklearn.model_selection import train_test_split X_train, X_val, y_train, y_val = train_test_split( training_texts, training_labels, test_size=0.2, random_state=42, stratify=training_labels # \u00c9quilibre les classes ) print(f\"Train: {len(X_train)}, Validation: {len(X_val)}\") # Train: 1920, Validation: 480 4. Cr\u00e9ation du dataset PyTorch from torch.utils.data import Dataset class TripDataset(Dataset): def __init__(self, texts, labels, tokenizer): self.texts = texts self.labels = labels self.tokenizer = tokenizer def __getitem__(self, idx): text = self.texts[idx] label = self.labels[idx] encoding = self.tokenizer( text, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\" ) return { \"input_ids\": encoding[\"input_ids\"].squeeze(), \"attention_mask\": encoding[\"attention_mask\"].squeeze(), \"labels\": torch.tensor(label) } train_dataset = TripDataset(X_train, y_train, tokenizer) val_dataset = TripDataset(X_val, y_val, tokenizer) 5. Configuration d'entra\u00eenement from transformers import TrainingArguments, Trainer training_args = TrainingArguments( output_dir=\"models/departure_arrival_classifier\", num_train_epochs=3, per_device_train_batch_size=8, per_device_eval_batch_size=16, learning_rate=2e-5, weight_decay=0.01, logging_steps=10, evaluation_strategy=\"epoch\", save_strategy=\"epoch\", load_best_model_at_end=True, metric_for_best_model=\"accuracy\" ) trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metrics ) 6. Lancement de l'entra\u00eenement # Lancer l'entra\u00eenement trainer.train() # Sortie attendue : # Epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [01:23<00:00] # Train Loss: 0.142 # Eval Loss: 0.098 # Eval Accuracy: 96.2% # # Epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [01:21<00:00] # Train Loss: 0.067 # Eval Loss: 0.084 # Eval Accuracy: 97.5% # # Epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [01:22<00:00] # Train Loss: 0.034 # Eval Loss: 0.079 # Eval Accuracy: 98.1% 7. Sauvegarde du mod\u00e8le # Sauvegarder le meilleur mod\u00e8le trainer.save_model(\"models/departure_arrival_classifier\") tokenizer.save_pretrained(\"models/departure_arrival_classifier\") # Fichiers sauvegard\u00e9s : # models/departure_arrival_classifier/ # \u251c\u2500\u2500 config.json # \u251c\u2500\u2500 model.safetensors # \u251c\u2500\u2500 tokenizer_config.json # \u251c\u2500\u2500 sentencepiece.bpe.model # \u251c\u2500\u2500 special_tokens_map.json # \u2514\u2500\u2500 added_tokens.json","title":"Entra\u00eenement du classifier"},{"location":"trip-parser/#metriques-de-performance_1","text":"Dataset de validation : 480 exemples M\u00e9trique Score Description Accuracy 98.1% Taux de classification correcte Precision 97.8% Pr\u00e9cision (departure) Recall 98.5% Rappel (departure) F1-Score 98.2% F1 global Matrice de confusion : Predicted Dep Arr Actual Dep 236 4 \u2192 98.3% recall Arr 3 237 \u2192 98.7% recall Precision: 98.7% 98.3%","title":"M\u00e9triques de performance"},{"location":"trip-parser/#inference-detaillee","text":"text = \"Je vais de Paris \u00e0 Lyon\" location = \"Paris\" # 1. Marquer la location marked_text = text.replace(location, \"[LOC]\") # \u2192 \"Je vais de [LOC] \u00e0 Lyon\" # 2. Tokeniser inputs = tokenizer(marked_text, return_tensors=\"pt\") # \u2192 { # \"input_ids\": tensor([[5, 123, 456, 789, 12, 567, 6]]), # \"attention_mask\": tensor([[1, 1, 1, 1, 1, 1, 1]]) # } # 3. Forward pass with torch.no_grad(): outputs = model(**inputs) logits = outputs.logits # \u2192 tensor([[4.2, -3.8]]) # [score_departure, score_arrival] # 4. Softmax pour probabilit\u00e9s probs = torch.softmax(logits, dim=1) # \u2192 tensor([[0.9982, 0.0018]]) # 5. Pr\u00e9diction label = logits.argmax().item() # \u2192 0 (departure) confidence = probs[0, label].item() # \u2192 0.9982 return (\"departure\", 0.9982)","title":"Inf\u00e9rence d\u00e9taill\u00e9e"},{"location":"trip-parser/#configuration","text":"","title":"\u2699\ufe0f Configuration"},{"location":"trip-parser/#fichier-de-configuration","text":"Fichier : src/trip_parser/config.py @dataclass class Paths: \"\"\"Configuration des chemins (absolus).\"\"\" # Racine du projet (calcul\u00e9e automatiquement) PROJECT_ROOT: Path = field( default_factory=lambda: Path(__file__).parent.parent.parent ) @property def models_dir(self) -> Path: \"\"\"Dossier des mod\u00e8les : PROJECT_ROOT/models/\"\"\" return self.PROJECT_ROOT / \"models\" @property def data_dir(self) -> Path: \"\"\"Dossier des donn\u00e9es : PROJECT_ROOT/data/\"\"\" return self.PROJECT_ROOT / \"data\" @property def logs_dir(self) -> Path: \"\"\"Dossier des logs : PROJECT_ROOT/logs/\"\"\" return self.PROJECT_ROOT / \"logs\" @property def departure_arrival_model(self) -> Path: \"\"\"Chemin du classifier fine-tun\u00e9.\"\"\" return self.models_dir / \"departure_arrival_classifier\" @property def training_dataset(self) -> Path: \"\"\"Chemin du dataset d'entra\u00eenement.\"\"\" return self.data_dir / \"training_dataset.json\" @dataclass class ModelConfig: \"\"\"Configuration des mod\u00e8les ML.\"\"\" # Nom du mod\u00e8le NER sur Hugging Face ner_model_name: str = \"Jean-Baptiste/camembert-ner\" # Seuil de confiance pour la classification confidence_threshold: float = 0.5 # Device (None = auto-d\u00e9tection) device: str | None = None # \"cuda\" ou \"cpu\" @dataclass class Config: \"\"\"Configuration globale.\"\"\" paths: Paths = field(default_factory=Paths) model: ModelConfig = field(default_factory=ModelConfig)","title":"Fichier de configuration"},{"location":"trip-parser/#utilisation-de-la-configuration","text":"from trip_parser import get_config config = get_config() # Acc\u00e9der aux chemins print(config.paths.PROJECT_ROOT) # \u2192 /Users/natchi/Epitech/T-AIA-911/bootstrap print(config.paths.models_dir) # \u2192 /Users/natchi/Epitech/T-AIA-911/bootstrap/models print(config.paths.departure_arrival_model) # \u2192 /Users/natchi/Epitech/T-AIA-911/bootstrap/models/departure_arrival_classifier # Acc\u00e9der \u00e0 la config des mod\u00e8les print(config.model.ner_model_name) # \u2192 Jean-Baptiste/camembert-ner print(config.model.confidence_threshold) # \u2192 0.5 # Modifier la configuration config.model.confidence_threshold = 0.7 config.model.device = \"cuda\"","title":"Utilisation de la configuration"},{"location":"trip-parser/#exceptions","text":"","title":"\ud83d\udea8 Exceptions"},{"location":"trip-parser/#hierarchie-complete","text":"TripExtractionError (Exception) \u2502 \u251c\u2500\u2500 ModelNotFoundError \u2502 Message: \"Model not found at '{path}'. Please train the model first...\" \u2502 Attributs: model_path \u2502 \u251c\u2500\u2500 ModelLoadError \u2502 Message: \"Failed to load model '{name}': {original_error}\" \u2502 Attributs: model_name, original_error \u2502 \u251c\u2500\u2500 InsufficientLocationsError \u2502 Message: \"Need at least {required} locations, but only found {found}\" \u2502 Attributs: found_count, required_count \u2502 \u251c\u2500\u2500 InvalidInputError \u2502 Message: \"Invalid input for '{field}': {reason}\" \u2502 Attributs: field, value, reason \u2502 \u251c\u2500\u2500 ClassificationError \u2502 Message: \"Failed to classify locations. Consider adding to training...\" \u2502 Attributs: text, locations \u2502 \u2514\u2500\u2500 TokenizationError Message: \"Tokenization failed: {original_error}\" Attributs: text, original_error","title":"Hi\u00e9rarchie compl\u00e8te"},{"location":"trip-parser/#gestion-des-exceptions","text":"from trip_parser import TripParser from trip_parser.exceptions import ( TripExtractionError, InvalidInputError, InsufficientLocationsError, ModelNotFoundError ) parser = TripParser() try: departure, arrival = parser.parse_trip(user_input) except InvalidInputError as e: # Texte vide ou invalide print(f\"Erreur de validation: {e.field} - {e.value}\") # Action: Demander \u00e0 l'utilisateur de corriger l'entr\u00e9e except InsufficientLocationsError as e: # Moins de 2 villes d\u00e9tect\u00e9es print(f\"Seulement {e.found_count} ville(s) d\u00e9tect\u00e9e(s)\") # Action: Demander plus de d\u00e9tails except ModelNotFoundError as e: # Mod\u00e8le non entra\u00een\u00e9 print(f\"Mod\u00e8le manquant: {e.model_path}\") print(\"Ex\u00e9cutez: trip-train\") # Action: Afficher les instructions d'entra\u00eenement except TripExtractionError as e: # Erreur g\u00e9n\u00e9rique print(f\"Erreur d'extraction: {e}\") # Action: Logger et retourner une erreur g\u00e9n\u00e9rique","title":"Gestion des exceptions"},{"location":"trip-parser/#utilitaires","text":"","title":"\ud83d\udd27 Utilitaires"},{"location":"trip-parser/#logging","text":"Fichier : src/trip_parser/utils.py from trip_parser.utils import setup_logging import logging # Configuration basique setup_logging(level=logging.INFO) # Configuration avec fichier setup_logging( level=logging.DEBUG, log_file=\"logs/trip_parser.log\" ) # Utilisation logger = logging.getLogger(__name__) logger.info(\"Processing started\") logger.debug(f\"Text: {text}\") logger.error(f\"Error: {e}\", exc_info=True)","title":"Logging"},{"location":"trip-parser/#formatage-des-resultats","text":"from trip_parser.utils import format_trip_result # Formatage pour affichage result = format_trip_result(\"Paris\", \"Lyon\") print(result) # \u2192 \"Paris \u2192 Lyon\" result = format_trip_result(\"Paris\", None) print(result) # \u2192 \"Paris \u2192 ?\" result = format_trip_result(None, None) print(result) # \u2192 \"No trip information found\"","title":"Formatage des r\u00e9sultats"},{"location":"trip-parser/#optimisations-et-bonnes-pratiques","text":"","title":"\ud83d\udcca Optimisations et bonnes pratiques"},{"location":"trip-parser/#performance","text":"1. R\u00e9utiliser l'instance TripParser # \u2705 Bon : une seule instance parser = TripParser() # Charge les mod\u00e8les une fois for text in texts: result = parser.parse_trip(text) # \u274c Mauvais : recharge \u00e0 chaque fois for text in texts: parser = TripParser() # 2-3s de chargement ! result = parser.parse_trip(text) 2. Utiliser GPU si disponible import torch if torch.cuda.is_available(): print(\"GPU disponible, utilisation automatique\") else: print(\"CPU utilis\u00e9 (plus lent)\") 3. Batch processing pour gros volumes # Traiter plusieurs phrases d'un coup results = [parser.parse_trip(t) for t in texts]","title":"Performance"},{"location":"trip-parser/#qualite","text":"1. Ajouter des donn\u00e9es d'entra\u00eenement // data/training_dataset.json { \"examples\": [ // Ajouter vos propres phrases probl\u00e9matiques { \"sentence\": \"Vol de Nantes vers Rennes\", \"departure\": \"Nantes\", \"arrival\": \"Rennes\" } ] } 2. R\u00e9entra\u00eener r\u00e9guli\u00e8rement # Apr\u00e8s avoir ajout\u00e9 des donn\u00e9es trip-train 3. Valider les r\u00e9sultats departure, arrival = parser.parse_trip(text) if not (departure and arrival): # Demander clarification \u00e0 l'utilisateur pass","title":"Qualit\u00e9"}]}